---
title: "S5 1 Comparaisons Multiples"
format:
    html:
        toc: true
        toc-depth: 5
        toc-title: "Table of contents"
        toc-location: left
        toc-sticky: true
        number-sections: true
        theme: default

    docx:
        toc: true
        toc-depth: 5

    pdf:
        toc: true
        toc-depth: 5
        pdf-engine: xelatex
        number-sections: true
        header-includes: |
            % \usepackage{fontspec} 
            % \setmainfont{Ubuntu}
            \usepackage{etoolbox}
            \renewcommand{\contentsname}{}
            \AtBeginDocument{
                \addtocontents{toc}{\protect\smallskip}
                \let\oldtableofcontents\tableofcontents
                \renewcommand{\tableofcontents}{
                \begingroup
                    \footnotesize
                    \setlength{\parskip}{2pt}
                    \oldtableofcontents
                \endgroup
                }
            }
            \setcounter{tocdepth}{5}
            \makeatletter
            \renewcommand{\@tocrmarg}{0pt}
            \makeatother
            \usepackage{fvextra}
            \usepackage[section]{placeins}
            \usepackage{needspace}
            \usepackage{float}
            \floatplacement{figure}{H}
            \floatplacement{table}{H}
            \newcommand{\sectionbreak}{\needspace{5\baselineskip}}
            \setlength{\parindent}{0pt}
            \setlength{\parskip}{4pt}
            \usepackage[most]{tcolorbox}
            \usepackage{color}
            \definecolor{lightgray}{gray}{0.95}
            \newtcolorbox{graybox}{colback=gray!10!white,colframe=black,boxrule=0.6pt,arc=1mm,left=6pt,right=6pt,top=4pt,bottom=4pt}
            \newtcolorbox{codebox}{breakable,colback=blue!5!white,colframe=blue!50!black,boxrule=0.5pt,arc=1mm,left=4pt,right=4pt,top=3pt,bottom=3pt}
            \DefineVerbatimEnvironment{CodeBoxContent}{Verbatim}{fontsize=\small,breaklines,breakanywhere}
            \renewcommand{\thesection}{\arabic{section}}
            \renewcommand{\thesubsection}{\thesection.\Alph{subsection}}
            \renewcommand{\thesubsubsection}{\thesubsection.\arabic{subsubsection}}

geometry: margin=2.5cm
---

```{r}
#| label: setup
#| include: false
#| echo: false

library(plotrix)
library(viridisLite)
library(ggplot2)
library(survminer)
library(treemap)
library(psy)
library(qgraph)
library(ape)
library(survival)
library(httpgd)
library(psy)
knitr::opts_chunk$set(echo = TRUE)

load("~/Documents/Projets/M2biostatistiques/Cours/CUSM_data/CUSM")
data(expsy)
```

# Introduction

-   **Fisher** : calcule les petits *p* pour chaque comparaison.

    -   Il fait ainsi de l'**inférence inductive**, c'est à dire qu'il utilise chacune des *p-values* pour en déduire des nouvelles connaissances.

    -   Les observations de départ sont vraies, mais les conclusions sont probables

    -   Génomique : 1 million de petits *p* : ça ne rentrera jamais dans la tête !

-   **Neyman-Pearson** : calcule une **seule** *p-value* pour l'ensemble des comparaisons.

    -   Hypothèse nulle H0 et hypothèse alternative H1

    -   Risque de première espèce (alpha) et risque de deuxième espèce (beta)

        -   $\alpha$ : probabilité de rejeter l'hypothèse nulle alors qu'elle est vraie

        -   $\beta$ : probabilité de ne pas rejeter l'hypothèse nulle alors qu'elle est fausse

    -   Si on augmente le nombre d'hypothèses, on augmente le risque alpha (parce que 5% à chaque fois !)

::: callout-important
Donc risque avec les comparaisons multiples dans la théorie de Neyman et Pearson, mais pas vraiment dans la théorie de Fisher.
:::

[Adjusting for multiple testing—when and how?](Article%20de%20référence%20:%20https://www.jclinepi.com/action/showPdf?pii=S0895-4356%2800%2900314-0)

# Quand ajuster ?

-   Dans Neyman et Pearson = dans les essais randomisés contrôlés

# Comment ajuster ?

## Exemple

Dans l'asthme, on évalue le VEMS et la QoL.

-   1ère situation : Médicament bon si VEMS significatif **ET** QoL significatif

-   2e situation : Médicament bon si VEMS significatif **OU** QoL significatif

    -   Problème : 2 tests indépendants, chacun avec un alpha de 5%

## Méthode de Bonferroni = répartition du risque alpha

**Méthode de Bonferonni** = la plus classique.

Principe : diviser le risque alpha par le nombre de tests effectués.

Dans le cas de l'exemple : 2 tests, donc alpha = 0.05/2 = 0.025

Problème :

-   perte de puissance !

-   Critères d'efficacité souvent corrélés

## Méthode de Holm = répartition du risque alpha

**Méthode de Holm** = plus puissante que Bonferroni.

Principe : ajuster le seuil alpha en fonction du rang des p-values.

1.  Ordonner les p-values de la plus petite à la plus grande

2.  Comparer chaque p-value au seuil alpha divisé par le nombre de tests restants

Exemple : 4 tests, alpha = 0.05

| Rang | p-value | Seuil alpha ajusté | Décision          |
|------|---------|--------------------|-------------------|
| 1    | 0.01    | 0.05/4 = 0.0125    | Rejeter H0        |
| 2    | 0.03    | 0.05/3 = 0.0167    |                   |
| 3    | 0.04    | 0.05/2 = 0.025     | Ne pas rejeter H0 |
| 4    | 0.06    | 0.05/1 = 0.05      | Ne pas rejeter H0 |

## Méthode par hiérarchie

Si critère principal (Survie sans progression) et critères secondaires (Taux CCR, Survie Brute, Qualité de vie)

**Hiérarchisation** :

1.  Tester le critère principal au seuil alpha

2.  Si significatif, tester le premier secondaire au seuil alpha ; sinon stop !

3.  Si significatif, tester le second secondaire au seuil alpha ; sinon stop !

# En dehors des essais thérapeutiques

## Génomique

-   Très grand nombre de tests

-   Correction nécessaire !

    -   Bonferroni : possible mais trop conservateur

    -   FDR : False Discovery Rate (Benjamini-Hochberg)

        -   Contrôle le taux de fausses découvertes parmi les résultats significatifs

        -   Par exemple 20 marqueurs significatifs avec FDR à 15%

        -   Signifie que 3 marqueurs (15% de 20) sont susceptibles d'être des faux positifs

        -   On maîtrise pas le risque de première espèce sur chaque test individuel, mais le pourcentage de faux positifs parmi les tests déclarés significatifs

-   Ou référence inductive ! \$ *"ce sont des pistes intéressantes"*

# Questions

1.  Quand on recherche des interactions

    -   Par exemple 70 interactions

    -   Si on veut **affirmer** qu'il y en a une significative, garder 0,05 n'a pas de sens

    -   Solution :

        -   Classer les p-values

        -   Et les mettre sur une courbe

        -   certaines p values sont /plus petites que ne le voudrait le hasard

        -   Cox et Wermuth

        -   ![](images/paste-36.png)