[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Mes notes de cours",
    "section": "",
    "text": "1 Introduction\nCeci est la page d’accueil du document. Le contenu pourra être complété plus tard.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Mes notes de cours</span>"
    ]
  },
  {
    "objectID": "1_resume_statistique.html",
    "href": "1_resume_statistique.html",
    "title": "2  Résumé statistique",
    "section": "",
    "text": "3 Position et dispersion",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Résumé statistique</span>"
    ]
  },
  {
    "objectID": "1_resume_statistique.html#position",
    "href": "1_resume_statistique.html#position",
    "title": "2  Résumé statistique",
    "section": "3.1 Position",
    "text": "3.1 Position\nParamètres de position = valeurs qui résument la tendance centrale d’une distribution.\n\nMoyenne\nMédiane\nMode\n\n\n3.1.1 Moyenne\nMoyenne = somme des valeurs divisée par le nombre de valeurs.\n\n\\[\n\\frac{1}{n} \\sum_{i=1}^{n} x_i\n\\]\nCorrespond au centre de gravité des points si on les représente sur une droite.\nHypothèses :\n\nLes valeurs sont indépendantes\nÉquivalence de la quantité (1 euro vaut 1 euro quelque soit sa position sur la droite des réels) : donc les notes c’est pas top en vrai !!\nLes valeurs sont continues\n\n\n\n3.1.2 Médiane\nSignification plus directe : valeur qui partage la distribution en deux parties égales.\nSi la distribution est symétrique, la moyenne et la médiane sont égales.\n\n\n3.1.3 Mode\nMode = valeur la plus fréquente.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Résumé statistique</span>"
    ]
  },
  {
    "objectID": "1_resume_statistique.html#dispersion",
    "href": "1_resume_statistique.html#dispersion",
    "title": "2  Résumé statistique",
    "section": "3.2 Dispersion",
    "text": "3.2 Dispersion\nMesures de dispersion = valeurs qui résument la variabilité d’une distribution.\n\nÉtendue = empan\n\n\n3.2.1 Étendue = empan\nCorrespond à la différence entre la valeur maximale et la valeur minimale.\n\n\n3.2.2 Écart interquartile (IQR)\n= Q3 - Q1\n\n\n3.2.3 Écart-type\nécart type = écart “le plus typique” par rapport à la moyenne.\nSi \\(m\\) est la moyenne des observations \\(x_i\\), l’écart type \\(s\\) est défini par la racine carrée de la variance :\n\\[\ns = \\sqrt{[(x_1 - m^2) + \\dots + (x_n - m)^2]/(n-1)}\n\\]\nLa variance correspond à la moyenne des carrés des écarts par rapport à la moyenne.\nDonc en gros : écart type = racine carrée des carrés des écarts par rapport à la moyenne.\nPourquoi ajouter des carrés ?\n\nPositive les écarts négatifs\nAccentue les écarts importants\nEt pour une super propriété de l’écart-type :\n\nLa variance de deux variables indépendantes est égale à la somme de leurs variances.\n\n\nComment l’interpréter ?\n\nDans le cas d’une distribution normale,\n\nenviron 2/3 des observations se situent à moins d’un écart-type de la moyenne.\nenviron la moitié des observations se situent à \\([m - (2/3)s ; m + (2/3)s]\\)\n\n\nAvantages et inconvénients :\n\nAvantage :\n\nutilise toutes les valeurs de la distribution\npropriétés mathématiques intéressantes : la variance de la somme de deux variables indépendantes est égale à la somme de leurs variances.\ns’utilise dans de nombreux tests statistiques (t-test, ANOVA, régression linéaire, etc.)\nFacile à manipuler mathématiquement\nInterprétation claire dans le cas de distributions normales\n\nInconvénient :\n\nsensible aux valeurs extrêmes (outliers)\nne s’interprète pas facilement dans le cas de distributions asymétriques\nPas adapté aux variables ordinales ou catégorielles\n\n\n\n\n3.2.4 Variance\nVariance = écart type au carré\nou moyenne des carrés des valeurs moins le carré de la moyenne.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Résumé statistique</span>"
    ]
  },
  {
    "objectID": "1_resume_statistique.html#exemple-sur-r",
    "href": "1_resume_statistique.html#exemple-sur-r",
    "title": "2  Résumé statistique",
    "section": "3.3 Exemple sur R",
    "text": "3.3 Exemple sur R\nUtilisation du jeu de données smp.d (version réduite de smp) et de la fonction summary()\n\nsummary(smp.d)\n\n      age                profession    nb.enfants       depression    \n Min.   :19.00   ouvrier      :228   Min.   : 0.000   Min.   :0.0000  \n 1st Qu.:28.00   sans.emploi  :221   1st Qu.: 0.000   1st Qu.:0.0000  \n Median :37.00   employé      :136   Median : 1.000   Median :0.0000  \n Mean   :38.94   commerçant   : 91   Mean   : 1.572   Mean   :0.3917  \n 3rd Qu.:48.00   intermédiaire: 57   3rd Qu.: 2.000   3rd Qu.:1.0000  \n Max.   :84.00   (Other)      : 60   Max.   :14.000   Max.   :1.0000  \n NA's   :2       NA's         :  6   NA's   :26                       \n schizophrenie       gravite      recherche.nouv   evit.danger   \n Min.   :0.0000   Min.   :1.000   Min.   :1.000   Min.   :1.000  \n 1st Qu.:0.0000   1st Qu.:2.000   1st Qu.:1.000   1st Qu.:1.000  \n Median :0.0000   Median :4.000   Median :2.000   Median :2.000  \n Mean   :0.0801   Mean   :3.635   Mean   :2.058   Mean   :1.865  \n 3rd Qu.:0.0000   3rd Qu.:5.000   3rd Qu.:3.000   3rd Qu.:3.000  \n Max.   :1.0000   Max.   :7.000   Max.   :3.000   Max.   :3.000  \n                  NA's   :4       NA's   :104     NA's   :108    \n dep.recompense \n Min.   :1.000  \n 1st Qu.:1.000  \n Median :2.000  \n Mean   :2.152  \n 3rd Qu.:3.000  \n Max.   :3.000  \n NA's   :114    \n\n\nDeux inconvénients à la fonction summary():\n\nNe donne pas l’écart-type\nLa disposition des résultats n’est pas très claire.\n\nOn peut utiliser la fonction describe() du package prettyR pour un résumé plus complet.\n\ndescribe(smp.d)\n\nDescription of smp.d \n\n\n\n Numeric \n                mean median    var    sd valid.n\nage            38.94     37 175.72 13.26     797\nnb.enfants      1.57      1   3.42  1.85     773\ndepression      0.39      0   0.24  0.49     799\nschizophrenie   0.08      0   0.07  0.27     799\ngravite         3.64      4   2.72  1.65     795\nrecherche.nouv  2.06      2   0.77  0.88     695\nevit.danger     1.87      2   0.76  0.87     691\ndep.recompense  2.15      2   0.69  0.83     685\n\n Factor \n          \nprofession ouvrier sans.emploi employé commerçant intermédiaire autre cadre\n   Count    228.00      221.00  136.00      91.00         57.00 31.00    24\n   Percent   28.54       27.66   17.02      11.39          7.13  3.88     3\n          \nprofession &lt;NA&gt; agriculteur\n   Count   6.00        5.00\n   Percent 0.75        0.63\nMode ouvrier",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Résumé statistique</span>"
    ]
  },
  {
    "objectID": "1_resume_statistique.html#principe",
    "href": "1_resume_statistique.html#principe",
    "title": "2  Résumé statistique",
    "section": "4.1 Principe",
    "text": "4.1 Principe\nDans un essai thérapeutique, il faut décrire es caractéristiques des patients inclus dans chaque groupe de traitement.\nIl faut donc les décrire en fonction de différentes modalités (groupes de traitement, sexe, âge, etc.)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Résumé statistique</span>"
    ]
  },
  {
    "objectID": "1_resume_statistique.html#dans-r",
    "href": "1_resume_statistique.html#dans-r",
    "title": "2  Résumé statistique",
    "section": "4.2 Dans R",
    "text": "4.2 Dans R\nOn peut aussi utiliser la fonction table() pour faire des tableaux de contingence.\n\ntable(\n    smp.d$profession, \n    smp.d$depression,\n    deparse.level=2, # deparse.level fait apparaître les noms des variables dans le tableau\n    useNA=\"ifany\")\n\n                smp.d$depression\nsmp.d$profession   0   1\n   agriculteur     3   2\n   commerçant     65  26\n   cadre          16   8\n   intermédiaire  31  26\n   employé        81  55\n   ouvrier       132  96\n   autre          22   9\n   sans.emploi   132  89\n   &lt;NA&gt;            4   2\n\n\nSi on voulait les pourcentages plutôt :\nLa fonction prop.table() permet de calculer des pourcentages à partir d’un tableau de contingence.\nL’option margin permet de choisir si on veut les pourcentages par ligne (margin=1) ou par colonne (margin=2).\n\noptions(digits=3) # pour afficher 3 décimales\nprop.table(\n    table(\n        smp.d$profession, \n        smp.d$depression,\n        deparse.level=2, # deparse.level fait apparaître les noms des variables dans le tableau\n        useNA=\"ifany\"),\n    margin=1) # margin=1 pourcentage par ligne ; margin=2 pourcentage par colonne\n\n                smp.d$depression\nsmp.d$profession     0     1\n   agriculteur   0.600 0.400\n   commerçant    0.714 0.286\n   cadre         0.667 0.333\n   intermédiaire 0.544 0.456\n   employé       0.596 0.404\n   ouvrier       0.579 0.421\n   autre         0.710 0.290\n   sans.emploi   0.597 0.403\n   &lt;NA&gt;          0.667 0.333\n\n\nMais encore une fois, je trouve personnellement que le top est d’utiliser tbl_summary du package gtsummary.\nIl va falloir me convaincre de ne pas utiliser ce banger absolu : je ne vois pas pourquoi.\nA la limite, pourquoi pas tableone aussi.\navec tableone : (fait des tests t pour les variables continues et Chi2 / Fisher pour les catégorielles par défaut)\n\nlibrary(tableone)\nvars &lt;- c(\"age\",\"profession\",\"nb.enfants\", \"gravite\",\"recherche.nouv\", \"evit.danger\",\"dep.recompense\")\ncatVars &lt;- c(\"profession\",\"gravite\",\"recherche.nouv\", \"evit.danger\",\"dep.recompense\")\ntable1 &lt;- CreateTableOne(vars = vars, data = smp.d, factorVars = catVars, strata = \"depression\")\nprint(table1, showAllLevels = TRUE, formatOptions = list(digits = 2))\n\n                        Stratified by depression\n                         level         0             1             p      test\n  n                                      486           313                    \n  age (mean (SD))                      39.93 (13.69) 37.41 (12.42)  0.009     \n  profession (%)         agriculteur       3 ( 0.6)      2 ( 0.6)   0.333     \n                         commerçant       65 (13.5)     26 ( 8.4)             \n                         cadre            16 ( 3.3)      8 ( 2.6)             \n                         intermédiaire    31 ( 6.4)     26 ( 8.4)             \n                         employé          81 (16.8)     55 (17.7)             \n                         ouvrier         132 (27.4)     96 (30.9)             \n                         autre            22 ( 4.6)      9 ( 2.9)             \n                         sans.emploi     132 (27.4)     89 (28.6)             \n  nb.enfants (mean (SD))                1.57 (1.92)   1.58 (1.73)   0.936     \n  gravite (%)            1               100 (20.7)      6 ( 1.9)  &lt;0.001     \n                         2               111 (23.0)     18 ( 5.8)             \n                         3                82 (17.0)     33 (10.5)             \n                         4                89 (18.5)     74 (23.6)             \n                         5                68 (14.1)    114 (36.4)             \n                         6                26 ( 5.4)     55 (17.6)             \n                         7                 6 ( 1.2)     13 ( 4.2)             \n  recherche.nouv (%)     1               168 (38.5)     81 (31.3)   0.005     \n                         2               107 (24.5)     50 (19.3)             \n                         3               161 (36.9)    128 (49.4)             \n  evit.danger (%)        1               229 (52.8)     86 (33.5)  &lt;0.001     \n                         2               109 (25.1)     45 (17.5)             \n                         3                96 (22.1)    126 (49.0)             \n  dep.recompense (%)     1               121 (28.1)     71 (28.0)  &lt;0.001     \n                         2               148 (34.3)     49 (19.3)             \n                         3               162 (37.6)    134 (52.8)             \n\n\navec gtsummary :\n\n(attention il a tendance à faire des tests de Wilcoxon par défaut pour les variables continues, il faut lui dire de faire des t-tests si on veut ça)\nPour les variables catégorielles, il fait par défaut des tests du Chi2 (ou Fisher si effectifs petits) donc autant ne pas lui donner d’instructions\n\n\n# utiliser smp.d.bis avec la variable depression en facteur recodé en \"Dépressif\" / \"Non dépressif\"\nsmp.d.bis &lt;- smp.d\nsmp.d.bis$depression &lt;- factor(smp.d.bis$depression, levels=c(0,1), labels=c(\"Non dépressif\",\"Dépressif\"))\n\ntableau &lt;- smp.d.bis %&gt;%\n    tbl_summary(\n        by = depression,\n        statistic = list(\n            all_continuous() ~ \"{mean} ({sd})\",\n            # all_continuous() ~ \"{median} [{p25}, {p75}]\",\n            all_categorical() ~ \"{n} / {N} ({p}%)\"\n            ),\n        digits = all_continuous() ~ 2,\n        missing = \"no\"\n        ) %&gt;%\n        modify_header(label = \"**Caractéristiques**\") %&gt;%\n        bold_labels() %&gt;%\n        add_overall() %&gt;%\n        add_p(\n            # test = list( (rajouter si tests spécifiques pr les 2)\n            all_continuous()  ~ \"t.test\" # ou \"wilcox.test\" pour test non paramétrique \n            # all_categorical() ~ \"chisq.test\" # ou \"fisher.test\" si effectifs petits\n            )\n# ajouter les p-values pour les comparaisons entre groupes\n\nJuste un peu chiant pour avoir un bel affichage en pdf mais franchement…\ntableau %&gt;%\n    # Conversion en objet kable (LaTeX standard)\n    as_kable_extra(booktabs = TRUE, longtable = TRUE) %&gt;%\n    kableExtra::column_spec(1, width = \"6cm\") %&gt;%\n    # (Optionnel) Ajuste la taille de la police si le tableau est encore trop large\n    kableExtra::kable_styling(latex_options = c(\"repeat_header\"), font_size = 9)\n\n\n\n\n\n\n\n\n\n\nCaractéristiques\nOverall\nN = 799\nNon dépressif\nN = 486\nDépressif\nN = 313\np-value\n\n\n\n\nage\n38.94 (13.26)\n39.93 (13.69)\n37.41 (12.42)\n0.007\n\n\nprofession\n\n\n\n\n\n\nagriculteur\n5 / 793 (0.6%)\n3 / 482 (0.6%)\n2 / 311 (0.6%)\n\n\n\ncommerçant\n91 / 793 (11%)\n65 / 482 (13%)\n26 / 311 (8.4%)\n\n\n\ncadre\n24 / 793 (3.0%)\n16 / 482 (3.3%)\n8 / 311 (2.6%)\n\n\n\nintermédiaire\n57 / 793 (7.2%)\n31 / 482 (6.4%)\n26 / 311 (8.4%)\n\n\n\nemployé\n136 / 793 (17%)\n81 / 482 (17%)\n55 / 311 (18%)\n\n\n\nouvrier\n228 / 793 (29%)\n132 / 482 (27%)\n96 / 311 (31%)\n\n\n\nautre\n31 / 793 (3.9%)\n22 / 482 (4.6%)\n9 / 311 (2.9%)\n\n\n\nsans.emploi\n221 / 793 (28%)\n132 / 482 (27%)\n89 / 311 (29%)\n\n\n\nnb.enfants\n1.57 (1.85)\n1.57 (1.92)\n1.58 (1.73)\n&gt;0.9\n\n\nschizophrenie\n64 / 799 (8.0%)\n29 / 486 (6.0%)\n35 / 313 (11%)\n0.008\n\n\ngravite\n\n\n\n&lt;0.001\n\n\n1\n106 / 795 (13%)\n100 / 482 (21%)\n6 / 313 (1.9%)\n\n\n\n2\n129 / 795 (16%)\n111 / 482 (23%)\n18 / 313 (5.8%)\n\n\n\n3\n115 / 795 (14%)\n82 / 482 (17%)\n33 / 313 (11%)\n\n\n\n4\n163 / 795 (21%)\n89 / 482 (18%)\n74 / 313 (24%)\n\n\n\n5\n182 / 795 (23%)\n68 / 482 (14%)\n114 / 313 (36%)\n\n\n\n6\n81 / 795 (10%)\n26 / 482 (5.4%)\n55 / 313 (18%)\n\n\n\n7\n19 / 795 (2.4%)\n6 / 482 (1.2%)\n13 / 313 (4.2%)\n\n\n\nrecherche.nouv\n\n\n\n0.005\n\n\n1\n249 / 695 (36%)\n168 / 436 (39%)\n81 / 259 (31%)\n\n\n\n2\n157 / 695 (23%)\n107 / 436 (25%)\n50 / 259 (19%)\n\n\n\n3\n289 / 695 (42%)\n161 / 436 (37%)\n128 / 259 (49%)\n\n\n\nevit.danger\n\n\n\n&lt;0.001\n\n\n1\n315 / 691 (46%)\n229 / 434 (53%)\n86 / 257 (33%)\n\n\n\n2\n154 / 691 (22%)\n109 / 434 (25%)\n45 / 257 (18%)\n\n\n\n3\n222 / 691 (32%)\n96 / 434 (22%)\n126 / 257 (49%)\n\n\n\ndep.recompense\n\n\n\n&lt;0.001\n\n\n1\n192 / 685 (28%)\n121 / 431 (28%)\n71 / 254 (28%)\n\n\n\n2\n197 / 685 (29%)\n148 / 431 (34%)\n49 / 254 (19%)\n\n\n\n3\n296 / 685 (43%)\n162 / 431 (38%)\n134 / 254 (53%)\n\n\n\n\n1 Mean (SD); n / N (%)\n\n\n\n\n\n\n2 Welch Two Sample t-test; NA; Pearson's Chi-squared test",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Résumé statistique</span>"
    ]
  },
  {
    "objectID": "1_resume_statistique.html#variables-quantitatives",
    "href": "1_resume_statistique.html#variables-quantitatives",
    "title": "2  Résumé statistique",
    "section": "5.1 Variables quantitatives",
    "text": "5.1 Variables quantitatives\n3 types de liaisons entre variables quantitatives :\n\nDépendance : connaître X permet de mieux estimer Y (par exemple tabac et maladie respiratoire, taille et poids, etc.)\nDépendance monotone : X et Y varient dans le même sens (par exemple âge et pression artérielle)\n\nDépendance linéaire : relation linéaire entre X et Y (par exemple taille et poids chez les adultes)\nCorrélation\nVariance partagée = proportion de la variance de Y expliquée par X dans une relation linéaire entre les deux variables\n\nConcordance : si X est plus grand pour un individu que pour un autre, alors Y est aussi plus grand pour le premier individu (par exemple taille et poids)\n\npour une variable quantitative : coefficient de corrélation intraclasse (ICC)\n\n\n\n5.1.1 Dépendance\nIl n’existe pas de paramètre estimant parfaitement la dépendance ou l’indépendance entre deux variables quantitatives.\nL’idéal serait d’avoir un paramètre \\(\\delta(X,Y)\\) valant 0 quand X et Y sont indépendantes et 1 quand elles sont parfaitement dépendantes.\n\n\n5.1.2 Dépendance monotone ou linéaire\nLe coefficient de corrélation de Pearson \\(r\\) mesure la dépendance linéaire entre deux variables quantitatives X et Y.\nIl est désigné par les lettres \\(r\\) ou \\(\\rho\\) (rho), en référence à Karl Pearson qui l’a introduit en 1895.\nIl varie entre -1 (les deux variables \\(X\\) et \\(Y\\) sont parfaitement linéairement dépendantes de façon négative) et +1 (les deux variables \\(X\\) et \\(Y\\) sont parfaitement linéairement dépendantes de façon positive).\nCorrélaton nulle (\\(r=0\\)) signifie que les deux variables sont linéairement indépendantes.\nNB : le coefficient ne matérialise pas la force de la dépendance, mais seulement son type !\nPour matérialiser la force de la relation, on utilise le coefficient de détermination \\(r^2\\).\nLe paramètre \\(r^2\\) représente approximativement la proportion de la variance de \\(Y\\) expliquée par la variance de \\(X\\) dans une relation linéaire entre les deux variables.\nC’est à dire :\n\n\\(X\\) est le nombre d’heures de révision\n\\(Y\\) est la note obtenue à un examen\n\nOn trouve un coefficent de corrélation \\(r=0.8\\) entre \\(X\\) et \\(Y\\), alors \\(r^2=0.64\\) soit 64%.\nDonc : 64% de la variabilité (de la variance) des notes \\(Y\\) s’expliquer par le le modèle linéaire basé sur le nombre d’heures de révision \\(X\\).\nCe n’est pas la même chose que “\\(r^2\\)% des notes s’expliquent par le nombre d’heures de révision”.\n\n\n\n\n\n\nImportant\n\n\n\nCoefficient de corrélation \\(r\\) :\n\nmesure la direction de la relation linéaire entre deux variables quantitatives.\nvarie entre -1 et +1 (avec 0 = pas de relation linéaire).\nen pratique : mesure un peu la force quand même… mais il n’y a pas vraiment d’unité pour l’exprimer\n\n\nCoefficient de détermination \\(r^2\\) :*\n\nmesure la force de la relation linéaire entre deux variables quantitatives avec une unité (en % de variance expliquée)\nvarie entre 0 et 1 (avec 0 = pas de relation linéaire).\nreprésente la proportion de la variance de \\(Y\\) expliquée par la variance de \\(X\\) (et non pas le pourcentage de valeurs de \\(Y\\) expliquées par \\(X\\)).\n\n\n\n\n5.1.2.1 Exemple sur R\n\n5.1.2.1.1 SMP\nReprésentation graphique de la relation entre l’âge et le nombre d’enfants dans le jeu de données smp.\n\nplot(smp$age, smp$nb.enfants,\n        xlab=\"Âge\",\n        ylab=\"Nombre d'enfants\",\n        main=\"Relation entre l'âge et le nombre d'enfants\",\n        pch=19) # pch = sert à choisir le type de point\n\n\n\n\n\n\n\n\nCalcul du coefficient de corrélation de Pearson entre l’âge et le nombre d’enfants.\n\ncor(\n    smp$age, \n    smp$nb.enfants, \n    use=\"complete.obs\") # ignore les valeurs manquantes\n\n[1] 0.498\n\n\nLe coefficient de corrélation est de 0.498, ce qui indique une dépendance linéaire positive entre l’âge et le nombre d’enfants.\n\n\n5.1.2.1.2 Données simulées\n\nset.seed(20230430)\nx &lt;- rnorm(100000) # génère 100000 valeurs aléatoires suivant une loi normale\ny &lt;- rnorm(100000)\nz &lt;- rnorm(100000)\nX1 &lt;- c(x,y) # concatène les deux vecteurs x et y\nX2 &lt;- c(x,z)\n\nReprésentation graphique de la relation entre X1 et X2.\n\nplot(X1, X2,\n        xlab=\"X1\",\n        ylab=\"X2\",\n        main=\"Relation entre X1 et X2\",\n        pch=19) \n\n\n\n\n\n\n\n\nCoorélation entre X1 et X2.\n\nround(cor(X1, X2),3)\n\n[1] 0.498\n\n\nVariance de X1 :\n\nround(var(X1),3)\n\n[1] 1\n\n\nlogique ce soit = 1 car X1 est la concaténation de deux variables indépendantes de variance 1 (car générées par rnorm donc suivent une loi normale standard).\nPour calculer la variance partagée entre X1 et X2, on utilise la formule de la variance de la somme de deux variables aléatoires indépendantes :\n\\[\nVar(X1 + X2) = Var(X1) + Var(X2) + 2Cov(X1, X2)\n\\]\nSur R :\n\n# corrélation de Pearson mise au carrée donne la part de variance partagée\nrho2  &lt;- (cor(X1, X2)^2)\nrho2\n\n[1] 0.248\n\n\nUne autre manière d’obtenir ça :\n\nConstruire un modèle linéaire de \\(Y\\) en fonction de \\(X\\)\nExtraire la part de variance résiduelle (non expliquée par \\(X\\)) du modèle\nVariance expliquée par \\(X\\) = 1 - variance résiduelle\n\n(mais summary(lm()) donne directement le R² dans la partie “Multiple R-squared”)\n\nres &lt;- lm(X1 ~ X2)\n# summary donne l'info dans \"Multiple R-squared\"\nsummary(res)\n\n\nCall:\nlm(formula = X1 ~ X2)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-5.079 -0.487 -0.001  0.486  4.867 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.00361    0.00194    1.86    0.063 .  \nX2           0.49770    0.00194  256.59   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.868 on 199998 degrees of freedom\nMultiple R-squared:  0.248, Adjusted R-squared:  0.248 \nF-statistic: 6.58e+04 on 1 and 2e+05 DF,  p-value: &lt;2e-16\n\n# variance résiduelle\nround(var(residuals(res)),3) \n\n[1] 0.754\n\n# variance expliquée par X2\n1 - round(var(residuals(res)),3) \n\n[1] 0.246\n\n\n\n\n\n\n\n\nImportant\n\n\n\nNB : la variance partagée n’est pas la même chose que la covariance !!\nCovariance = mesure comment deux variables varient ensemble, positive si les deux variables augmentent ensemble, négative si l’une augmente quand l’autre diminue.\n\n\n\n\n\n\n\n\n\n\nParamètre\nSymbole\nInterprétation\nFormule / calcul R\n\n\n\n\nCoefficient de corrélation\n\\(r\\) ou \\(\\rho\\)\nDirection et force de la relation linéaire entre deux variables quantitatives\ncor(X, Y)\n\n\nVariance partagée\n\\(r^2\\)\nProportion de la variance de \\(Y\\) expliquée par \\(X\\) (force de la relation linéaire)\nrho2 &lt;- cor(X, Y)^2\n\n\nCovariance\n\\(\\mathrm{Cov}(X,Y)\\)\nMesure comment deux variables varient ensemble (positive : ensemble, négative : sens inverse)\ncov(X, Y)\n\n\n\n\n\n\n\n5.1.2.1.3 Matrice de corrélation\nPour calculer la matrice de corrélation entre plusieurs variables quantitatives, on peut utiliser la fonction cor() en lui passant un data frame ou une matrice.\n\nquanti &lt;- c(\"age\",\"nb.enfants\",\"depression\",\"schizophrenie\", \"gravite\",\"recherche.nouv\",\"evit.danger\",\"dep.recompense\")\nround(cor(smp.d[,quanti],use=\"pairwise.complete.obs\"),digits=3)\n\n                  age nb.enfants depression schizophrenie gravite\nage             1.000      0.498     -0.093        -0.021  -0.127\nnb.enfants      0.498      1.000      0.003        -0.003  -0.057\ndepression     -0.093      0.003      1.000         0.094   0.454\nschizophrenie  -0.021     -0.003      0.094         1.000   0.318\ngravite        -0.127     -0.057      0.454         0.318   1.000\nrecherche.nouv -0.223     -0.159      0.109         0.022   0.154\nevit.danger    -0.027      0.004      0.256         0.081   0.230\ndep.recompense -0.001     -0.023      0.089        -0.004   0.019\n               recherche.nouv evit.danger dep.recompense\nage                    -0.223      -0.027         -0.001\nnb.enfants             -0.159       0.004         -0.023\ndepression              0.109       0.256          0.089\nschizophrenie           0.022       0.081         -0.004\ngravite                 0.154       0.230          0.019\nrecherche.nouv          1.000       0.081          0.071\nevit.danger             0.081       1.000          0.119\ndep.recompense          0.071       0.119          1.000\n\n\nOn peut représenter ça graphiquement avec la fonction corrplot() du package corrplot.\n\nlibrary(corrplot)\n\ncorrplot 0.95 loaded\n\ncorrplot(\n    round(cor(smp.d[,quanti],use=\"pairwise.complete.obs\"),digits=3),\n    method=\"circle\",\n    addCoef.col = \"red\",\n    type=\"upper\",\n    tl.col=\"black\",\n    tl.srt=45)\n\n\n\n\n\n\n\n\nUne matrice de corrélation est symétrique (mêmes valeurs de part et d’autre de la diagonale), car la corrélation entre \\(X\\) et \\(Y\\) est la même que celle entre \\(Y\\) et \\(X\\).\n\n\n\n\n\n\nNote\n\n\n\nA quoi ça peut servir dans une étude rétropective ?\nDans une étude qui compare 2 techniques chirurgicales (A vs B), la matrice de corrélation sert surtout à explorer et comprendre les relations entre les nombreuses variables mesurées autour de l’intervention.\n\nExplorer les facteurs pré-opératoires entre eux (âge corrélé au score ASA, etc.)\nRepérer la colinéarité entre co-variables avant une régression ajustée\nRelier facteurs pré-op et outcomes post-op (âge, IMC, ASA vs durée d’hospitalisation, perte sanguine, etc.)\n\nNotamment selon le type de chirurgie (groupe A vs groupe B) : est ce que les plus vieux ont plus de perte sanguine avec la technique A que B ?\n\n\n\n\n\n\n\n\n5.1.3 Concordance\n\n5.1.3.1 Principle\nPar exemple, “concordance” entre deux échographies identiques fait par deux médecins différents.\nVariables quantitiatives : concordance mesurée par le coefficient de corrélation intraclasse (ICC).\n\nICC varie entre 0 (pas de concordance) et 1 (concordance parfaite).\nDans l’exemple du score échographique, le coefficient de corrélation intraclasse =\n\n\\[\n\\frac{\\text{variance inter-patients}}{\\text{variance inter-patients} + \\text{variance inter-radiologues} + \\text{variance résiduelle}}\n\\]\nDonc en gros : ICC = “vrai signal” / (“vrai signal” + “bruit”)\nVaut 1 quand il n’y a aucun bruit (variance inter-radiologues et résiduelle = 0).\nVaut 0 quand il n’y a que de bruit, donc les mesures sont totalement indépendantes entre elles.\n\n\n5.1.3.2 Exemple sur R\nDans l’étude smp, 2 cliniciens sont présentés lors des entretiens : un junior et un senior.\nA la fin de chaque entretien, ils remplissaient plusieurs questionnaires, dont un comportait l’échelle CGI = Clinical Global Impression (échelle de 1 à 7, 1 = pas malade, 7 = très malade).\nIl est possible de quantifier le niveau de concordance entre les notes CGI données par le junior et le senior à l’aide du coefficient de corrélation intraclasse (ICC).\nDans ce cas : il s’agit d’un ICC de type “2-way random effects, absolute agreement, single rater/measurement” (notation ICC(2,1) de Shrout & Fleiss, 1979).\n\n2-way random effects : les deux évaluateurs (junior et senior) sont considérés comme des échantillons aléatoires d’une population plus large d’évaluateurs possibles.\nAbsolute agreement : on s’intéresse à l’accord absolu entre les évaluateurs, pas seulement à la corrélation.\nSingle rater/measurement : on considère les notes individuelles de chaque évaluateur, pas une moyenne.\n\nC’est le type d’ICC le plus couramment utilisé en pratique clinique.\n\npsy::icc(\n    smp.aij[,c(\"gravite.jun\",\"gravite.sen\")]\n)\n\n$nb.subjects\n[1] 796\n\n$nb.raters\n[1] 2\n\n$subject.variance\n[1] 2.4\n\n$rater.variance\n[1] -0.000228\n\n$residual\n[1] 0.257\n\n$icc.consistency\n[1] 0.903\n\n$icc.agreement\n[1] 0.903\n\n\n\n$subject.variance : variance sujets = variance signal\n$rater.variance : variance évaluateurs = variance bruit due aux différences entre évaluateurs\n$residual : variance résiduelle = variance bruit due aux autres sources d’erreur\n$icc.agreement : coefficient de corrélation intraclasse ICC vaut 0,9\n\nMais la librarie irr propose aussi une fonction icc() pour calculer le coefficient de corrélation intraclasse, il faut juste la paramétrer un peu plus mais l’output est plus clair.\n\nlibrary(irr)\n\nLoading required package: lpSolve\n\n\n\nAttaching package: 'irr'\n\n\nThe following object is masked from 'package:psy':\n\n    icc\n\nirr::icc(\n    smp.aij[,c(\"gravite.jun\",\"gravite.sen\")],\n    model=\"twoway\", # sinon oneway si un seul évaluateur par sujet\n    type=\"agreement\", # sinon consistency = uniformité des réponses\n    unit=\"single\" # single ou average\n)\n\n Single Score Intraclass Correlation\n\n   Model: twoway \n   Type : agreement \n\n   Subjects = 796 \n     Raters = 2 \n   ICC(A,1) = 0.903\n\n F-Test, H0: r0 = 0 ; H1: r0 &gt; 0 \n F(795,795) = 19.7 , p = 5.62e-295 \n\n 95%-Confidence Interval for ICC Population Values:\n  0.89 &lt; ICC &lt; 0.915\n\n\n\n\n\n\n5.1.4 Résumé des paramètres de dépendance entre deux variables quantitatives\nRésumé des principaux paramètres de dépendance entre deux variables quantitatives :\n\nDépendance\nDépendance monotone ou linéaire\n\nCoefficient de corrélation de Pearson\nCoefficient de détermination = variance partagée (≠ covariance)\n\nConcordance = coefficient de corrélation intraclasse (ICC)\n\n\n\n\n\n\n\n\n\n\n\nParamètre\nSymbole\nInterprétation\nFormule / calcul R\n\n\n\n\nCoefficient de corrélation\n\\(r\\) ou \\(\\rho\\)\nDirection et force de la relation linéaire entre deux variables quantitatives\ncor(X, Y)\n\n\nVariance partagée\n\\(r^2\\)\nProportion de la variance de \\(Y\\) expliquée par \\(X\\) (force de la relation linéaire)\nrho2 &lt;- cor(X, Y)^2\n\n\nCovariance\n\\(\\mathrm{Cov}(X,Y)\\)\nMesure comment deux variables varient ensemble (positive : ensemble, négative : sens inverse)\ncov(X, Y)\n\n\nCoefficient de corrélation intraclasse\nICC\nMesure la concordance entre plusieurs mesures quantitatives\npsy::icc(dataframe) ou irr::icc(dataframe, model=..., type=..., unit=...)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Résumé statistique</span>"
    ]
  },
  {
    "objectID": "1_resume_statistique.html#variables-catégorielles",
    "href": "1_resume_statistique.html#variables-catégorielles",
    "title": "2  Résumé statistique",
    "section": "5.2 Variables catégorielles",
    "text": "5.2 Variables catégorielles\n\n5.2.1 Dépendance\n\n5.2.1.1 Chi2 et associés\n\nExiste-t-il une relation entre les deux variables catégorielles ?\nSi oui, quelle est la force de cette relation ?\n\nPour ces questions : on utilise\n\nLe test du Chi2 d’indépendance sert à évaluer l’existence d’une relation entre deux variables catégorielles.\n\nEt des transformations normalisées du Chi2 pour évaluer la force de cette relation :\n(pour normaliser le Chi2 : racine carré de chi2/nombre d’observations)\n\nLe V de Cramer pour la force de l’association entre deux variables catégorielles non ordonnées (type de chirurgie) (= on pourrait utiliser le coefficient de Pearson pour des variables binaires).\n\nVarie entre 0 (pas d’association) et 1 (association parfaite)\n\nLe coefficient de Pearson : plutôt pour variables quantitatives, mais utilisable pour des variables binaires (0/1)\n\nVarie entre -1 et +1\n\nLe coefficient de Spearman : pour variables ordinales ou quantitatives non linéaires (rangées)\n\nCoefficient de Spearman = corrélation de Pearson calculée sur les rangs des données\nVarie entre -1 et +1\n\n\n\n\n\n\n\n\nNote\n\n\n\nANOVA ou V de Cramer pour variables catégorielles non ordonnées ?\n\nANOVA :\n\n1 variable quantitative, 1 ou plusieurs variables catégorielles non ordonnées\ncompare les moyennes de la variable quantitative entre les différentes modalités de la variable catégorielle\ntest statistique (p-value)\noutcome quantitatif\n\nV de Cramer :\n\nVariables catégorielles non ordonnées\nmesure la force de l’association entre les variables\nvaleur entre 0 et 1\noutcome catégoriel\n\n\n\n\n\n\n5.2.1.2 Odds-ratio et risque relatif\nPour des X et Y binaires (0/1) :\nExemple : association entre décès en USI et existence d’une infection ou non\n\n\n\n\nDécès (Y=1)\nPas de décès (Y=0)\n\n\n\n\nInfection (X=1)\na\nb\n\n\nPas d’infection(X=0)\nc\nd\n\n\n\n\nRisque relatif (RR) = risque de décès chez les patients infectés / risque de décès chez les patients non infectés = [a/(a+b)] / [c/(c+d)]\n\nOn a RR fois plus de risque de décès si on est infecté\n\\(RR = \\frac{\\text{\\% de deces chez les infectes}}{\\text{\\% de deces chez les non infectes}} = \\frac{a}{a+b} / \\frac{c}{c+d}\\)\n\nOdds-ratio (OR) = rapports des côtes = interprétation plus subtile\n\nOdds de décès chez les patients infectés = a/b (côte)\nOdds de décès chez les patients non infectés = c/d\n\\(OR = \\frac{\\dfrac{\\text{morts infectes}}{\\text{vivants infectes}}}{\\dfrac{\\text{morts non infectes}}{\\text{vivants non infectes}}} = \\frac{\\frac{a}{b}}{\\frac{c}{d}} = \\frac{a \\times d}{b \\times c}\\)\nIl y a OR fois plus de “morts par rapport aux vivants” si on est infecté que de “morts par rapport aux vivants” si on n’est pas infecté.\n\n\nRR et OR sont positifs et varient de 0 à l’infini.\nS’ils valent 1 : pas d’association entre X et Y, les variables sont indépendantes.\nS’ils valent 0 ou sont très grands : forte association entre X et Y.\nRapport entre RR et OR :\n\nSi l’événement étudié est rare (&lt;10%) : RR ≈ OR\nSi l’événement est fréquent (&gt;10%) : OR surestime le RR (OR &gt; RR si RR &gt; 1 ; OR &lt; RR si RR &lt; 1)\n\n\n\n5.2.1.3 Exemple sur R\nSur fichier smp.d : force de l’association entre la variable “dépression” (smp.d$depression) et le FDR “le prisonnier a un niveau élevé d’évitement du danger” (smp.d$evit.danger).\nLa variable dépression est binaire (0 = non dépressif, 1 = dépressif).\nLa variable evit.danger n’est pas binaire, mais codée 1, 2 ou 3 pour “faible”, “moyen” ou “élevé”.\nIl faut donc la recoder en binaire (0 = faible ou moyen, 1 = élevé).\n\nsmp.d$evit.danger.b &lt;- smp.d$evit.danger &gt; 2\nsmp.d$depression.b &lt;- smp.d$depression == 1\ntb &lt;- table(\n        smp.d$depression.b, \n        smp.d$evit.danger.b, \n        deparse.level=2\n        )\ntb\n\n                  smp.d$evit.danger.b\nsmp.d$depression.b FALSE TRUE\n             FALSE   338   96\n             TRUE    131  126\n\n\nPour obtenir facilement le RR et l’OR, on peut utiliser la fonction epi.2by2() du package epiR.\n\nepi.2by2(\n    tb,\n    method=\"cohort.count\", # sinon case.control\n    conf.level=0.95\n    )\n\n             Outcome+    Outcome-      Total                 Inc risk *\nExposure+         338          96        434     77.88 (73.68 to 81.70)\nExposure-         131         126        257     50.97 (44.69 to 57.24)\nTotal             469         222        691     67.87 (64.25 to 71.34)\n\nPoint estimates and 95% CIs:\n-------------------------------------------------------------------\nInc risk ratio                                 1.53 (1.34, 1.74)\nInc odds ratio                                 3.39 (2.43, 4.73)\nAttrib risk in the exposed *                   26.91 (19.65, 34.16)\nAttrib fraction in the exposed (%)            34.55 (25.88, 42.85)\nAttrib risk in the population *                16.90 (9.87, 23.93)\nAttrib fraction in the population (%)         24.90 (19.77, 30.45)\n-------------------------------------------------------------------\nUncorrected chi2 test that OR = 1: chi2(1) = 53.594 Pr&gt;chi2 = &lt;0.001\nFisher exact test that OR = 1: Pr&gt;chi2 = &lt;0.001\n Wald confidence limits\n CI: confidence interval\n * Outcomes per 100 population units \n\n\n\n\n\n5.2.2 Dépendance monotone\nUne dépendance monotone ne peut s’envisager qu’entre des variables ordinales (rangées) ou entre une variable ordinale et une variable quantitative.\n\nCoefficient de Spearman : corrélation de Pearson calculée sur les rangs des données.\n\nVarie entre -1 et +1\nUtilisable pour des variables ordinales (rangées) ou quantitatives non linéaires\n\n\nProblème : donner du sens à une corrélation basée sur des rangs !! dépend ++ du codage\n\n5.2.2.1 Exemple sur R\nEn pratique : dans l’étude santé mentale en prison, les deux variables de tempérament : « recherche de nouveauté » et « évitement du danger » sont codées en 1, 2 et 3 pour, respectivement, « bas », « moyen » et « élevé ». Si l’on souhaite apprécier dans quelle mesure un niveau élevé de recherche de nouveauté est associé à un niveau bas d’évitement du danger, il est possible d’estimer un coefficient de corrélation de Spearman ou de Pearson :\nDans l’étude smp : variable “recherche de nouveauté” (smp.d$recherche.nouv) et variable “évitement du danger” (smp.d$evit.danger).\n\nles deux variables recherche.nouv et evit.danger sont codées 1, 2 ou 3 pour “faible”, “moyen” ou “élevé”.\nobjectif : apprécier dans quelle mesure un niveau élevé de recherche de nouveauté est associé à un niveau bas d’évitement du danger.\n\n\ntable(smp$recherche.nouv)\n\n\n  1   2   3 \n249 157 289 \n\ntable(smp$evit.danger)\n\n\n  1   2   3 \n315 154 222 \n\n\nCalcul du coefficient de corrélation de Spearman entre les deux variables.\n\ncor(\n    smp.d$recherche.nouv, \n    smp.d$evit.danger, \n    method=\"spearman\",\n    use=\"complete.obs\") # ignore les valeurs manquantes\n\n[1] 0.0785\n\n\nLe coefficient de corrélation de Spearman est de 0.078, ce qui indique une très faible dépendance monotone positive entre la recherche de nouveauté et l’évitement du danger.\nNB : si on avait utilisé le coefficient de Pearson :\n\ncor(\n    smp.d$recherche.nouv, \n    smp.d$evit.danger, \n    method=\"pearson\",\n    use=\"complete.obs\") # ignore les valeurs manquantes\n\n[1] 0.0807\n\n\nLe coefficient de corrélation de Pearson est de 0.081 : les deux coefficients sont très proches (c’est assez fréquent quand les variables sont ordinales avec peu de modalités).\n\n\n\n5.2.3 Concordance\n\n5.2.3.1 Coefficient kappa de Cohen\nPour les variables catégorielles, on pourrait se dire que mesurer à quel point 2 variables s’accordent reviendraient à compter la proportion de fois ou elles ont la même valeur.\nProblème : cette proportion de concordance peut être due au hasard !!\nOn corrige ça avec le kappa de Cohen.\n\n\\[\n\\text{kappa} = \\frac{\\text{concordance observee - concordance due au hasard}}{1 - \\text{concordance due au hasard}}\n\\]\n\n\\(\\text{kappa} = 0\\) : concordance observée = concordance due au hasard\n\\(\\text{kappa} = 1\\) : concordance parfaite\n\n\n\n5.2.3.2 Sensibilité, spécificité, VPP, VPN\nLe kappa de Cohen mesure une concordance globale et symétrique entre deux variables catégorielles.\nMais parfois, on s’intéresse à la capacité d’une variable à s’approcher d’ue variable de référence\n= mesurer à quel point \\(Y\\) prédit correctement \\(X\\).\nDans ce cas, il vaut mieux utiliser des paramètres asymétriques :\n\nSensibilité = proportion de vrais positifs parmi les positifs réels = \\(P(Y=1|X=1)\\)\nSpécificité = proportion de vrais négatifs parmi les négatifs réels = \\(P(Y=0|X=0)\\)\n\nLe problème avec la sensibilité et la spécificité : elles ne tiennent pas compte de la prévalence de la condition réelle \\(X\\) (c’est à dire la proportion de \\(X=1\\) dans la population).\n\nValeur prédictive positive (VPP) = proportion de vrais positifs parmi les positifs prédits = \\(P(X=1|Y=1)\\)\nValeur prédictive négative (VPN) = proportion de vrais négatifs parmi les négatifs prédits = \\(P(X=0|Y=0)\\)\n\nDans un tableau de contingence :\n\n\n\n\n\n\n\n\n\nY=1 (test positif)\nY=0 (test négatif)\n\n\n\n\nX=1 (condition réelle présente)\na (vrais positifs)\nb (faux négatifs)\n\n\nX=0 (condition réelle absente)\nc (faux positifs)\nd (vrais négatifs)\n\n\n\n\nSensibilité = a / (a + b)\nSpécificité = d / (c + d)\nValeur prédictive positive (VPP) = a / (a + c)\nValeur prédictive négative (VPN) = d / (b + d)\n\nOn peut ainsi représenter une courbe ROC (Receiver Operating Characteristic) qui trace la sensibilité en fonction de 1 - spécificité pour différents seuils de décision.\n\n5.2.3.2.1 Exemple 1 sur R\n\nLes deux cliniciens (junior et senior) posent un diagnostic de schizophrénie (1 = oui, 0 = non) pour chaque patient.\nNiveau d’accord inter-juges pour une variable catégorielle : kappa de Cohen.\n\n\npsy::ckappa(\n    smp.aij[,c(\"scz.jun\",\"scz.sen\")]\n)\n\n$table\n    0  1\n0 715 11\n1  30 43\n\n$kappa\n[1] 0.65\n\n\nAutre méthode avec le package irr :\n\nirr::kappa2(\n    smp.aij[,c(\"scz.jun\",\"scz.sen\")],\n    weight=\"unweighted\" # ou \"equal\" ou \"squared\" pour kappa pondéré\n)\n\n Cohen's Kappa for 2 Raters (Weights: unweighted)\n\n Subjects = 799 \n   Raters = 2 \n    Kappa = 0.65 \n\n        z = 18.6 \n  p-value = 0 \n\n\nLe clinicien junior a posé le diagnostic de schizophrénie chez 30 + 43 = 73 détenus alors que le clinicien senior l’a fait pour seulement 11 + 43 = 54.\nAu total, le coefficient kappa vaut 0,65.\n\n\n5.2.3.2.2 Exemple 2 sur R\n\nÉtude sur 244 patients déprimés hospitalisés : tâche de lecture de texte puis comptage de 1 à 10, enregistrement voix.\nExtraction de la fréquence fondamentale (hauteur de voix), connue pour être ~75–140 Hz chez les hommes et ~170–250 Hz chez les femmes.\nObjectif : voir dans quelle mesure la hauteur de voix prédit le sexe en testant un seuil de 155 Hz.\nMéthode : calcul sensibilité et spécificité du seuil 155 Hz pour discriminer hommes et femmes.\n\n\nsexe.f &lt;- vox$sexe == 2\nvoix.aigue &lt;- vox$moyf0&gt;155\n# moyenne des femmes avec voix aiguë = sensibilité\n# = proportion de femmes avec test positif\nmean(voix.aigue[sexe.f], na.rm=TRUE) \n\n[1] 0.917\n\n# moyenne des hommes sans voix aiguë = spécificité \n# = proportion d'hommes avec test négatif\nmean(!voix.aigue[!sexe.f], na.rm=TRUE) \n\n[1] 0.933\n\n\nVérifier le seuil de 155 Hz avec une courbe ROC :\n\nrocf0 &lt;- roc(sexe.f~vox$moyf0)\n\nSetting levels: control = FALSE, case = TRUE\n\n\nSetting direction: controls &lt; cases\n\nplot(rocf0, \n    main=\"Courbe ROC pour la hauteur de voix\",\n    print.thres=\"best\",\n    print.thres.best.method=\"youden\",\n    print.auc=TRUE)\n\n\n\n\n\n\n\n\nSeuil optimal calculé par indice de Youden (maximise la somme de la sensibilité et de la spécificité) = 158,17 Hz\nAUC : calcule la qualité globale du test\n\nAire comprise entre 0 et 1\n= probabilité que la hauteur de voix d’une femme soit plus élevée que celle d’un homme pris au hasard",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Résumé statistique</span>"
    ]
  },
  {
    "objectID": "6_effet_centre.html",
    "href": "6_effet_centre.html",
    "title": "3  6 Effet centre",
    "section": "",
    "text": "4 Introduction\nLes mesures répétées désignent des situations où plusieurs observations sont recueillies sur une même unité statistique (souvent un patient) au cours du temps, ou lorsque les observations sont regroupées au sein de clusters (par exemple, des patients au sein d’un même hôpital ou des membres d’une même famille).\nLe défi majeur posé par ces données réside dans la non-indépendance des observations.\nEn effet, les mesures effectuées sur un même patient à différents moments sont généralement corrélées entre elles.\nIgnorer cette corrélation en utilisant des méthodes statistiques classiques (comme la régression linéaire standard ou l’ANOVA classique) viole l’hypothèse d’indépendance des résidus, conduisant à des estimations biaisées de la précision (intervalles de confiance trop étroits) et à une augmentation du risque d’erreur de type I.\nSi l’analyse est relativement simple avec seulement deux points de mesure (analyse de l’évolution \\(Y_{après} - Y_{avant}\\) ou ajustement sur la valeur basale), elle devient plus complexe avec trois mesures ou plus.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>6 Effet centre</span>"
    ]
  },
  {
    "objectID": "6_effet_centre.html#analyse-naïve-sans-prise-en-compte-du-centre",
    "href": "6_effet_centre.html#analyse-naïve-sans-prise-en-compte-du-centre",
    "title": "3  6 Effet centre",
    "section": "5.1 Analyse naïve sans prise en compte du centre",
    "text": "5.1 Analyse naïve sans prise en compte du centre\nImaginons qu’on néglige l’effet centre et qu’on réalise une régression linéaire simple de \\(Y\\) en fonction de \\(X\\)..\nOn prend 3 centres comprenanant chacun 9 détenus.\n\n\n\nEstimation d’une corrélation entre « durée de l’entretien » et «score de dépression » sans tenir compte de l’effet centre (ici un centre par couleur). La droite de régression minimise la somme des \\(\\varepsilon_i^2\\) et néglige l’effet centre.\n\n\nIci :\n\nEffet centre particulièrement important\nChaque centre semble associé à un niveau spécifique de dépression \\(\\hat{X}\\)\nEt à un niveau moyen spécifique de durée d’entretien \\(\\hat{Y}\\)\n\n\n5.1.1 Problèmes posés par cette analyse naïve\n= biais de confusion par effet de groupe + non-indépendance des résidus\nProblème 1 : Biais de confusion par effet de groupe.\n\nSi les centres pour lesquels le niveau de dépression est le plus élevé sont aussi ceux où la durée moyenne des entretiens est la plus longue, la pente de régression est biaisée.\nElle mélange l’effet individuel (la relation durée-dépression pour un détenu) et l’effet du groupe. Le modèle ne peut distinguer si la dépression est liée à la durée de l’entretien ou à d’autres facteurs propres au centre (personnel, type de population, etc.).\nConséquence : Le coefficient de régression estimé est faussé et ne représente pas la véritable association au niveau individuel.\n\nProblème 2 : Non-indépendance des résidus.\n\nLes résidus \\(\\varepsilon_i\\) ne sont pas indépendants. Les observations au sein d’un même groupe (centre) se ressemblent plus qu’avec celles d’autres groupes.\nC’est la corrélation intra-classe.\nConséquence : Ce problème ne biaise pas l’estimation de la pente, mais il conduit à une sous-estimation de son erreur-standard.\nImpact : L’intervalle de confiance est artificiellement étroit et la p-value trop petite. Le risque est de conclure à tort à un effet significatif (Erreur de Type I).\nSolutions : Bootstrap par grappe ou estimateur sandwich\n\nLe Bootstrap par grappe (Cluster Bootstrap) :\n\nPrincipe :\n\nPuisque les individus d’un groupe ne sont pas indépendants, on ré-échantillonne les groupes (les centres) avec remise.\nPour chaque groupe tiré, on inclut tous les individus qu’il contient.\n\nRésultat :\n\nOn obtient une distribution de 1000 coefficients qui reflète l’incertitude liée à la variabilité entre les groupes. L’IC à 95% est construit à partir de cette distribution (ex: via les percentiles).\nCet intervalle sera presque toujours plus large que l’IC naïf, reflétant une estimation plus honnête de l’incertitude.\n\n\n\nL’estimateur “Sandwich” (Estimateur Robuste de la Variance) :\n\nLe problème :\n\nLe modèle classique est “trop confiant”. Il pense que chaque ligne de données apporte une information unique.\nOr, si les patients d’un même centre se ressemblent, on a moins d’information réelle qu’on ne le croit.\nL’erreur-standard calculée classiquement est donc trop petite.\n\n\nSolution :\n\nAu lieu de se fier uniquement à la théorie (qui suppose l’indépendance), l’estimateur Sandwich regarde les résidus réels (les erreurs du modèle).\nSi, dans un centre, tous les résidus vont dans le même sens (ex: le modèle se trompe toujours par excès pour ce centre), l’estimateur détecte cette corrélation. Il utilise cette “réalité du terrain” pour corriger mathématiquement la variance à la hausse.\n\n\nPrincipe : La formule mathématique de la variance robuste se compose de trois blocs multipliés entre eux : \\(A \\times B \\times A\\).\nOn l’appelle “Sandwich” uniquement parce que la correction (B) est coincée entre deux blocs identiques (A), comme une tranche de jambon entre deux tranches de pain.\n\nLe bloc A (La Théorie) : C’est la variance calculée par le modèle classique. Elle suppose que tout est parfait (indépendance).\nLe bloc B (La Réalité) : C’est une correction calculée directement à partir des données brutes (les résidus). Si les erreurs sont corrélées dans les groupes, ce bloc B va “gonfler” la valeur.\nLe calcul : On multiplie Théorie \\(\\times\\) Correction \\(\\times\\) Théorie.\n\nRésultat : Les estimations des coefficients (la pente) ne changent pas, mais les intervalles de confiance s’élargissent et les p-values augmentent, reflétant une incertitude plus honnête.\n\n\n\n\n\n5.1.2 Exemple R avec jeu de données fictif\n\nGénération des données\n\n\nset.seed(1)\n# génération des Xi et Yi pour 5 temps de mesure dans 200 centres\nx1 &lt;- runif(200)*0.3 # Génération des xi pour le centre j\nx2 &lt;- runif(200)*0.3\nx3 &lt;- runif(200)*0.3\nx4 &lt;- runif(200)*0.3\nx5 &lt;- runif(200)*0.3\na &lt;- rnorm(200)*100+300 # Les coefficiens de la régression\nb &lt;- rnorm(200)*100+150 # sont fonction du centre\ny1 &lt;- a+b*x1+rnorm(200)*72.5\ny2 &lt;- a+b*x2+rnorm(200)*72.5\ny3 &lt;- a+b*x3+rnorm(200)*72.5\ny4 &lt;- a+b*x4+rnorm(200)*72.5\ny5 &lt;- a+b*x5+rnorm(200)*72.5\n\n# dt est le fichier \"large\" (une ligne par centre)\ndt &lt;- data.frame(1:200,x1,y1,x2,y2,x3,y3,x4,y4,x5,y5)\nnames(dt)[1] &lt;- \"centre\"\n\n# conversion du fichier \"large\" en fichier \"long\"\ndtl &lt;- reshape(dt,idvar=\"centre\",varying=2:11,v.names=c(\"x\",\"y\"),timevar = \"temps\",direction=\"long\")\ndtl$centre &lt;- as.factor(dtl$centre)\n\n\nRégression linéaire simple sans prise en compte de l’effet centre\n\n\nmod.lm &lt;- lm(y ~ x, data=dtl)\nsummary(mod.lm)$coefficients\n\n            Estimate Std. Error   t value      Pr(&gt;|t|)\n(Intercept) 286.6649   8.232679 34.820363 1.591602e-174\nx           153.6712  47.571204  3.230341  1.276828e-03\n\n\nIci, le calcul de l’erreur-standard (l’écart-type) et de la p-value repose sur l’hypothèse que les résidus sont indépendants, ce qui n’est pas le cas.\nImpossible de le savoir si on n’a pas d’information sur les données !!\nAttention parce que les résidus semblent “normaux” (cf. graphique ci-dessous), cela ne garantit pas leur indépendance.\n\npar(mfrow=c(1,2))\nhist(residuals(mod.lm),main=\"Histogramme des résidus\",xlab=\"Résidus\")\nqqnorm(residuals(mod.lm),main=\"Q-Q plot des résidus\")\nqqline(residuals(mod.lm))\n\n\n\n\nGraphique des résidus du modèle linéaire simple sans prise en compte de l’effet centre\n\n\n\n\nBootsrap\nIl est possible de recourir à un bootstrap pour contourner cette limite, en utilisant la fonction clusbootglm() de la bibliothèque ClusterBootstrap.\n\nset.seed(1)\nlibrary(\"ClusterBootstrap\")\nmod.clusboot &lt;- clusbootglm(y~x,data=dtl,clusterid=centre)\n\n$boot.coefs : \n(Intercept)         x\n286.6787            153.6561\n$boot.sds\n(Intercept)         x\n11.03841            50.14656\nL’écart type de b = 50,14 (par rapport à 47,57 naïf). Les coefficients ne changent pas.\nEstimateur sandwich\n\nlibrary(\"sandwich\")\nsqrt(diag(vcovCL(lm(y~x,data=dtl),cluster=~centre))[\"x\"])\n\n       x \n50.73999 \n\n\nL’estimation de l’erreur type (50.74) est très proche de celle du bootstrap, prenant toujours en compte la dépendance des observations d’un même centre.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>6 Effet centre</span>"
    ]
  },
  {
    "objectID": "6_effet_centre.html#analyse-avec-prise-en-compte-de-leffet-centre",
    "href": "6_effet_centre.html#analyse-avec-prise-en-compte-de-leffet-centre",
    "title": "3  6 Effet centre",
    "section": "5.2 Analyse avec prise en compte de l’effet centre",
    "text": "5.2 Analyse avec prise en compte de l’effet centre\nil s’agit ici de calculer les moyennes de X et Y pour chaque centre puis d’en faire une régression linéaire\n\n\n\nEstimation d’une pente inter-centres à partir des moyennes de X et Y pour chaque centre.\n\n\n\n5.2.1 Exemple R\n\n#moyenne de Y et X par centre\nymeans = tapply(dtl$y, dtl$centre, mean)\nxmeans = tapply(dtl$x, dtl$centre, mean)\n\n#régression linéaire des moyennes\nsummary(lm(ymeans ~ xmeans))\n\n\nCall:\nlm(formula = ymeans ~ xmeans)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-309.22  -75.94   -4.72   73.62  308.89 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    268.8       29.6   9.080   &lt;2e-16 ***\nxmeans         272.9      190.4   1.434    0.153    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 111.4 on 198 degrees of freedom\nMultiple R-squared:  0.01027,   Adjusted R-squared:  0.005276 \nF-statistic: 2.055 on 1 and 198 DF,  p-value: 0.1532\n\n\nxmeans : fournit une estimation de la pente inter-centres.\nFournit une estimation de la pente inter-centres, avec une erreur type estimée en prenant en compte l’indépendance des centres.\nCela indique comment la moyenne de \\(Y\\) varie d’un centre à l’autre en fonction de la moyenne de \\(X\\) du centre. L’erreur type est ici estimée correctement car on travaille sur les centres (qui sont indépendants entre eux), et non sur les observations répétées.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>6 Effet centre</span>"
    ]
  },
  {
    "objectID": "6_effet_centre.html#analyse-intra-centres-modèles-conditionnels-mixtes-ou-non",
    "href": "6_effet_centre.html#analyse-intra-centres-modèles-conditionnels-mixtes-ou-non",
    "title": "3  6 Effet centre",
    "section": "5.3 Analyse intra-centres (modèles conditionnels, mixtes ou non)",
    "text": "5.3 Analyse intra-centres (modèles conditionnels, mixtes ou non)\n3 méthodes :\n\nModèle linéaire avec effet fixe par centre (chaque centre )\nModèle linéaire avec pente commune (intercept variable par centre)\nModèle mixte avec effet aléatoire de centre (c’est à dire que les centres sont vus comme un échantillon aléatoire d’une population plus large de centres possibles)\n\n\n5.3.1 Modèle linéaire avec effet fixe par centre\nPour évaluer la corrélation intra-centre entre \\(X\\) et \\(Y\\), on peut faire une régression linéaire dans chaque centre puis calculer la moyenne des pentes obtenues.\n\n\n\nApproche conditionnelle artisanale pour laquelle une régression est réalisée dans chaque centre, une pente moyenne étant calculée dans un second temps.\n\n\nC’est une approche “conditionnelle” car chaque pente est calculée “conditionnellement” à un centre donné.\nL’équation serait :\n\n\\[\nY_{ij} = a + [a.centre_{j}] + b x_{ij} + [b.centre_{j}] x_{ij} + \\varepsilon_{ij}\n\\]\n\n\\(i\\) : individu\n\\(j\\) : centre\n\\(a\\) : intercept global\n\\(b\\) : pente globale\n\\([a.centre_{j}]\\) : déviation de l’intercept pour le centre j\n\\([b.centre_{j}]\\) : déviation de la pente pour le centre j\n\nGlobalement : ça revient à faire une régression linéaire avec des interactions entre \\(X\\) et le centre.\nDonc chaque centre a sa propre droite de régression (intercept et pente différents).\nEn R simplement : lm(y ~ x * centre).\n\n\n5.3.2 Modèle linéaire avec pente commune (intercept variable par centre)\nVariante plus simple : pente commune\nModèle proposé :\n\n\\[\ny_{ij} = a + [a.\\text{centre}_j] + b\\, x_{ij} + \\varepsilon_{ij}\n\\]\nIci :\n\nchaque centre \\(j\\) a son intercept propre : \\(a + [a.\\text{centre}_j]\\)\nmais la pente \\(b\\) est identique dans tous les centres\n\nGraphiquement : toutes les droites sont parallèles (même pente) mais décalées verticalement (intercepts différents).\n\n\n\nApproche conditionnelle avec pente commune, elle correspond au modèle : \\(y_{ij} = a + [a.\\text{centre}_j] + b\\, x_{ij} + \\varepsilon_{ij}\\)\n\n\nEn R : lm(y \\~ x + centre)\nAvec 2 trucs importants à savoir sur l’interprétation de b :\n\n\\(b\\) : sorte de moyenne des pentes centre par centre, pondérée par la variance de \\(x\\) dans chaque centre.\n\nDonc lié aux pentes que l’on obtiendrait si on faisait une régression séparée dans chaque centre, puis qu’on faisait une moyenne pondérée.\n\nerreur type de \\(b\\) : correcte uniquement si vraiment toutes les pentes sont égales entre centres.\n\nSi en réalité les pentes diffèrent un peu entre centres, mais que le modèle force une pente commune, alors :\n\n\\(b\\) reste un estimateur moyen\nmais l’incertitude autour de \\(b\\) est mal évaluée → d’où la suggestion d’utiliser un estimateur sandwich (variance robuste) ou le bootstrap.\n\n\n\nRésumé :\n\nModèle plus simple, mais repose sur l’hypothèse forte : “même pente partout”.\nSi cette hypothèse est fausse, le \\(b\\) affiché reste “une pente moyenne”, mais son écart-type est trop optimiste.\n\n\n\n5.3.3 Modèle mixte avec effet aléatoire de centre\nUtile surtout si beaucoup de centres.\nPassage aux modèles “mixtes” : centre comme effet aléatoire\nIdée : plutôt que mettre une variable catégorielle [centre] avec 10 000 modalités, on introduit une variable aléatoire (centre).\nDonc la variable catégorielle [centre] devient une variable aléatoire gaussienne (centre).\nNouveau modèle :\n\n\\[\ny\\_{ij} = a + (a\\_{\\text{centre}*j}) + b, x*{ij} + \\varepsilon\\_{ij}\n\\]\nOu :\n\n\\((a\\_{\\text{centre}*j})\\) : effet aléatoire pour le centre j, c’est à dire une variable aléatoire qui suit une distribution normale et qui modélise la variabilité des intercepts entre centres.\n\\(b\\) : pente commune à tous les centres.\n\\(\\varepsilon\\_{ij}\\) : erreur résiduelle pour l’individu i dans le centre j.\n\nLes effets sont “mixtes” car il y a à la fois des effets fixes (a, b) et des effets aléatoires (a_{*j}).\nCa aide car :\n\nPas besoin de 9999 variables binaire (dummy) pour les centres.\nProcessus aléatoire pour les centres.\n\nIl faut le faire surtout s’il y a plus de 5 centres.\n\n\n\n5.3.4 Exemple R\nCalcul des pentes de régressions de \\(Y\\) en fonction de \\(X\\) dans chaque centre\n\n# fonction calculant la pente pour un centre donné\npente_intra=function(centre) {coef(lm(data=dtl[dtl$centre==centre,], y~x))[\"x\"]}\n# application de la fonction à tous les centres\npentes = sapply(levels(dtl$centre), pente_intra) \n\n# affichage de la pente moyenne et de son erreur standard\ncat(\"La pente moyenne est de\", round(mean(pentes), 2),\n    \"avec une erreur standard de\", round(sd(pentes) / sqrt(length(pentes)), 2), \"\\n\")\n\nLa pente moyenne est de 131.66 avec une erreur standard de 41.6 \n\n\n\nModèle avec effet fixe par centre \\(Y_{ij} = a + [a.centre_{j}] + b x_{ij} + [b.centre_{j}] x_{ij} + \\varepsilon_{ij}\\)\n\nC’est surtout le paramètre \\(b\\) qui nous intéresse.\nOn utilise contr.sum pour que le coefficient x corresponde à la pente MOYENNE de tous les centres (sinon ce serait la pente du centre de référence). Le “point zéro” n’est plus le centre 1 mais la moyenne des centres.\n\ndtlbis &lt;- dtl\ncontrasts(dtlbis$centre) &lt;- contr.sum\n# estimation du modèle avec effet fixe par centre\nmod.lmci &lt;- lm(y~x*centre, data=dtlbis)\n# affichage dans un cat()\ncat(\"La pente intra-centres estimée est de\", round(summary(mod.lmci)$coefficients[\"x\",\"Estimate\"],2),\n    \"avec une erreur standard de\", round(summary(mod.lmci)$coefficients[\"x\",\"Std. Error\"],2), \"\\n\")\n\nLa pente intra-centres estimée est de 131.66 avec une erreur standard de 39.47 \n\n\n\nModèle avec pente commune \\(Y_{ij} = a + [a.\\text{centre}_j] + b\\, x_{ij} + \\varepsilon_{ij}\\)\n\n\nmod.lmc &lt;- lm(y~x+centre, data=dtl)\ncat(\"La pente intra-centres estimée est de\", round(summary(mod.lmc)$coefficients[\"x\",\"Estimate\"],2),\n    \"avec une erreur standard de\", round(summary(mod.lmc)$coefficients[\"x\",\"Std. Error\"],2), \"\\n\")\n\nLa pente intra-centres estimée est de 118.26 avec une erreur standard de 31.51 \n\n\n\nModèle mixte avec effet aléatoire de centre \\(Y_{ij} = a + (a_{\\text{centre}*j}) + b, x*{ij} + \\varepsilon_{ij}\\)\n\nIl faut utiliser la fonction lmer() de la bibliothèque lme4 ou nlme.\nSyntaxe : (1|centre) signifie qu’on modélise un intercept aléatoire par centre.\n\nlibrary(nlme)\nmod.lmer1 &lt;- lmer(y~x+(1|centre), data=dtl)\nsummary(mod.lmer1)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: y ~ x + (1 | centre)\n   Data: dtl\n\nREML criterion at convergence: 11949.7\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.1811 -0.6001  0.0126  0.6147  2.7906 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n centre   (Intercept) 11242    106.03  \n Residual              5723     75.65  \nNumber of obs: 1000, groups:  centre, 200\n\nFixed effects:\n            Estimate Std. Error      df t value Pr(&gt;|t|)    \n(Intercept)  291.354      9.146 346.352  31.857  &lt; 2e-16 ***\nx            122.391     31.081 840.929   3.938 8.91e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n  (Intr)\nx -0.509\n\n\nLa méthode ici utilisée est la vraisemblance restreinte (REML), dont le principe est d’estimer les paramètres de variance en maximisant la vraisemblance des résidus (c’est à dire leur cohérence avec les données observées), ce qui est préférable pour estimer les paramètres de variance des effets aléatoires.\nL’effet centre et le résidus sont donc caractérisés par des variances estimées (du fait qu’on les considère comme des variables aléatoires).\nLa variance de l’effet centre est donc estimée sensiblement plus importante que le bruit présent dans le modèle (résidus).\nL’estimation de la pente vaut 122,39, légèrement différente des modèles précédents.\nPour interpréter la pente d’un modèle à effets mixtes :\n\nSi la variance intra-centre de \\(X\\) est très faible, la pente fixe du modèle mixte s’interprète comme une pente inter-centre.\nSi la variance inter-centre de \\(X\\) est faible (donc faible effet centre), la pente fixe s’interprète comme une pente intra-centre.\n\n\nModèle mixte avec pente aléatoire par centre \\(Y_{ij} = a + (a_{\\text{centre}*j}) + (b_{\\text{centre}*j}) x_{ij} + \\varepsilon_{ij}\\)\n\n\n\n5.3.5 Conditions de validités des modèles mixtes\n\nLa pente inter-centres est égale à la moyenne des pentes intra-centres (c’est à dire que les pentes des centres ne diffèrent pas trop entre elles) ;\nL’indépendance des résidus, ce qui peut poser des problèmes lorsque la structurede corrélation intra-centre est complexe, notamment lorsqu’elle est susceptible d’être négative, car les modèles mixtes classiques ne permettent pas de modéliser des corrélations négatives entre les observations d’un même centre ;\nContribution des plus gros centres supérieure à celle des petits centres. Ca pose problème uniquement si la taille du centre est corrélée à la variable \\(Y\\).\nIndépendance, normalité, homoscédasticité et nullité moyenne des effets aléatoires ; qu’il s’agisse des ordonnées à l’origine spécifiques à chacun des centres ou de leurs pentes ;",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>6 Effet centre</span>"
    ]
  },
  {
    "objectID": "6_effet_centre.html#modèle-marginal-gee-generalized-estimating-equations",
    "href": "6_effet_centre.html#modèle-marginal-gee-generalized-estimating-equations",
    "title": "3  6 Effet centre",
    "section": "5.4 Modèle marginal = GEE (Generalized Estimating Equations)",
    "text": "5.4 Modèle marginal = GEE (Generalized Estimating Equations)\n\\(Y\\) : score de dépression, \\(X\\) durée de l’entretien, patients regroupés par centre et il existe une corrélation intra-centre.\nApproche conditionnelle (modèles mixtes, etc.) : “Quel est l’effet de X dans un centre donné ?”\nApproche marginale : “Quel est l’effet de X en moyenne dans la population, tous centres confondus ?”\n\\(\\rightarrow\\) on ne modélise pas les centres un par un ; on s’intéresse à la moyenne globale et on corrige seulement la corrélation.\n\n5.4.1 Définition\nDans l’approche conditionnelle : on réalise une série de modèles au sein même de chaque centre (on regarde ce qui se passe “à l’intérieur” des centres).\nDans l’approche marginale : on écrit un modèle très simple : en gros, comme lm(y~x), mais on remplace l’estimateur classique par un autre estimateur, qui corrige pour la corrélation intra-centre.\nIl faut faire l’hypothèse d’égalité des pentes inter-centres et intra-centre : la pente de la relation \\(X\\) - \\(Y\\) est la même entre les centres (si on compare des centres entre eux) et à l’intérieur des centres (si on regarde les patients d’un même centre).\nSous cette hypothèse, l’estimation GEE de la pente est plus efficace (variance plus faible) que l’estimation naïve de lm(y ~ x), c’est à dire même moyenne mais moins de variance.\n\n\n5.4.2 Principe des GEE\n\nD’abord estimation d’à quel point les observations d’un même centre sont corrélées entre elles (corrélation intra-centre).\nEnsuite, GEE utilise cette information pour ajuster la manière de calculer les coefficients du modèle linéaire\n\nSi la corrélation intra-centre est faible, GEE donne des résultats très proches de lm(y ~ x).\nSi la corrélation intra-centre est forte, GEE fournit une estimation plus précise de la pente, mais l’interprétation de cette pente devient plus complexe.\n\nSimulations de jeux de données multicentriques de taille modeste (4 observations par centre dans 5 centres).\nLes panneaux A, B et C correspondent à des jeux légèrement différents.\nDans les encadrés sont données :\n\nN°1 : les pentes fixes d’un modèle à effets mixtes à intercept aléatoire \\(y_{ij} = a + [a.centre_j] + b x_{ij} + \\varepsilon_{ij}\\);\nN°2 : les pentes d’un modèle à effets mixtes à intercept et pente aléatoires (\\(y_{ij} = a + [a.centre_j] + b x_{ij} + [b.centre_j] x_{ij} + \\varepsilon_{ij}\\)).\nLes pentes d’un modèle linéaire estimé par GEE sont également estimées.\n\nLe symbole en gras représente la moyenne de chaque centre (barycentre des points du centre).\nUne modification minime des données conduit les modèles à effets mixtes à estimer tantôt la pente inter-centres (décroissante donc négative), et tantôt la pente intra-centre (positive)\n##is# Exemple R\nIl faut utiliser la library gee.\nDans la syntaxe, l’utilisation de order est indispensable pour que les observations soient regroupées par centre.\nL’option corstr=\"exchangeable\" indique que la corrélation intra-centre est supposée identique entre toutes les paires d’observations d’un même centre (structure de corrélation dite “échangeable”), c’est à dire que la corrélation entre les observations 1 et 2 d’un centre est la même que celle entre les observations 1 et 3, etc.\n\ndtlgee &lt;- dtl[order(dtl$centre,dtl$temps),]\nmod.gee &lt;- gee(\n                y~x, \n                data=dtlgee, \n                id=centre, \n                corstr=\"exchangeable\"\n                )\n\nBeginning Cgee S-function, @(#) geeformula.q 4.13 98/01/27\n\n\nrunning glm to get initial regression estimate\n\n\n(Intercept)           x \n   286.6649    153.6712 \n\nsummary(mod.gee)\n\n\n GEE:  GENERALIZED LINEAR MODELS FOR DEPENDENT DATA\n gee S-function, version 4.13 modified 98/01/27 (1998) \n\nModel:\n Link:                      Identity \n Variance to Mean Relation: Gaussian \n Correlation Structure:     Exchangeable \n\nCall:\ngee(formula = y ~ x, id = centre, data = dtlgee, corstr = \"exchangeable\")\n\nSummary of Residuals:\n       Min         1Q     Median         3Q        Max \n-391.96041  -86.83861    2.71576   83.68505  368.27139 \n\n\nCoefficients:\n            Estimate Naive S.E.   Naive z Robust S.E.  Robust z\n(Intercept) 291.3500   9.135526 31.891982    9.410923 30.958709\nx           122.4175  31.121353  3.933554   34.743959  3.523419\n\nEstimated Scale Parameter:  16929.16\nNumber of Iterations:  2\n\nWorking Correlation\n          [,1]      [,2]      [,3]      [,4]      [,5]\n[1,] 1.0000000 0.6610401 0.6610401 0.6610401 0.6610401\n[2,] 0.6610401 1.0000000 0.6610401 0.6610401 0.6610401\n[3,] 0.6610401 0.6610401 1.0000000 0.6610401 0.6610401\n[4,] 0.6610401 0.6610401 0.6610401 1.0000000 0.6610401\n[5,] 0.6610401 0.6610401 0.6610401 0.6610401 1.0000000",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>6 Effet centre</span>"
    ]
  },
  {
    "objectID": "6_effet_centre.html#principes-généraux",
    "href": "6_effet_centre.html#principes-généraux",
    "title": "3  6 Effet centre",
    "section": "6.1 Principes généraux",
    "text": "6.1 Principes généraux\nSi \\(Y\\) n’est plus une variable quantitative normalement distribuée, mais une variable binaire (ex: succès/échec), on peut utiliser un modèle linéaire généralisé (GLM) avec une fonction de lien logit (régression logistique).\nNB : condition de validité de l’estimateur du maximum de vraisemblance de la régression logistique = au moins 5 à 10 évènements par variable explicative incluse dans le modèle.\nOn peut faire une “régression logistique conditionnelle” :\n\nvraisemblance partielle au sein de chaque centre puis agréger ces vraisemblances en une seule valeur\n\npermet d’obtenir des OR intra-centres, mais empêche l’étude de l’effet centre lui-même.\n\n“modèle linéaire généralisé à effets mixtes = GLMM” (Generalized Linear Mixed Model) :\n\nla variable (centre) est vue comme un effet aléatoire.\n\n\nOn peut aussi faire une approche “marginale” :\n\nIgnorer l’effet centre en premier lieu (modèle logistique simple), avec si possible un bootstrap par grappe ou un estimateur sandwich pour corriger l’erreur standard pour prendre en compte la corrélation intra-centre.\nUtiliser un modèle GEE avec une fonction de lien logit pour obtenir des OR “marginales” corrigées de la corrélation intra-centre.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>6 Effet centre</span>"
    ]
  },
  {
    "objectID": "6_effet_centre.html#exemple-r-avec-données-simulées",
    "href": "6_effet_centre.html#exemple-r-avec-données-simulées",
    "title": "3  6 Effet centre",
    "section": "6.2 Exemple R avec données simulées",
    "text": "6.2 Exemple R avec données simulées\nOn reprend le jeu de données simulées mais transforme \\(Y\\) en variable binaire selon un seuil de 300.\n\ndtl$y.b &lt;- ifelse(dtl$y&gt;300,1,0)\ndtlbis$y.b &lt;- ifelse(dtlbis$y&gt;300,1,0) \ndtlgee$y.b &lt;- ifelse(dtlgee$y&gt;300,1,0) \n\n\nModèle non ajusté : régression logistique simple sans prise en compte de l’effet centre\n\n\nmodglm &lt;- glm(y.b~x,data=dtl,family=\"binomial\")\nlibrary(gtsummary)\n# tableau gt summary avec modify footnote pour dire comment les OR ont été obtenus (en anglais)\ntbl_glm &lt;- tbl_regression(\n    modglm,\n    exponentiate = TRUE,\n    label = list(x ~ \"Duration of interview (X)\")\n    ) %&gt;%\n    modify_footnote(\n        estimate ~ \"Odds Ratios (OR) calculated from logistic regression model without accounting for center effect.\"\n    )\ntbl_glm\n\n\n\n\n\n\n\nCharacteristic\nOR1\n95% CI\np-value\n\n\n\n\nDuration of interview (X)\n4.33\n1.03, 18.4\n0.047\n\n\n\n1 Odds Ratios (OR) calculated from logistic regression model without accounting for center effect.\n\n\nAbbreviations: CI = Confidence Interval, OR = Odds Ratio\n\n\n\n\n\n\n\n\nOR calculé caractérise la relation entre \\(X\\) et \\(Y\\) en ignorant l’effet centre et en supposant que toutes les observations sont indépendantes.\n\nEstimation par bootstrap par grappe\n\nPour corriger l’erreur standard résultant de la corrélation intra-centre, on peut utiliser un bootstrap par grappe ou un estimateur sandwich.\n\n# Bootstrap par grappe\nmodboot &lt;- clusbootglm(\n                    y.b~x,\n                    data=dtl,\n                    clusterid=centre,\n                    family=\"binomial\")\nmodboot$boot.coefs\n\n(Intercept)           x \n-0.07882868  1.47121016 \n\nmodboot$boot.sds\n\n(Intercept)           x \n  0.1518630   0.7952629 \n\nexp(modboot$boot.coefs)[2]\n\n       x \n4.354502 \n\n\nL’OR estimé après bootstrap est légèrement différent, et l’erreur standard est plus grande, reflétant l’incertitude accrue due à la corrélation intra-centre.\nLe rapport entre le coefficient non exponentié et l’erreur standard permet de tester la présence d’une corrélation :\n\ncat(\"Le rapport coefficient/erreur standard est de\",\n    round((modboot$boot.coefs[2]) / (modboot$boot.sds[2]), 2),\n    \"\\n\")\n\nLe rapport coefficient/erreur standard est de 1.85 \n\n\nLe rapport entre le coefficient (non exponentié) et son erreur standard correspond au z-score du test de Wald.\nIl sert à tester l’hypothèse nulle H0 : le coefficient de X est nul (OR = 1), c’est-à-dire « pas d’association entre X et Y » après correction de la corrélation intra-centre.\nSi ce z-score est inférieur en valeur absolue à 1,96, on ne met pas en évidence d’association significative au seuil de 5 %.\nIci, le coefficient vaut 1,87 donc &lt; 1,96 → pas de preuve d’une association significative entre \\(X\\) et \\(Y\\) après correction de la corrélation intra-centre.\n\nModèle ajusté à effet fixe : régression logistique avec ajustement sur la variable catégorielle [centre]\n\n\nmodglmaj &lt;- glm(y.b~x+centre,data=dtl,family=\"binomial\")\nsummary(modglmaj)$coefficients[\"x\", ]\n\n  Estimate Std. Error    z value   Pr(&gt;|z|) \n2.19692245 1.24982624 1.75778230 0.07878456 \n\nexp(summary(modglmaj)$coefficients[\"x\", \"Estimate\"])\n\n[1] 8.997281\n\n\nLe problème est que le modèle compte 199 variables indicatrices (dummy) pour les centres, ce qui est lourd.\nIl faudrait au mieux 2000 observations pour respecter la règle des 10 évènements par variable, or il y en a 535.\n\nModèle logistique conditionnel :\n\nLa fonction clogit() permet de faire une régression logistique conditionnelle en utilisant la vraisemblance partielle.\nVraisemblance partielle = méthode d’estimation qui permet d’éliminer les paramètres de nuisance (ici, les intercepts spécifiques à chaque centre) en conditionnant sur le nombre d’événements observés dans chaque groupe.\nAu lieu d’estimer la probabilité absolue de l’événement, on estime la probabilité qu’un individu ait l’événement sachant le nombre total d’événements observés dans son centre.\nCela permet d’estimer l’association intra-centre sans avoir à estimer les coefficients de chaque centre.\nC’est mathématiquement équivalent à un modèle de Cox stratifié.\n\nlibrary(survival)\nsummary(clogit(y.b~x+strata(centre),dtl))\n\nCall:\ncoxph(formula = Surv(rep(1, 1000L), y.b) ~ x + strata(centre), \n    data = dtl, method = \"exact\")\n\n  n= 1000, number of events= 535 \n\n   coef exp(coef) se(coef)     z Pr(&gt;|z|)\nx 1.754     5.779    1.115 1.573    0.116\n\n  exp(coef) exp(-coef) lower .95 upper .95\nx     5.779      0.173    0.6494     51.43\n\nConcordance= 0.551  (se = 0.037 )\nLikelihood ratio test= 2.48  on 1 df,   p=0.1\nWald test            = 2.47  on 1 df,   p=0.1\nScore (logrank) test = 2.49  on 1 df,   p=0.1\n\n\nLe coefficient obtenu correspond au Log-Odds Ratio intra-centre.\n\nModèle mixte à pente commune\n\nIci, la pente commune correspond à une pente commune au sein des différents centres.\n\nmoglmer1 &lt;- glmer(y.b~x+(1|centre),data=dtl,family=\"binomial\")\nsummary(moglmer1)$coefficients[\"x\", ]\n\n  Estimate Std. Error    z value   Pr(&gt;|z|) \n1.92515054 1.01661177 1.89369294 0.05826578 \n\nexp(summary(moglmer1)$coefficients[\"x\", \"Estimate\"])\n\n[1] 6.856181\n\n\n\nModèle mixte autorisant des pentes propres à chaque centre\n\n\nmodglmer2 &lt;- glmer(y.b~x+(1+x|centre),data=dtl,family=\"binomial\")\n\nboundary (singular) fit: see help('isSingular')\n\nsummary(modglmer2)$coefficients[\"x\", ]\n\n  Estimate Std. Error    z value   Pr(&gt;|z|) \n 2.3676541  1.0784455  2.1954323  0.0281326 \n\nexp(summary(modglmer2)$coefficients[\"x\", \"Estimate\"])\n\n[1] 10.67233\n\n\nboundary (singular) fit: see help('isSingular') nous alerte sur un possible problème numérique : cela signifie que le modèle a du mal à estimer certains paramètres en raison d’une matrice de variance-covariance singulière, souvent causée par un manque de variabilité dans les données ou une sur-paramétrisation du modèle.\n\nModèle marginal GEE avec fonction de lien logit\n\n\nmodgee &lt;- gee(\n                y.b~x, \n                data=dtlgee, \n                id=centre, \n                corstr=\"exchangeable\",\n                family=\"binomial\"\n                )\n\nBeginning Cgee S-function, @(#) geeformula.q 4.13 98/01/27\n\n\nrunning glm to get initial regression estimate\n\n\n(Intercept)           x \n-0.07879536  1.46485165 \n\nsummary(modgee)$coefficients[\"x\", ]\n\n   Estimate  Naive S.E.     Naive z Robust S.E.    Robust z \n  1.1122609   0.6119977   1.8174265   0.6426709   1.7306851 \n\nexp(summary(modgee)$coefficients[\"x\", \"Estimate\"])\n\n[1] 3.041227\n\n\n\nAu final, on a 7 OR différents avec des IC et des pvalue différentes :\n\n\n\n\n\n\n\n\nOR selon la methode d'estimation\n\n\nEstimation Method\nOdds Ratio (OR)\nStandard Error\np-value\n\n\n\n\nNon ajuste (GLM)\n4.33\n0.74\n0.0466\n\n\nBootstrap ajuste (clusbootglm)\n4.35\n0.80\n0.0643\n\n\nEffet fixe ajuste (GLM + centre)\n9.00\n1.25\n0.0788\n\n\nConditionnel (clogit)\n5.78\n1.12\n0.1157\n\n\nPente commune mixte (glmer)\n6.86\n1.02\n0.0583\n\n\nPente aleatoire mixte (glmer)\n10.67\n1.08\n0.0281\n\n\nMarginal (GEE)\n3.04\n0.64\n0.0835\n\n\n\n\n\n\n\nQuel modèle choisir en pratique ?\nLe choix du modèle dépend avant tout de la question scientifique et de la manière dont l’échantillon de centres est considéré.\n\nObjectif : mesurer une association globale dans la population (OR marginal)\n\nSi l’échantillon a vocation à représenter une population cible, et que la question est :\n« Quelle est la force de l’association entre Y.b et X globalement, dans cette population, en tenant compte du fait que les sujets sont regroupés par centre ? »,\nalors l’approche logistique simple avec correction de l’erreur standard par bootstrap de grappes est souvent la plus naturelle.\nConcrètement, on ajuste un modèle logistique standard glm(y.b ~ x, family = binomial) puis on corrige l’incertitude (erreur standard, IC, p-value) par un bootstrap par centre.\n\nLa pente estimée (et l’OR correspondant) reste très transparente à interpréter : c’est un OR marginal moyen, sur l’ensemble des sujets, exposés vs non exposés.\nLe bootstrap corrige l’optimisme de l’erreur standard dû à la corrélation intra-centre, sans introduire de structure de modèle supplémentaire.\nL’approche reste techniquement simple et robuste, au prix d’un peu de calcul.\n\nDans la même philosophie, un modèle GEE logistique (avec gee() et family = binomial) fournit aussi un OR marginal, mais cette fois-ci via une construction plus sophistiquée, qui impose de choisir une structure de corrélation (ex. « exchangeable »). Dans les situations standard, la logistique simple + bootstrap par centre suffit souvent, et a l’avantage d’être plus transparente.\n\nObjectif : contrôler l’effet centre comme facteur de confusion (OR conditionnel)\n\nSi la question est :\n« Quelle est la relation entre Y.b et X à l’intérieur des centres, en traitant le centre comme un facteur de confusion ou de nuisance ? »,\nalors il s’agit d’estimer un OR conditionnel au centre.\nPlusieurs modèles répondent à cette logique :\n\nla régression logistique conditionnelle (clogit(y.b ~ x + strata(centre))) ;\nle modèle mixte à pente commune (glmer(y.b ~ x + (1|centre))) ;\nle modèle mixte avec pentes aléatoires par centre (glmer(y.b ~ x + (1 + x|centre))).\n\nDans tous les cas, l’OR est conditionnel au centre : il répond à une question du type « à centre donné, quelle est l’association entre X et Y.b ? ».\nCette interprétation est plus délicate, car l’OR dépend d’une information (le centre) qui est rarement observable ou utilisable en pratique au moment de la prise de décision.\nCes modèles sont théoriquement valides, mais :\n\nreposent sur des hypothèses fortes (homogénéité des effets, distribution normale des effets aléatoires, structure de corrélation, etc.) ;\npeuvent conduire à des problèmes numériques (convergence, singularité) dès que la structure devient un peu complexe (pentes aléatoires, peu d’événements par centre, centres très hétérogènes).\n\nIl s’agit de modèles puissants, mais qui nécessitent un usage prudent et une expertise spécifique, surtout pour les modèles mixtes avec pentes aléatoires.\n\nModèle à effets fixes de centre : cas très limité\n\nLa régression logistique avec effet fixe de centre (glm(y.b ~ x + centre, family = binomial)) introduit une variable indicatrice pour chaque centre.\nEn pratique, ce modèle est à éviter dès que le nombre de centres est un peu important :\n\nil consomme énormément de degrés de liberté (une vingtaine de centres = une vingtaine de paramètres supplémentaires) ;\nil viole rapidement la règle « 10 événements par variable » ;\nil n’apporte pas d’information synthétique sur la variabilité entre centres.\n\nIl n’est raisonnable que si le nombre de centres est très faible (par exemple &lt; 5) et que chaque centre dispose de beaucoup de sujets.\n\nMarge vs conditionnel : conséquences sur l’OR\n\nLes modèles GEE donnent un OR marginal, c’est-à-dire une comparaison des cotes de prévalence de la maladie chez tous les exposés vs tous les non exposés, après « gommage » de l’effet centre.\nÀ l’inverse, la logistique conditionnelle et les modèles mixtes (pente commune ou pentes aléatoires) produisent des OR conditionnels au centre. En présence d’une forte variabilité du risque de base entre centres, ces OR conditionnels peuvent être beaucoup plus grands que l’OR marginal issu d’un GEE ou d’un modèle simple corrigé par bootstrap.\nEn résumé :\n\nOR marginal (GLM + bootstrap, GEE) : mesure l’effet « moyen » dans la population globale ;\nOR conditionnel (clogit, GLMM) : mesure l’effet « à centre donné », avec une interprétation plus abstraite.\n\n\nSynthèse pratique\n\n\nSi l’objectif est une mesure simple, robuste et interprétable de la force d’association globale entre X et Y.b dans une population représentée par l’échantillon, la solution la plus raisonnable est :\n\nmodèle logistique simple glm(y.b ~ x, family = binomial)\navec correction de l’erreur standard par bootstrap de grappes sur le centre.\n\nSi l’objectif est de contrôler strictement l’effet du centre comme facteur de confusion et d’obtenir un OR au sein des centres, la logistique conditionnelle ou un modèle mixte à pente commune sont des candidats possibles, mais leur usage doit rester réservé aux situations où la question scientifique l’exige vraiment et avec un contrôle soigneux des hypothèses et de la convergence.\nLes modèles mixtes avec pentes aléatoires n’apportent un gain réel que si l’on souhaite modéliser explicitement l’hétérogénéité de l’effet de X d’un centre à l’autre et si l’échantillon contient suffisamment d’information pour les estimer correctement.\nLes GEE binaires se justifient surtout lorsque l’on souhaite un OR marginal avec une estimation plus « théorique » de la variance, en acceptant une certaine complexité de mise en œuvre et d’interprétation.\n\nEn pratique, sauf question très spécifique sur la structure centre par centre, l’association globale X–Y.b dans une étude multicentrique sera souvent décrite de façon honnête et pragmatique par un modèle logistique simple combiné à un bootstrap par grappe sur le centre, en explicitant clairement que l’OR rapporté est un OR marginal ajusté pour la corrélation intra-centre.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>6 Effet centre</span>"
    ]
  }
]