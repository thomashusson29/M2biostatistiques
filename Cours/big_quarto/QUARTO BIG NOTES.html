<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>QUARTO BIG NOTES</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="QUARTO BIG NOTES_files/libs/clipboard/clipboard.min.js"></script>
<script src="QUARTO BIG NOTES_files/libs/quarto-html/quarto.js" type="module"></script>
<script src="QUARTO BIG NOTES_files/libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="QUARTO BIG NOTES_files/libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="QUARTO BIG NOTES_files/libs/quarto-html/popper.min.js"></script>
<script src="QUARTO BIG NOTES_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="QUARTO BIG NOTES_files/libs/quarto-html/anchor.min.js"></script>
<link href="QUARTO BIG NOTES_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="QUARTO BIG NOTES_files/libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="QUARTO BIG NOTES_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="QUARTO BIG NOTES_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="QUARTO BIG NOTES_files/libs/bootstrap/bootstrap-d6a003b94517c951b2d65075d42fb01b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="heading-colors.css">
</head>

<body class="quarto-light">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article toc-left">
<div id="quarto-sidebar-toc-left" class="sidebar toc-left">
  <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="99">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#résumé-statistique" id="toc-résumé-statistique" class="nav-link active" data-scroll-target="#résumé-statistique">Résumé statistique</a>
  <ul class="collapse">
  <li><a href="#position" id="toc-position" class="nav-link" data-scroll-target="#position">Position</a>
  <ul class="collapse">
  <li><a href="#moyenne" id="toc-moyenne" class="nav-link" data-scroll-target="#moyenne">Moyenne</a></li>
  <li><a href="#médiane" id="toc-médiane" class="nav-link" data-scroll-target="#médiane">Médiane</a></li>
  <li><a href="#mode" id="toc-mode" class="nav-link" data-scroll-target="#mode">Mode</a></li>
  </ul></li>
  <li><a href="#dispersion" id="toc-dispersion" class="nav-link" data-scroll-target="#dispersion">Dispersion</a>
  <ul class="collapse">
  <li><a href="#empan" id="toc-empan" class="nav-link" data-scroll-target="#empan">Empan</a></li>
  <li><a href="#écart-interquartile" id="toc-écart-interquartile" class="nav-link" data-scroll-target="#écart-interquartile">Écart interquartile</a></li>
  <li><a href="#variance" id="toc-variance" class="nav-link" data-scroll-target="#variance">Variance</a></li>
  <li><a href="#écart-type" id="toc-écart-type" class="nav-link" data-scroll-target="#écart-type">Écart type</a></li>
  <li><a href="#fonction-r-pour-tout-ça" id="toc-fonction-r-pour-tout-ça" class="nav-link" data-scroll-target="#fonction-r-pour-tout-ça">Fonction R pour tout ça :</a></li>
  </ul></li>
  <li><a href="#dépendance-liaison-et-association" id="toc-dépendance-liaison-et-association" class="nav-link" data-scroll-target="#dépendance-liaison-et-association">Dépendance, liaison et association</a>
  <ul class="collapse">
  <li><a href="#variables-quantitatives" id="toc-variables-quantitatives" class="nav-link" data-scroll-target="#variables-quantitatives">Variables quantitatives</a></li>
  <li><a href="#variables-catégorielles" id="toc-variables-catégorielles" class="nav-link" data-scroll-target="#variables-catégorielles">Variables catégorielles</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#tests-statistiques" id="toc-tests-statistiques" class="nav-link" data-scroll-target="#tests-statistiques">Tests statistiques</a>
  <ul class="collapse">
  <li><a href="#comment-les-utiliser" id="toc-comment-les-utiliser" class="nav-link" data-scroll-target="#comment-les-utiliser">Comment les utiliser ?</a>
  <ul class="collapse">
  <li><a href="#intérêt" id="toc-intérêt" class="nav-link" data-scroll-target="#intérêt">Intérêt</a></li>
  <li><a href="#légitimité" id="toc-légitimité" class="nav-link" data-scroll-target="#légitimité">Légitimité</a></li>
  </ul></li>
  <li><a href="#types-de-tests" id="toc-types-de-tests" class="nav-link" data-scroll-target="#types-de-tests">Types de tests</a>
  <ul class="collapse">
  <li><a href="#comparaison-de-pourcentages" id="toc-comparaison-de-pourcentages" class="nav-link" data-scroll-target="#comparaison-de-pourcentages">Comparaison de pourcentages</a></li>
  <li><a href="#comparaison-de-moyennes" id="toc-comparaison-de-moyennes" class="nav-link" data-scroll-target="#comparaison-de-moyennes">Comparaison de moyennes</a></li>
  <li><a href="#test-de-nullité-dun-coefficient-de-corrélation" id="toc-test-de-nullité-dun-coefficient-de-corrélation" class="nav-link" data-scroll-target="#test-de-nullité-dun-coefficient-de-corrélation">Test de nullité d’un coefficient de corrélation</a></li>
  <li><a href="#tests-appariés" id="toc-tests-appariés" class="nav-link" data-scroll-target="#tests-appariés">Tests appariés</a></li>
  </ul></li>
  <li><a href="#calcul-de-beta-et-du-nombre-de-sujets-à-inclure" id="toc-calcul-de-beta-et-du-nombre-de-sujets-à-inclure" class="nav-link" data-scroll-target="#calcul-de-beta-et-du-nombre-de-sujets-à-inclure">Calcul de <span class="math inline">\(\beta\)</span> et du nombre de sujets à inclure</a></li>
  <li><a href="#tests-uni--ou-bilatéraux" id="toc-tests-uni--ou-bilatéraux" class="nav-link" data-scroll-target="#tests-uni--ou-bilatéraux">Tests uni- ou bilatéraux</a></li>
  <li><a href="#intervalles-de-confiance" id="toc-intervalles-de-confiance" class="nav-link" data-scroll-target="#intervalles-de-confiance">Intervalles de confiance</a></li>
  </ul></li>
  <li><a href="#modèles" id="toc-modèles" class="nav-link" data-scroll-target="#modèles">Modèles</a>
  <ul class="collapse">
  <li><a href="#modèle-linéaire" id="toc-modèle-linéaire" class="nav-link" data-scroll-target="#modèle-linéaire">Modèle linéaire</a>
  <ul class="collapse">
  <li><a href="#définition" id="toc-définition" class="nav-link" data-scroll-target="#définition">Définition</a></li>
  <li><a href="#corrélation-et-modèle-linéaire" id="toc-corrélation-et-modèle-linéaire" class="nav-link" data-scroll-target="#corrélation-et-modèle-linéaire">Corrélation et modèle linéaire</a></li>
  <li><a href="#le-test-t-un-cas-particulier-du-modèle-linéaire" id="toc-le-test-t-un-cas-particulier-du-modèle-linéaire" class="nav-link" data-scroll-target="#le-test-t-un-cas-particulier-du-modèle-linéaire">Le test t : un cas particulier du modèle linéaire</a></li>
  </ul></li>
  <li><a href="#modèle-linéaire-mixte" id="toc-modèle-linéaire-mixte" class="nav-link" data-scroll-target="#modèle-linéaire-mixte">Modèle linéaire mixte</a>
  <ul class="collapse">
  <li><a href="#définition-1" id="toc-définition-1" class="nav-link" data-scroll-target="#définition-1">Définition</a></li>
  <li><a href="#effets-fixes-et-effets-aléatoires" id="toc-effets-fixes-et-effets-aléatoires" class="nav-link" data-scroll-target="#effets-fixes-et-effets-aléatoires">Effets fixes et effets aléatoires</a></li>
  <li><a href="#forme-générale-du-modèle-linéaire-mixte" id="toc-forme-générale-du-modèle-linéaire-mixte" class="nav-link" data-scroll-target="#forme-générale-du-modèle-linéaire-mixte">Forme générale du modèle linéaire mixte</a></li>
  <li><a href="#estimateurs" id="toc-estimateurs" class="nav-link" data-scroll-target="#estimateurs">Estimateurs</a></li>
  <li><a href="#extensions" id="toc-extensions" class="nav-link" data-scroll-target="#extensions">Extensions</a></li>
  </ul></li>
  <li><a href="#modèles-linéaires-généralisés-glm" id="toc-modèles-linéaires-généralisés-glm" class="nav-link" data-scroll-target="#modèles-linéaires-généralisés-glm">Modèles linéaires généralisés (GLM)</a>
  <ul class="collapse">
  <li><a href="#introduction-aux-glm" id="toc-introduction-aux-glm" class="nav-link" data-scroll-target="#introduction-aux-glm">Introduction aux GLM</a></li>
  <li><a href="#régression-logistique" id="toc-régression-logistique" class="nav-link" data-scroll-target="#régression-logistique">Régression logistique</a></li>
  <li><a href="#modèle-de-poisson" id="toc-modèle-de-poisson" class="nav-link" data-scroll-target="#modèle-de-poisson">Modèle de Poisson</a></li>
  <li><a href="#modèle-de-survie" id="toc-modèle-de-survie" class="nav-link" data-scroll-target="#modèle-de-survie">Modèle de survie</a></li>
  <li><a href="#modèle-linéaire-généralisé-mixte-glmm" id="toc-modèle-linéaire-généralisé-mixte-glmm" class="nav-link" data-scroll-target="#modèle-linéaire-généralisé-mixte-glmm">Modèle linéaire généralisé mixte (GLMM)</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#bootstrap-1" id="toc-bootstrap-1" class="nav-link" data-scroll-target="#bootstrap-1">Bootstrap</a>
  <ul class="collapse">
  <li><a href="#principe-4" id="toc-principe-4" class="nav-link" data-scroll-target="#principe-4">Principe</a></li>
  <li><a href="#conditions-dapplication" id="toc-conditions-dapplication" class="nav-link" data-scroll-target="#conditions-dapplication">Conditions d’application</a></li>
  <li><a href="#avantages" id="toc-avantages" class="nav-link" data-scroll-target="#avantages">Avantages</a></li>
  <li><a href="#inconvénients" id="toc-inconvénients" class="nav-link" data-scroll-target="#inconvénients">Inconvénients</a></li>
  <li><a href="#applications-courantes" id="toc-applications-courantes" class="nav-link" data-scroll-target="#applications-courantes">Applications courantes</a></li>
  </ul></li>
  <li><a href="#effet-centre" id="toc-effet-centre" class="nav-link" data-scroll-target="#effet-centre">Effet centre</a>
  <ul class="collapse">
  <li><a href="#modèles-avec-erreurs-robustes" id="toc-modèles-avec-erreurs-robustes" class="nav-link" data-scroll-target="#modèles-avec-erreurs-robustes">Modèles avec erreurs robustes</a>
  <ul class="collapse">
  <li><a href="#bootstrap-en-grappe-cluster-bootstrap" id="toc-bootstrap-en-grappe-cluster-bootstrap" class="nav-link" data-scroll-target="#bootstrap-en-grappe-cluster-bootstrap">Bootstrap en grappe = cluster bootstrap</a></li>
  <li><a href="#estimateur-robuste-de-la-variance-sandwich-estimator-1" id="toc-estimateur-robuste-de-la-variance-sandwich-estimator-1" class="nav-link" data-scroll-target="#estimateur-robuste-de-la-variance-sandwich-estimator-1">Estimateur robuste de la variance (Sandwich estimator)</a></li>
  </ul></li>
  <li><a href="#modèles-linéaires-mixtes-lmm-et-modèles-linéaires-généralisés-mixtes-glmm" id="toc-modèles-linéaires-mixtes-lmm-et-modèles-linéaires-généralisés-mixtes-glmm" class="nav-link" data-scroll-target="#modèles-linéaires-mixtes-lmm-et-modèles-linéaires-généralisés-mixtes-glmm">Modèles linéaires mixtes (LMM) et modèles linéaires généralisés mixtes (GLMM)</a></li>
  <li><a href="#modèle-marginal-gee-generalized-estimating-equations" id="toc-modèle-marginal-gee-generalized-estimating-equations" class="nav-link" data-scroll-target="#modèle-marginal-gee-generalized-estimating-equations">Modèle marginal = GEE (Generalized Estimating Equations)</a></li>
  </ul></li>
  <li><a href="#données-manquantes" id="toc-données-manquantes" class="nav-link" data-scroll-target="#données-manquantes">Données manquantes</a>
  <ul class="collapse">
  <li><a href="#types-de-données-manquantes" id="toc-types-de-données-manquantes" class="nav-link" data-scroll-target="#types-de-données-manquantes">Types de données manquantes</a></li>
  <li><a href="#faire-la-différence-entre-mcar-mar-et-mnar" id="toc-faire-la-différence-entre-mcar-mar-et-mnar" class="nav-link" data-scroll-target="#faire-la-différence-entre-mcar-mar-et-mnar">Faire la différence entre MCAR, MAR et MNAR</a></li>
  <li><a href="#imputation-des-données-manquantes" id="toc-imputation-des-données-manquantes" class="nav-link" data-scroll-target="#imputation-des-données-manquantes">Imputation des données manquantes</a>
  <ul class="collapse">
  <li><a href="#imputation-simple" id="toc-imputation-simple" class="nav-link" data-scroll-target="#imputation-simple">Imputation simple</a></li>
  <li><a href="#imputation-multiple" id="toc-imputation-multiple" class="nav-link" data-scroll-target="#imputation-multiple">Imputation multiple</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#mesures-répétées-séries-chronologiques" id="toc-mesures-répétées-séries-chronologiques" class="nav-link" data-scroll-target="#mesures-répétées-séries-chronologiques">Mesures répétées / séries chronologiques</a>
  <ul class="collapse">
  <li><a href="#problème-posé" id="toc-problème-posé" class="nav-link" data-scroll-target="#problème-posé">Problème posé</a></li>
  <li><a href="#effet-sujet" id="toc-effet-sujet" class="nav-link" data-scroll-target="#effet-sujet">Effet sujet</a></li>
  <li><a href="#modèles-non-spécifiques-au-séries-chronologiques" id="toc-modèles-non-spécifiques-au-séries-chronologiques" class="nav-link" data-scroll-target="#modèles-non-spécifiques-au-séries-chronologiques">Modèles non spécifiques au séries chronologiques</a>
  <ul class="collapse">
  <li><a href="#modèles-linéaires-mixtes-lmm-et-modèles-linéaires-généralisés-mixtes-glmm-1" id="toc-modèles-linéaires-mixtes-lmm-et-modèles-linéaires-généralisés-mixtes-glmm-1" class="nav-link" data-scroll-target="#modèles-linéaires-mixtes-lmm-et-modèles-linéaires-généralisés-mixtes-glmm-1">Modèles linéaires mixtes (LMM) et modèles linéaires généralisés mixtes (GLMM)</a></li>
  <li><a href="#modèles-marginaux-gee" id="toc-modèles-marginaux-gee" class="nav-link" data-scroll-target="#modèles-marginaux-gee">Modèles marginaux (GEE)</a></li>
  </ul></li>
  <li><a href="#modèles-de-séries-chronologiques-arima-autoregressive-integrated-moving-average" id="toc-modèles-de-séries-chronologiques-arima-autoregressive-integrated-moving-average" class="nav-link" data-scroll-target="#modèles-de-séries-chronologiques-arima-autoregressive-integrated-moving-average">Modèles de séries chronologiques = ARIMA (AutoRegressive Integrated Moving Average)</a>
  <ul class="collapse">
  <li><a href="#modèle-auto-régressif-ar" id="toc-modèle-auto-régressif-ar" class="nav-link" data-scroll-target="#modèle-auto-régressif-ar">Modèle auto-régressif (AR)</a></li>
  <li><a href="#modèle-de-moyenne-mobile-ma" id="toc-modèle-de-moyenne-mobile-ma" class="nav-link" data-scroll-target="#modèle-de-moyenne-mobile-ma">Modèle de moyenne mobile (MA)</a></li>
  <li><a href="#modèles-complexes-arma-et-arima" id="toc-modèles-complexes-arma-et-arima" class="nav-link" data-scroll-target="#modèles-complexes-arma-et-arima">Modèles complexes : ARMA et ARIMA</a></li>
  <li><a href="#identification-des-paramètres-du-modèle" id="toc-identification-des-paramètres-du-modèle" class="nav-link" data-scroll-target="#identification-des-paramètres-du-modèle">Identification des paramètres du modèle</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#comparaisons-multiples" id="toc-comparaisons-multiples" class="nav-link" data-scroll-target="#comparaisons-multiples">Comparaisons multiples</a>
  <ul class="collapse">
  <li><a href="#pourquoi-ajuster" id="toc-pourquoi-ajuster" class="nav-link" data-scroll-target="#pourquoi-ajuster">Pourquoi ajuster ?</a></li>
  <li><a href="#quand-ajuster" id="toc-quand-ajuster" class="nav-link" data-scroll-target="#quand-ajuster">Quand ajuster ?</a></li>
  <li><a href="#méthodes-dajustement" id="toc-méthodes-dajustement" class="nav-link" data-scroll-target="#méthodes-dajustement">Méthodes d’ajustement</a>
  <ul class="collapse">
  <li><a href="#répartition-du-risque-alpha" id="toc-répartition-du-risque-alpha" class="nav-link" data-scroll-target="#répartition-du-risque-alpha">Répartition du risque alpha</a></li>
  <li><a href="#méthode-par-hierarchie" id="toc-méthode-par-hierarchie" class="nav-link" data-scroll-target="#méthode-par-hierarchie">Méthode par hierarchie</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#méthodes-non-supervisées" id="toc-méthodes-non-supervisées" class="nav-link" data-scroll-target="#méthodes-non-supervisées">Méthodes non supervisées</a>
  <ul class="collapse">
  <li><a href="#groupes-homogènes-de-sujets-clustering" id="toc-groupes-homogènes-de-sujets-clustering" class="nav-link" data-scroll-target="#groupes-homogènes-de-sujets-clustering">Groupes homogènes de sujets : clustering</a>
  <ul class="collapse">
  <li><a href="#analyse-en-composantes-principales-acp" id="toc-analyse-en-composantes-principales-acp" class="nav-link" data-scroll-target="#analyse-en-composantes-principales-acp">Analyse en composantes principales (ACP)</a></li>
  </ul></li>
  </ul></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="QUARTO-BIG-NOTES.pdf"><i class="bi bi-file-pdf"></i>PDF</a></li></ul></div></nav>
</div>
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">QUARTO BIG NOTES</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="résumé-statistique" class="level1">
<h1>Résumé statistique</h1>
<section id="position" class="level2">
<h2 class="anchored" data-anchor-id="position">Position</h2>
<section id="moyenne" class="level3">
<h3 class="anchored" data-anchor-id="moyenne">Moyenne</h3>
<ul>
<li><p>= centre de gravité des valeurs</p></li>
<li><p>suppose <strong>équivalence de la quantité</strong> : 1 euro voit 1 euro quelque soit sa position sur la droite des réels.</p></li>
</ul>
</section>
<section id="médiane" class="level3">
<h3 class="anchored" data-anchor-id="médiane">Médiane</h3>
<ul>
<li><p>Partage la distribution en 2 parts égales</p></li>
<li><p>Si distribution symétrique : moyenne = médiane</p></li>
</ul>
</section>
<section id="mode" class="level3">
<h3 class="anchored" data-anchor-id="mode">Mode</h3>
<ul>
<li>= Valeur la plus fréquente</li>
</ul>
</section>
</section>
<section id="dispersion" class="level2">
<h2 class="anchored" data-anchor-id="dispersion">Dispersion</h2>
<section id="empan" class="level3">
<h3 class="anchored" data-anchor-id="empan">Empan</h3>
<ul>
<li>= différence entre valeur minimale et valeur maximale</li>
</ul>
</section>
<section id="écart-interquartile" class="level3">
<h3 class="anchored" data-anchor-id="écart-interquartile">Écart interquartile</h3>
<ul>
<li>= Q3 - Q1</li>
</ul>
</section>
<section id="variance" class="level3">
<h3 class="anchored" data-anchor-id="variance">Variance</h3>
<ul>
<li>= Variance = moyenne des carrés des écarts à la moyenne</li>
</ul>
<p><span class="math display">\[
\text{v} = \frac{(\text{ecart}_1 - \mu)² + (\text{ecart}_2 - \mu)² + \dots + (\text{ecart}_n - \mu)²}{\text{nombre d'observation}}
\]</span></p>
</section>
<section id="écart-type" class="level3">
<h3 class="anchored" data-anchor-id="écart-type">Écart type</h3>
<ul>
<li><p>= racine carrée de la variance</p></li>
<li><p>= racine carrée des carrés des écarts à la moyenne</p></li>
<li><p>Avantages variances et écarts types :</p>
<ul>
<li><p>Carrés : positive écarts négatifs et accentue écarts importants</p></li>
<li><p>Variance de deux variables indépendantes est égales à la somme de leurs variances</p></li>
<li><p>Dans le cas d’une distribution normale :</p>
<ul>
<li><p>2/3 des observations se situent dans un intervalle de ±1 écart type autour de la moyenne</p></li>
<li><p>95% des observations se situent dans un intervalle de ±2 écart type autour de la moyenne</p></li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="fonction-r-pour-tout-ça" class="level3">
<h3 class="anchored" data-anchor-id="fonction-r-pour-tout-ça">Fonction R pour tout ça :</h3>
<ul>
<li><p><code>summary()</code> donne la moyenne, médiane, min, max, 1er et 3e quartile</p></li>
<li><p><code>describe()</code> pas mal de trucs aussi</p></li>
</ul>
</section>
</section>
<section id="dépendance-liaison-et-association" class="level2">
<h2 class="anchored" data-anchor-id="dépendance-liaison-et-association">Dépendance, liaison et association</h2>
<ul>
<li><p>Définition de la dépendance : deux variables sont dépendantes si la connaissance de la valeur de l’une permet de mieux prédire la valeur de l’autre</p></li>
<li><p>Par exemple : taille et poids sont dépendantes (plus on est grand, plus on pèse lourd)</p></li>
</ul>
<section id="variables-quantitatives" class="level3">
<h3 class="anchored" data-anchor-id="variables-quantitatives">Variables quantitatives</h3>
<ul>
<li><p>3 types de liaisons entre variables quantitatives :</p>
<ul>
<li><p>Dépendance : connaître X permet de mieux prédire Y</p></li>
<li><p>Dépendance monotone : X et Y varient dans le même sens (croissant ou décroissant)</p>
<ul>
<li><p>Dépendance linéaire : relation de proportionnalité entre X et Y</p></li>
<li><p>Corrélation linéaire (coefficient de corrélation linéaire de Pearson) = <span class="math inline">\(\text{r}\)</span> : mesure de la force de la dépendance linéaire entre X et Y</p></li>
<li><p>Coefficient de détermination = variance partagée <span class="math inline">\(\text{r}^2\)</span> : proportion de la variance de Y expliquée par sa projection linéaire sur X (régression linéaire simple)</p></li>
</ul></li>
<li><p>Concordance : X et Y varient dans le même sens mais pas forcément de façon linéaire</p>
<ul>
<li>Coefficient intraclasse : mesure de la concordance entre plusieurs mesures de la même variable</li>
</ul></li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 6%">
<col style="width: 28%">
<col style="width: 9%">
<col style="width: 54%">
</colgroup>
<tbody>
<tr class="odd">
<td><strong>Mesure</strong></td>
<td><strong>Paramètre</strong></td>
<td><strong>Symbole</strong></td>
<td><strong>Interprétation</strong></td>
</tr>
<tr class="even">
<td>Dépendance</td>
<td>Coefficient de corrélation linéaire</td>
<td>r</td>
<td><p>Mesure la direction et la force de la dépendance linéaire entre deux variables quantitatives.</p>
<p>Varie entre -1 et 1.</p></td>
</tr>
<tr class="odd">
<td>Dépendance</td>
<td>Coefficient de détermination (régression linéaire simple)</td>
<td>r²</td>
<td><p>Mesure la proportion de la variance de Y expliquée par sa projection linéaire sur X (régression linéaire simple).</p>
<p>Varie entre 0 et 1.</p></td>
</tr>
<tr class="even">
<td>Concordance</td>
<td>Coefficient intraclasse</td>
<td>ICC</td>
<td><p>Mesure la concordance entre plusieurs mesures de la même variable.</p>
<p>Varie entre 0 et 1.</p></td>
</tr>
<tr class="odd">
<td><em>Autre</em></td>
<td><em>Covariance</em></td>
<td>Cov(<span class="math inline">\(\text{X, Y}\)</span>)</td>
<td><em>Mesure comment deux variables varient ensemble (positive: ensemble ; négative : sens inverse)</em></td>
</tr>
</tbody>
</table>
<section id="dépendance-entre-variables-quantitatives" class="level4">
<h4 class="anchored" data-anchor-id="dépendance-entre-variables-quantitatives">Dépendance entre variables quantitatives</h4>
<ul>
<li>Pas de paramètre estimant parfaitement la dépendance ou l’indépendance entre deux variables quantitatives</li>
</ul>
</section>
<section id="dépendance-monotone-ou-linéaire-entre-variables-quantitatives" class="level4">
<h4 class="anchored" data-anchor-id="dépendance-monotone-ou-linéaire-entre-variables-quantitatives">Dépendance monotone ou linéaire entre variables quantitatives</h4>
<ul>
<li><p>Mesure de la direction dépendance linéaire : coefficient de corrélation linéaire de Pearson (<span class="math inline">\(\rho\)</span> ou <span class="math inline">\(\text{r}\)</span>)</p>
<ul>
<li><p>Varie entre -1 (<span class="math inline">\(\text{X} et \text{Y}\)</span> parfaitement négativement corrélées) et 1 (<span class="math inline">\(\text{X} et \text{Y}\)</span> parfaitement positivement corrélées)</p></li>
<li><p>0 : pas de corrélation linéaire entre X et Y = indépendance linéaire</p></li>
<li><p><strong>NB : le coefficient de corrélation ne mesure pas vraiment la force de la dépendance entre X et Y mais son type de dépendance !!</strong> <em>en pratique, mesure un peu la force quand même mais il n’y a pas d’unité pour l’exprimer</em></p></li>
<li><p>Mesure de la force de la dépendance linéaire : <strong>coefficient de détermination</strong> (<span class="math inline">\(\text{r}^2\)</span>)</p>
<ul>
<li><p>Varie entre 0 (pas de dépendance) et 1 (dépendance parfaite)</p></li>
<li><p>Indique la proportion de la variance de Y expliquée par sa projection linéaire sur X (régression linéaire simple)</p></li>
<li><p>Par exemple : <span class="math inline">\(\text{r} = 0.8\)</span> <span class="math inline">\(\Rightarrow\)</span> <span class="math inline">\(\text{r}^2 = 0.64\)</span> : 64% de la variance de Y est expliquée par sa projection linéaire sur X (régression linéaire simple) (et ce n’est pas <span class="math inline">\(\text{r}^2\)</span> des valeurs de Y sont expliquées par X !!)</p></li>
</ul></li>
</ul></li>
</ul>
<p>Remarque importante :</p>
<ul>
<li><p>Le coefficient r² correspond au coefficient de détermination d’une régression linéaire simple de Y sur X.</p></li>
<li><p>Il ne s’agit pas d’une symétrie entre X et Y : seule la variabilité de Y est décomposée.</p></li>
<li><p>La variance de X n’explique jamais directement la variance de Y.</p></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 28%">
<col style="width: 6%">
<col style="width: 64%">
</colgroup>
<tbody>
<tr class="odd">
<td>Paramètre</td>
<td>Symbole</td>
<td>Interprétation</td>
</tr>
<tr class="even">
<td>Coefficient de corrélation linéaire</td>
<td>r</td>
<td><p>Mesure la direction et la force de la dépendance linéaire entre deux variables quantitatives.</p>
<p>Varie entre -1 et 1.</p></td>
</tr>
<tr class="odd">
<td>Coefficient de détermination (régression linéaire simple)</td>
<td>r²</td>
<td><p>Mesure la proportion de la variance de Y expliquée par sa projection linéaire sur X (dans le cas d’une régression linéaire simple).</p>
<p>Varie entre 0 et 1.</p></td>
</tr>
<tr class="even">
<td>Covariance</td>
<td>Cov(X, Y)</td>
<td><p>Mesure la tendance conjointe de deux variables à varier ensemble.</p>
<p>Peut être positive, négative ou nulle.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="concordance-entre-variables-quantitatives" class="level4">
<h4 class="anchored" data-anchor-id="concordance-entre-variables-quantitatives">Concordance entre variables quantitatives</h4>
<ul>
<li><p>Mesure de la concordance entre variables quantitatives : <strong>coefficient intraclasse</strong> (ICC)</p></li>
<li><p>Varie entre 0 (pas de concordance) et 1 (concordance parfaite)</p></li>
<li><p>Indique la proportion de la variance totale attribuable à la variance entre les sujets</p></li>
<li><p>Calcul : <span class="math inline">\(\text{ICC} = \frac{\text{variance entre sujets}}{\text{variance entre sujets + variance entre examinateurs + variance résiduelle}}\)</span></p>
<ul>
<li><p>En gros : <span class="math inline">\(\text{ICC} = \frac{\text{vrai signal}}{\text{vrai signal} + \text{bruit}}\)</span></p></li>
<li><p>Vaut 1 quand aucun bruit (variance examinateurs et résiduelle = 0); vaut 0 quand tout est bruit (variance entre sujets = 0)</p></li>
<li><p>Par exemple : ICC = 0.75 : 75% de la variance totale est attribuable à la variance entre les sujets</p></li>
</ul></li>
<li><p>ICC le plus classiquement utilisé : 2-way random effects, absolute agreement, single rater/measurement</p></li>
</ul>
</section>
</section>
<section id="variables-catégorielles" class="level3">
<h3 class="anchored" data-anchor-id="variables-catégorielles">Variables catégorielles</h3>
<section id="dépendance-entre-variables-catégorielles" class="level4">
<h4 class="anchored" data-anchor-id="dépendance-entre-variables-catégorielles">Dépendance entre variables catégorielles</h4>
<ul>
<li><p>Mesure de la dépendance entre variables catégorielles : <strong>chi-carré de Pearson</strong> (<span class="math inline">\(\chi^2\)</span>)</p>
<ul>
<li><p>Existe-t-il une association entre deux variables catégorielles ?</p></li>
<li><p>Le <em>test du Chi-carré d’indépendance</em> permet de tester l’hypothèse nulle d’indépendance entre deux variables catégorielles, c’est à dire l’absence de relation entre elles.</p></li>
<li><p>Méthode :</p></li>
</ul></li>
<li><p>Pour évaluer la force de la relation : <strong>transformation normalisée du chi-carré</strong></p>
<ul>
<li><p><strong>Coefficient phi</strong> (<span class="math inline">\(\phi\)</span>) :</p>
<ul>
<li><p>Utile surtout pour un tableau <span class="math inline">\(2 \times 2\)</span> (deux variables binaires)</p></li>
<li><p><span class="math inline">\(|\phi| = \sqrt{\chi^2 / n}\)</span> où <span class="math inline">\(n\)</span> = taille de l’échantillon</p></li>
<li><p>Correspond à la corrélation de Pearson entre deux variables binaires codées 0/1 (version signée entre -1 et 1)</p></li>
</ul></li>
<li><p><strong>V de Cramér</strong> (<span class="math inline">\(V\)</span>) :</p>
<ul>
<li><p>Utile pour un tableau <span class="math inline">\(r \times c\)</span> (variables nominales, possiblement <span class="math inline">\(&gt; 2\)</span> modalités)</p></li>
<li><p><span class="math inline">\(V = \sqrt{\chi^2 / (n (k - 1))}\)</span> avec <span class="math inline">\(k = \min(r, c)\)</span></p></li>
<li><p>Varie entre 0 (pas d’association) et 1 (association parfaite)</p></li>
</ul></li>
<li><p><strong>Coefficient de contingence de Pearson</strong> (<span class="math inline">\(C\)</span>) :</p>
<ul>
<li><p><span class="math inline">\(C = \sqrt{\chi^2 / (\chi^2 + n)}\)</span></p></li>
<li><p>Utilisable pour des tableaux <span class="math inline">\(r \times c\)</span>, mais l’échelle dépend de la taille du tableau : <span class="math inline">\(C\)</span> ne peut pas atteindre 1 et n’est pas directement comparable entre tableaux de dimensions différentes</p></li>
<li><p>Varie entre 0 et <span class="math inline">\(C_{max}\)</span> avec <span class="math inline">\(C_{max} = \sqrt{(k-1)/k}\)</span> (donc <span class="math inline">\(C&lt;1\)</span>), où <span class="math inline">\(k = \min(r, c)\)</span></p></li>
<li><p>Lien avec <span class="math inline">\(\phi\)</span> (cas <span class="math inline">\(2 \times 2\)</span>) : <span class="math inline">\(C\)</span> est juste un re-calage de <span class="math inline">\(|\phi|\)</span> : <span class="math inline">\(C = \frac{|\phi|}{\sqrt{1+\phi^2}}\)</span> (donc même ordre/monotonie, mais valeurs plus “compressées”)</p></li>
</ul></li>
<li><p><strong>Coefficient de corrélation de Spearman</strong> <span class="math inline">\(\rho_s\)</span> :</p>
<ul>
<li><p>Pour des variables <strong>ordinales</strong> (ou une relation <strong>monotone</strong> non linéaire entre deux quantitatives)</p></li>
<li><p>= corrélation de Pearson calculée sur les rangs, varie entre -1 et 1</p></li>
</ul></li>
</ul></li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 20%">
<col style="width: 26%">
<col style="width: 52%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Mesure</strong></th>
<th><strong>Paramètre</strong></th>
<th><strong>Interprétation</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Dépendance</td>
<td>Chi-carré de Pearson</td>
<td><p>Mesure l’association entre deux variables catégorielles.</p>
<p>Valeur plus élevée indique une association plus forte.</p></td>
</tr>
<tr class="even">
<td>Dépendance (2 variables binaires)</td>
<td>Coefficient phi (φ)</td>
<td>Varie entre -1 et 1.</td>
</tr>
<tr class="odd">
<td>Dépendance (variables nominales)</td>
<td>V de Cramér (V)</td>
<td><p>Mesure la force de l’association entre deux variables nominales.</p>
<p>Varie entre 0 et 1.</p></td>
</tr>
<tr class="even">
<td>Dépendance (variables nominales)</td>
<td>Coefficient de contingence (C)</td>
<td>Varie entre 0 et C_max (dépendant de la taille du tableau).</td>
</tr>
<tr class="odd">
<td>Dépendance (variables ordinales)</td>
<td>Coefficient de corrélation de Spearman (ρs)</td>
<td><p>Mesure la force et la direction de l’association monotone entre deux variables ordinales.</p>
<p>Varie entre -1 et 1.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="dépendance-monotone" class="level4">
<h4 class="anchored" data-anchor-id="dépendance-monotone">Dépendance monotone</h4>
<ul>
<li><p>Uniquement pour des variables ordinales (ou une relation monotone non linéaire entre deux quantitatives)</p></li>
<li><p>Mesure de la dépendance monotone entre variables ordinales : <strong>coefficient de corrélation de Spearman</strong> (<span class="math inline">\(\rho_s\)</span>)</p>
<ul>
<li><p>= corrélation de Pearson calculée sur les rangs</p></li>
<li><p>Varie entre -1 (dépendance monotone négative parfaite) et 1 (dépendance monotone positive parfaite)</p></li>
<li><p>0 : pas de dépendance monotone entre X et Y = indépendance monotone</p></li>
</ul></li>
</ul>
</section>
<section id="concordance-entre-variables-catégorielles" class="level4">
<h4 class="anchored" data-anchor-id="concordance-entre-variables-catégorielles">Concordance entre variables catégorielles</h4>
<ul>
<li><p>Mesure de la concordance entre variables catégorielles : <strong>kappa de Cohen</strong> (<span class="math inline">\(\kappa\)</span>)</p>
<ul>
<li><p>Pour deux évaluateurs classant des sujets dans des catégories (variables nominales ou ordinales)</p></li>
<li><p>Varie entre -1 (désaccord parfait) et 1 (accord parfait)</p></li>
<li><p>0 : accord équivalent au hasard</p></li>
<li><p><span class="math inline">\(\kappa = \frac{\text{concordance observee } - \text{ concordance due au hasard}}{1\ - \text{ concordance due au hasard}}\)</span></p></li>
</ul></li>
</ul>
</section>
<section id="or-et-rr-pour-variables-binaires" class="level4">
<h4 class="anchored" data-anchor-id="or-et-rr-pour-variables-binaires">OR et RR pour variables binaires</h4>
<p>Pour un tableau de contingence <span class="math inline">\(2 \times 2\)</span> :</p>
<table class="caption-top table">
<colgroup>
<col style="width: 27%">
<col style="width: 27%">
<col style="width: 26%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>Événement présent</th>
<th>Événement absent</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Groupe exposé</td>
<td>a</td>
<td>b</td>
</tr>
<tr class="even">
<td>Groupe non exposé</td>
<td>c</td>
<td>d</td>
</tr>
</tbody>
</table>
<ul>
<li><p><strong>Odds Ratio (OR)</strong> :</p>
<ul>
<li><p>Mesure la force de l’association entre deux variables binaires</p></li>
<li><p>Odds = probabilité qu’un événement se produise / probabilité qu’il ne se produise pas = <span class="math inline">\(\text{R} / (1 - \text{R})\)</span></p></li>
<li><p>= (odds d’un événement dans le groupe exposé) / (odds d’un événement dans le groupe non exposé) = <span class="math inline">\(\frac{\text{R}_1 / (1 - \text{R}_1)}{\text{R}_0 / (1 - \text{R}_0)}\)</span></p></li>
<li><p>= <span class="math inline">\(\frac{a/b}{c/d} = \frac{a \times d}{b \times c}\)</span></p></li>
<li><p>Interprétation :</p>
<ul>
<li><p>OR = 1 : pas d’association entre exposition et événement</p></li>
<li><p>OR &gt; 1 : exposition associée à une augmentation des odds de l’événement</p></li>
<li><p>OR &lt; 1 : exposition associée à une diminution des odds de l’événement</p></li>
</ul></li>
<li><p>Attention 1 : les odds ne sont pas des probabilités !</p></li>
<li><p>Attention 2 : pour des événements fréquents, l’OR peut surestimer la force de l’association par rapport au RR</p></li>
</ul></li>
<li><p><strong>Risque relatif (RR)</strong> :</p>
<ul>
<li><p>Mesure la force de l’association entre deux variables binaires</p></li>
<li><p>= (risque d’un événement dans le groupe exposé) / (risque d’un événement dans le groupe non exposé) = <span class="math inline">\(\text{R}_1 / \text{R}_0\)</span></p></li>
<li><p>= <span class="math inline">\(\frac{a/(a+b)}{c/(c+d)}\)</span></p></li>
<li><p>Interprétation :</p>
<ul>
<li><p>RR = 1 : pas d’association entre exposition et événement</p></li>
<li><p>RR &gt; 1 : exposition associée à une augmentation du risque de l’événement</p></li>
<li><p>RR &lt; 1 : exposition associée à une diminution du risque de l’événement</p></li>
</ul></li>
<li><p>Le RR est souvent plus intuitif que l’OR, surtout pour des événements fréquents</p></li>
<li><p>Cependant, le RR ne peut être estimé directement que dans des études de cohorte ou essais cliniques, pas dans des études cas-témoins</p></li>
</ul></li>
<li><p>Rapport entre OR et RR :</p>
<ul>
<li><p>Pour des événements rares (incidence &lt;= 10%), OR ≈ RR</p></li>
<li><p>Pour des événements fréquents, OR surestime le RR car les odds augmentent plus rapidement que les probabilités.</p></li>
</ul></li>
</ul>
<section id="tableau-récapitulatif-or-vs-rr" class="level5">
<h5 class="anchored" data-anchor-id="tableau-récapitulatif-or-vs-rr">Tableau récapitulatif OR vs RR</h5>
<table class="caption-top table">
<colgroup>
<col style="width: 8%">
<col style="width: 45%">
<col style="width: 45%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>Odds Ratio (OR)</th>
<th>Risque relatif (RR)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Définition</td>
<td>Ratio des odds entre deux groupes</td>
<td>Ratio des risques entre deux groupes</td>
</tr>
<tr class="even">
<td>Formule</td>
<td>(a/b)/(c/d) = (a × d)/(b × c)</td>
<td>(a/(a+b))/(c/(c+d))</td>
</tr>
<tr class="odd">
<td>Interprétation</td>
<td>OR = 1 : pas d’association ; OR &gt; 1 : odds plus élevées ; OR &lt; 1 : odds plus faibles</td>
<td>RR = 1 : pas d’association ; RR &gt; 1 : risque plus élevé ; RR &lt; 1 : risque plus faible</td>
</tr>
<tr class="even">
<td>Estimabilité</td>
<td>Études cas-témoins, cohortes, essais cliniques</td>
<td>Cohortes et essais cliniques (pas cas-témoins)</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="sensibilité-et-spécificité-vpp-et-vpn" class="level4">
<h4 class="anchored" data-anchor-id="sensibilité-et-spécificité-vpp-et-vpn">Sensibilité et spécificité, VPP et VPN</h4>
<ul>
<li><p>Le kappa de Cohen mesure une <strong>concordance globale et symétrique</strong> entre deux évaluateurs, mais ne distingue pas les types d’erreurs (faux positifs vs faux négatifs)</p></li>
<li><p>Pour évaluer la performance d’un test diagnostique binaire, on utilise des mesures spécifiques :</p>
<ul>
<li><p>Sensibilité = proportion de vrais positifs parmi les cas positifs réels = <span class="math inline">\(\text{P}(\text{Y} = 1 | \text{X} = 1)\)</span></p></li>
<li><p>Spécificité = proportion de vrais négatifs parmi les cas négatifs réels = <span class="math inline">\(\text{P}(\text{Y} = 0 | \text{X} = 0)\)</span></p></li>
</ul></li>
<li><p>Le problème de la sensibilité et spécificité est qu’elles ne tiennent pas compte de la prévalence de la condition dans la population (par exemple, dans le dépistage d’une maladie rare, un test peut avoir une haute sensibilité et spécificité mais produire beaucoup de faux positifs)</p>
<ul>
<li><p>VPP = proportion de vrais positifs parmi les résultats positifs du test = <span class="math inline">\(\text{P}(\text{X} = 1 | \text{Y} = 1)\)</span></p></li>
<li><p>VPN = proportion de vrais négatifs parmi les résultats négatifs du test = <span class="math inline">\(\text{P}(\text{X} = 0 | \text{Y} = 0)\)</span></p></li>
</ul></li>
</ul>
<p>Dans un tableau de contingence <span class="math inline">\(2 \times 2\)</span> :</p>
<table class="caption-top table">
<colgroup>
<col style="width: 30%">
<col style="width: 29%">
<col style="width: 30%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>Condition présente</th>
<th>Condition absente</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Test positif</td>
<td>a</td>
<td>b</td>
</tr>
<tr class="even">
<td>Test négatif</td>
<td>c</td>
<td>d</td>
</tr>
</tbody>
</table>
<ul>
<li><p>Sensibilité = a / (a + c)</p></li>
<li><p>Spécificité = d / (b + d)</p></li>
<li><p>VPP = a / (a + b)</p></li>
<li><p>VPN = d / (c + d)</p></li>
</ul>
<div style="page-break-after: always;"></div>
</section>
</section>
</section>
</section>
<section id="tests-statistiques" class="level1">
<h1>Tests statistiques</h1>
<section id="comment-les-utiliser" class="level2">
<h2 class="anchored" data-anchor-id="comment-les-utiliser">Comment les utiliser ?</h2>
<section id="intérêt" class="level3">
<h3 class="anchored" data-anchor-id="intérêt">Intérêt</h3>
<ul>
<li><p>Outils d’inférence : passer de ce qui est observé sur un échantillon à une affirmation sur une population plus large</p></li>
<li><p>Langage commun de la communauté scientifique</p></li>
</ul>
</section>
<section id="légitimité" class="level3">
<h3 class="anchored" data-anchor-id="légitimité">Légitimité</h3>
<ul>
<li><p>Usage légitime si répond à une question scientifique précise, formulée a priori</p></li>
<li><p>Usage illégitime si utilisé pour “fouiller” les données à la recherche d’effets significatifs :</p>
<ul>
<li><p>Test de normalité (Shapiro-Wilk, Kolmogorov-Smirnov, etc.) sur chaque variable</p></li>
<li><p>Tester les caractristiques des perdus de vue…</p></li>
</ul></li>
<li><p>Donc n’est pas un substitut au raisonnement scientifique</p></li>
</ul>
</section>
</section>
<section id="types-de-tests" class="level2">
<h2 class="anchored" data-anchor-id="types-de-tests">Types de tests</h2>
<section id="comparaison-de-pourcentages" class="level3">
<h3 class="anchored" data-anchor-id="comparaison-de-pourcentages">Comparaison de pourcentages</h3>
<section id="test-du-chi-carré-dindépendance" class="level4">
<h4 class="anchored" data-anchor-id="test-du-chi-carré-dindépendance">Test du Chi-carré d’indépendance</h4>
<ul>
<li><p>Compare la <strong>répartition des fréquences</strong> observées dans un tableau de contingence à celles attendues sous l’hypothèse d’indépendance entre les variables</p></li>
<li><p>En fait, il teste l’hypothèse nulle d’indépendance entre deux variables catégorielles</p></li>
<li><p>Conditions de validité :</p>
<ul>
<li><p>Effectifs théoriques &gt;= 5 dans chque case des tableaux</p></li>
<li><p>Observations indépendantes</p></li>
<li><p>Distribution des effectifs suit une loi du Chi-carré (c’est à dire que les effectifs sont suffisamment grands pour que la distribution asymptotique du Chi-carré soit une bonne approximation de la distribution réelle des effectifs sous l’hypothèse nulle)</p></li>
</ul></li>
<li><p>Si conditions non remplies : test exact de Fisher (pour tableaux <span class="math inline">\(2 \times 2\)</span>)</p></li>
<li><p>Rapport Chi-2 et OR :</p>
<ul>
<li><p>Le test du Chi-carré teste l’hypothèse nulle d’indépendance entre deux variables catégorielles, ce qui est équivalent à tester si l’odds ratio (OR) est égal à 1 dans un tableau de contingence <span class="math inline">\(2 \times 2\)</span>.</p></li>
<li><p>Donc la p-value du test du chi-carré et celle du test “OR=1” sont identiques.</p></li>
<li><p>Si chi-carré est significatif, ça vaut le coup de calculer l’OR pour quantifier la force de l’association entre les variables.</p></li>
</ul></li>
</ul>
</section>
<section id="test-exact-de-fisher" class="level4">
<h4 class="anchored" data-anchor-id="test-exact-de-fisher">Test exact de Fisher</h4>
<ul>
<li><p>Compare la <strong>répartition des fréquences</strong> dans des petits échantillons</p></li>
<li><p>Utilisé quand les effectifs théoriques sont trop petits pour le test du Chi-carré</p></li>
</ul>
</section>
<section id="comparaison-dun-pourcentage-à-une-valeur-théorique" class="level4">
<h4 class="anchored" data-anchor-id="comparaison-dun-pourcentage-à-une-valeur-théorique">Comparaison d’un pourcentage à une valeur théorique</h4>
<ul>
<li><p>Test exact de binomial</p></li>
<li><p>Situation peu fréquente en pratique ! Par exemple équiprobabilité des naissances garçons/filles</p></li>
</ul>
</section>
<section id="comparaison-de-3-pourcentages-ou-plus" class="level4">
<h4 class="anchored" data-anchor-id="comparaison-de-3-pourcentages-ou-plus">Comparaison de 3 pourcentages ou plus</h4>
<ul>
<li><p>Situation peu fréquente non plus !</p></li>
<li><p>Idem avec un test du Chi-carré d’indépendance</p></li>
<li><p>Le problème pour l’interprétation de la p-value : si significatif, on ne sait pas où est la différence</p></li>
<li><p>Il faut dans ce cas faire un <em>Chi-carré de tendance</em></p></li>
</ul>
</section>
</section>
<section id="comparaison-de-moyennes" class="level3">
<h3 class="anchored" data-anchor-id="comparaison-de-moyennes">Comparaison de moyennes</h3>
<ul>
<li><p>Test t de Student</p></li>
<li><p>test de Welch</p></li>
<li><p>test t de Student apparié</p></li>
<li><p>test non paramétrique de Wilcoxon</p>
<ul>
<li><p>test de Mann-Whitney pour échantillons indépendants</p></li>
<li><p>test de Wilcoxon pour échantillons appariés</p></li>
</ul></li>
</ul>
<div style="page-break-after: always;"></div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Résumé des tests de comparaison de moyennes</strong></p>
<ul>
<li><p>Comparaison de moyennes avec test t de Student :</p>
<ul>
<li><p>Effectif : &gt; 30 par groupe ou à peu près égaux (11 et 12 par exemple)</p></li>
<li><p>Distribution : symétrique (approximativement normale) et variances à peu près égales</p></li>
</ul></li>
<li><p>Si échantillons appariés : test t apparié, ou Wilcoxon apparié (= signed rank)</p></li>
<li><p>Si distribution très asymétrique : test non paramétrique de Mann-Whitney (= Wilcoxon non apparié = rank sum)</p></li>
<li><p>Si effectifs très inégaux ou variances très différentes : test de Welch</p></li>
</ul>
</div>
</div>
<section id="test-t-de-student" class="level4">
<h4 class="anchored" data-anchor-id="test-t-de-student">Test t de Student</h4>
<ul>
<li><p>Compare les moyennes de deux échantillons indépendants</p></li>
<li><p>Conditions de validité :</p>
<ul>
<li><p>Variable continue</p></li>
<li><p>Distribution normale dans chaque groupe (en pratique : n &gt;= 30 par groupe)</p></li>
<li><p>Homogénéité des variances entre les groupes = homoscédasticité, <strong>appréciée par QQplot !!</strong></p></li>
</ul></li>
<li><p>Si conditions non remplies : test de Welch (si variances inégales) ou test non paramétrique de Mann-Whitney (si distribution non normale)</p></li>
</ul>
</section>
<section id="test-de-welch" class="level4">
<h4 class="anchored" data-anchor-id="test-de-welch">Test de Welch</h4>
<ul>
<li><p>Compare les moyennes de deux échantillons indépendants</p></li>
<li><p>Variante du test t de Student qui ne suppose pas l’homogénéité des variances entre les groupes</p></li>
</ul>
</section>
<section id="test-t-de-student-apparié" class="level4">
<h4 class="anchored" data-anchor-id="test-t-de-student-apparié">Test t de Student apparié</h4>
<ul>
<li>Compare les moyennes de deux échantillons appariés (mêmes sujets mesurés deux fois, ou sujets appariés par paires)</li>
</ul>
</section>
<section id="test-non-paramétrique-de-wilcoxon" class="level4">
<h4 class="anchored" data-anchor-id="test-non-paramétrique-de-wilcoxon">Test non paramétrique de Wilcoxon</h4>
<ul>
<li><p>Compare les distributions de deux échantillons indépendants ou appariés</p></li>
<li><p>Ne suppose pas la normalité des distributions : utilise les rangs des données plutôt que les valeurs brutes</p></li>
<li><p>Échantillons indépendants : test de Mann-Whitney</p></li>
<li><p>Échantillons appariés : test de Wilcoxon</p></li>
</ul>
</section>
<section id="comparaison-de-3-moyennes-ou-plus" class="level4">
<h4 class="anchored" data-anchor-id="comparaison-de-3-moyennes-ou-plus">Comparaison de 3 moyennes ou plus</h4>
<ul>
<li><p>Comparaison pas si fréquente !</p></li>
<li><p>Comparasion de moyennes avec ANOVA :</p>
<ul>
<li><p>Si une variable à une distribution égale dans plusieurs groupes, alors la variance intra-groupe est proche de la variance inter-groupe</p></li>
<li><p>On passe par la comparaison des variances car pas de test t pour plus de 2 groupes</p></li>
<li><p>ANOVA : calcule le ratio de la variance inter-groupe sur la variance intra-groupe</p></li>
</ul></li>
<li><p>Conditions de validité :</p>
<ul>
<li><p>Indépendance des observations</p></li>
<li><p>Normalité des distributions dans chaque groupe et homogénéité des variances entre les groupes (homoscédasticité appréciée par QQplot)</p></li>
</ul></li>
<li><p>Si conditions non remplies : test non paramétrique de Kruskal-Wallis</p></li>
<li><p>Sur R : il faut passer par une régression linéaire (<code>lm</code>ou <code>lmer</code>) pour faire une ANOVA car :</p>
<ul>
<li><p>ANOVA est un cas particulier de régression linéaire quand les variables explicatives sont catégorielles</p></li>
<li><p>La régression linéaire et l’ANOVA utilisent toutes les deux le même principe : analyser la variance totale en variance expliquée par le modèle et variance résiduelle.</p></li>
</ul></li>
</ul>
</section>
</section>
<section id="test-de-nullité-dun-coefficient-de-corrélation" class="level3">
<h3 class="anchored" data-anchor-id="test-de-nullité-dun-coefficient-de-corrélation">Test de nullité d’un coefficient de corrélation</h3>
<ul>
<li><p>Les coefficients de corrélation (Pearson, Spearman, etc.) mesurent la force et la direction de la relation entre deux variables</p></li>
<li><p>Coefficients de corrélation :</p>
<ul>
<li><p>Variables quantitatives :</p>
<ul>
<li><p>Coefficient de corrélation linéaire de Pearson (variables continues). Varie entre -1 et 1.</p></li>
<li><p>Coefficient de corrélation de Spearman (variables ordinales). Varie entre -1 et 1. Basé sur les rangs.</p></li>
</ul></li>
<li><p>Variables catégorielles :</p>
<ul>
<li><p>Coefficient phi (φ) pour tableaux <span class="math inline">\(2 \times 2\)</span>. Varie entre -1 et 1.</p></li>
<li><p>V de Cramér (V) pour tableaux <span class="math inline">\(r \times c\)</span>. Varie entre 0 et 1.</p></li>
</ul></li>
<li><p>Accord entre évaluateurs :</p>
<ul>
<li><p>Coefficient de corrélation intraclasse (ICC(2,1)). Varie entre -∞ et 1 (en pratique 0 à 1).</p></li>
<li><p>Kappa de Cohen (κ). Varie entre -1 et 1.</p></li>
</ul></li>
</ul></li>
<li><p>Test de nullité d’un coefficient de corrélation :</p>
<ul>
<li><p>Permet de tester l’hypothèse nulle selon laquelle il n’y a pas de relation entre les variables</p></li>
<li><p>Coefficient : pas forcément égal à 0 dans la population !!</p></li>
</ul></li>
</ul>
</section>
<section id="tests-appariés" class="level3">
<h3 class="anchored" data-anchor-id="tests-appariés">Tests appariés</h3>
<ul>
<li><p>Utilisés lorsque les observations sont liées ou dépendantes</p></li>
<li><p>Exemple : mesures répétées sur les mêmes sujets, ou sujets appariés par paires</p></li>
<li><p>Tests appariés courants :</p>
<ul>
<li><p>Sur des moyennes :</p>
<ul>
<li><p>Test t de Student apparié : compare les moyennes de deux échantillons appariés</p></li>
<li><p>Test de Wilcoxon apparié : compare les distributions de deux échantillons appariés (non paramétrique)</p></li>
</ul></li>
<li><p>Sur des pourcentages :</p>
<ul>
<li><p>Test du Chi2 de McNemar : compare les proportions dans des échantillons appariés (variables binaires)</p></li>
<li><p>Test exact du Chi2 de McNemar : version exacte du test de McNemar pour petits échantillons</p></li>
</ul></li>
</ul></li>
</ul>
<div style="page-break-after: always;"></div>
</section>
</section>
<section id="calcul-de-beta-et-du-nombre-de-sujets-à-inclure" class="level2">
<h2 class="anchored" data-anchor-id="calcul-de-beta-et-du-nombre-de-sujets-à-inclure">Calcul de <span class="math inline">\(\beta\)</span> et du nombre de sujets à inclure</h2>
<ul>
<li><p>Dans la théorie de Neyman et Pearson, on fixe un seuil de risque de première espèce (<span class="math inline">\(\alpha\)</span>) et un seuil de risque de deuxième espèce (<span class="math inline">\(\beta\)</span>)</p></li>
<li><p><span class="math inline">\(\alpha\)</span> : probabilité de rejeter l’hypothèse nulle alors qu’elle est vraie (faux positif)</p></li>
<li><p><span class="math inline">\(\beta\)</span> : probabilité de ne pas rejeter l’hypothèse nulle alors qu’elle est fausse (faux négatif)</p></li>
<li><p>La puissance d’un test est égale à <span class="math inline">\(1 - \beta\)</span> : probabilité de rejeter l’hypothèse nulle quand elle est fausse (vrai positif)</p></li>
<li><p><span class="math inline">\(\beta\)</span> varie selon :</p>
<ul>
<li><p>La différence vraie : plus la différence vraie est grande, plus la puissance est élevée (et <span class="math inline">\(\beta\)</span> faible)</p></li>
<li><p>Le nombre de sujets inclus : plus le nombre de sujets est grand, plus la puissance est élevée (et <span class="math inline">\(\beta\)</span> faible)</p></li>
<li><p>La variabilité des données : plus la variabilité est faible, plus la puissance est élevée (et <span class="math inline">\(\beta\)</span> faible)</p></li>
<li><p><span class="math inline">\(\text{H}_1\)</span> choisi : plus <span class="math inline">\(\text{H}_1\)</span> est éloigné de <span class="math inline">\(\text{H}_0\)</span>, plus la puissance est élevée (et <span class="math inline">\(\beta\)</span> faible).</p>
<ul>
<li>S’ils sont proches, il est plus difficile de les distinguer donc <span class="math inline">\(\beta\)</span> est plus élevé</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="tests-uni--ou-bilatéraux" class="level2">
<h2 class="anchored" data-anchor-id="tests-uni--ou-bilatéraux">Tests uni- ou bilatéraux</h2>
<ul>
<li><p>Selon Fisher :</p>
<ul>
<li><p>L’inférence statistique est <strong>bilatérale</strong> par nature :</p>
<ul>
<li><p>on cherche à apprécier l’adéquation entre un échantillon observé et une population hypothétique infinie sous-jacente</p></li>
<li><p>donc test si l’estimateur issu de l’échantillon est supérieur ou inférieur à la valeur hypothétique</p></li>
</ul></li>
</ul></li>
<li><p>Selon Neyman et Pearson :</p>
<ul>
<li>inférence statistique <strong>unilatérale</strong> ou <strong>bilatérale</strong> selon le choix des hypothèses <span class="math inline">\(\H_0\)</span> et <span class="math inline">\(\H_1\)</span></li>
</ul></li>
</ul>
</section>
<section id="intervalles-de-confiance" class="level2">
<h2 class="anchored" data-anchor-id="intervalles-de-confiance">Intervalles de confiance</h2>
<ul>
<li><p>Définitions :</p>
<ul>
<li><p>IC = intervalle estimé à partir des données d’un échantillon, qui a une probabilité donnée (le niveau de confiance) de contenir la vraie valeur du paramètre dans la population.</p></li>
<li><p>IC à 95% = si on répétait l’expérience de prélèvement d’échantillons et de calcul d’IC plusieurs fois, environ 95% des IC ainsi obtenus contiendraient la vraie moyenne de la population.</p></li>
</ul></li>
<li><p><strong>Ça ne veut pas dire “95% des valeurs sont dans l’IC” !!</strong></p></li>
</ul>
<div style="page-break-after: always;"></div>
</section>
</section>
<section id="modèles" class="level1">
<h1>Modèles</h1>
<section id="modèle-linéaire" class="level2">
<h2 class="anchored" data-anchor-id="modèle-linéaire">Modèle linéaire</h2>
<section id="définition" class="level3">
<h3 class="anchored" data-anchor-id="définition">Définition</h3>
<ul>
<li><p>Modèle statistique qui décrit la relation linéaire entre une variable dépendante (Y) et une ou plusieurs variables indépendantes (X)</p></li>
<li><p>Modèle linéaire = modèle de régression linéaire = régression linéaire.</p></li>
<li><p>Utilisé quand la variable dépendante <span class="math inline">\(\text{Y}\)</span> est continue et suit une distribution normale</p></li>
<li><p>Forme générale : <span class="math inline">\(\text{Y} = \alpha_0 + \alpha_1 \text{X}_1 + \alpha_2 \text{X}_2 + \dots + \alpha_p \text{X}_p + \epsilon\)</span></p>
<ul>
<li><p><span class="math inline">\(\text{Y}\)</span> : variable dépendante</p></li>
<li><p><span class="math inline">\(\text{X}_1, \text{X}_2, ..., \text{X}_p\)</span> : variables indépendantes (prédicteurs)</p></li>
<li><p><span class="math inline">\(\alpha_0\)</span> : intercept (valeur de Y quand toutes les X sont nulles)</p></li>
<li><p><span class="math inline">\(\alpha_1, \alpha_2, ..., \alpha_p\)</span> : coefficients de régression (effet de chaque X sur Y)</p></li>
<li><p><span class="math inline">\(\epsilon\)</span> : terme d’erreur (variabilité non expliquée par le modèle)</p></li>
</ul></li>
<li><p>Méthode des moindres carrés pour estimer les coefficients : minimise la somme des carrés des écarts entre les valeurs observées et les valeurs prédites par le modèle</p>
<ul>
<li>En gros : estimer les coefficients de régression (<span class="math inline">\(\alpha_0, \alpha_1, ..., \alpha_p\)</span>) pour que la ligne de régression soit la “meilleure” possible, c’est à dire pour que <span class="math inline">\(\epsilon\)</span> soit le plus petit possible</li>
</ul></li>
<li><p>Relation avec ANOVA : l’ANOVA est un cas particulier du modèle linéaire où les variables indépendantes sont catégorielles.</p></li>
<li><p>Conditions de validité :</p>
<ul>
<li><p>Linéarité : relation linéaire entre chaque X et Y</p></li>
<li><p>Indépendance des erreurs, normalité des erreurs, variance constante des erreurs (erreurs = résidus du modèle)</p></li>
</ul></li>
<li><p>Interprétation :</p>
<ul>
<li><p>Chaque coefficient de régression (<span class="math inline">\(\alpha_i\)</span>) représente l’effet moyen d’une unité de changement dans la variable indépendante <span class="math inline">\(\text{X}_i\)</span> sur la variable dépendante <span class="math inline">\(\text{Y}\)</span>, en maintenant toutes les autres variables indépendantes constantes.</p></li>
<li><p>Par exemple, si <span class="math inline">\(\alpha_1 = 2\)</span>, cela signifie qu’une augmentation de 1 unité de <span class="math inline">\(\text{X}_1\)</span> est associée à une augmentation moyenne de 2 unités de <span class="math inline">\(\text{Y}\)</span>, toutes choses égales par ailleurs.</p></li>
</ul></li>
</ul>
</section>
<section id="corrélation-et-modèle-linéaire" class="level3">
<h3 class="anchored" data-anchor-id="corrélation-et-modèle-linéaire">Corrélation et modèle linéaire</h3>
<ul>
<li><p>Corrélation et régression linéaire décrivent toutes deux une <strong>relation linéaire</strong> entre deux variables quantitatives</p></li>
<li><p>Corrélation linéaire = coefficient de corrélation linéaire de Pearson (<span class="math inline">\(\text{r}\)</span>) :</p>
<ul>
<li><p>Mesure descriptive</p></li>
<li><p>Évalue si <span class="math inline">\(\text{X}\)</span> et <span class="math inline">\(\text{Y}\)</span> ont une relation linéaire</p></li>
<li><p>Symétrique : <span class="math inline">\(\text{corr}(\text{X, Y}) = \text{corr}(\text{Y, X})\)</span></p></li>
<li><p>Varie entre -1 et 1 mais ne permet aucune prédiction chiffrée.</p></li>
</ul></li>
<li><p>Régression linéaire simple :</p>
<ul>
<li><p>Modèle statistique prédictif</p></li>
<li><p>Décrit la valeur moyenne de <span class="math inline">\(\text{Y}\)</span> pour une valeur donnée de <span class="math inline">\(\text{X}\)</span></p></li>
<li><p>Asymétrique : prédit <span class="math inline">\(\text{Y}\)</span> à partir de <span class="math inline">\(\text{X}\)</span>, pas l’inverse</p></li>
<li><p>Fournit une équation de la droite de régression : <span class="math inline">\(\text{Y} = \alpha_0 + \alpha_1 \text{X} + \epsilon\)</span></p></li>
</ul></li>
<li><p>Relation entre <span class="math inline">\(\text{r}\)</span> et régression linéaire <strong>simple</strong> (donc une seule variable <span class="math inline">\(\text{X}\)</span>) :</p>
<ul>
<li><p>Lorsque la corrélation est parfaite (<span class="math inline">\(\text{r} = \pm 1\)</span>), la droite de régression passe par tous les points de données (pas d’erreur)</p>
<ul>
<li><span class="math inline">\(\text{Y}\)</span> peut être parfaitement prédit à partir de <span class="math inline">\(\text{X}\)</span> et il n’y a pas de variabilité résiduelle (<span class="math inline">\(\epsilon = 0\)</span>)</li>
</ul></li>
<li><p>Si la corrélation n’est pas parfaite (<span class="math inline">\(|\text{r}| &lt; 1\)</span>), la droite de régression minimise la somme des carrés des écarts entre les valeurs observées de <span class="math inline">\(\text{Y}\)</span> et les valeurs prédites par le modèle</p>
<ul>
<li><p>Une partie de la variabilité de <span class="math inline">\(\text{Y}\)</span> n’est pas expliquée par la relation linéaire avec <span class="math inline">\(\text{X}\)</span> = variabilité résiduelle (<span class="math inline">\(\epsilon \neq 0\)</span>)</p></li>
<li><p>Dans ce cas, la régression linéaire permet de décomposer la variance de <span class="math inline">\(\text{Y}\)</span> en deux composantes :</p>
<ul>
<li><p>Variance expliquée par la relation linéaire avec <span class="math inline">\(\text{X}\)</span></p></li>
<li><p>Variance résiduelle non expliquée par le modèle</p></li>
</ul></li>
<li><p>La proportion de la variance de <span class="math inline">\(\text{Y}\)</span> expliquée par <span class="math inline">\(\text{X}\)</span> est donnée par le coefficient de détermination (<span class="math inline">\(\text{r}^2\)</span>)</p>
<ul>
<li><p><span class="math inline">\(\text{r}^2\)</span> = proportion de la variance totale de <span class="math inline">\(\text{Y}\)</span> expliquée par la relation linéaire avec <span class="math inline">\(\text{X}\)</span></p></li>
<li><p>Varie entre 0 (aucune variance expliquée) et 1 (toute la variance expliquée)</p></li>
</ul></li>
<li><p>Donc <span class="math inline">\(\text{r}^2\)</span> est mesuré à partir de la régression linéaire simple, mais il est directement lié à la corrélation linéaire entre <span class="math inline">\(\text{X}\)</span> et <span class="math inline">\(\text{Y}\)</span> DANS LE CAS D’UNE RÉGRESSION LINÉAIRE SIMPLE SEULEMENT</p></li>
</ul></li>
</ul></li>
<li><p>Dans le cas d’une régression linéaire multiple (plusieurs variables indépendantes), la relation entre la corrélation et la régression est plus complexe.</p></li>
</ul>
</section>
<section id="le-test-t-un-cas-particulier-du-modèle-linéaire" class="level3">
<h3 class="anchored" data-anchor-id="le-test-t-un-cas-particulier-du-modèle-linéaire">Le test t : un cas particulier du modèle linéaire</h3>
<ul>
<li><p>Test t de student : permet de comparer <strong>les moyennes</strong> d’une variable quantitative dans deux groupes (<span class="math inline">\(\text{A}\)</span> et <span class="math inline">\(\text{B}\)</span>)</p></li>
<li><p>Donc on a une variable dépendante <span class="math inline">\(\text{Y}\)</span> (quantitative) et une variable indépendante <span class="math inline">\(\text{X}\)</span> (catégorielle binaire : groupe <span class="math inline">\(\text{A}\)</span> ou groupe <span class="math inline">\(\text{B}\)</span>).</p></li>
<li><p>Modèle : <span class="math inline">\(\text{Y} = \alpha_0 + \alpha_1 \text{groupe}_i + \epsilon_i\)</span></p></li>
<li><p>La commande <code>summary(lm(age ~ groupe, data = data))</code> donne une <code>t value</code> et une <code>Pr(&gt;|t|)</code> qui correspondent au test t de Student entre les deux groupes</p></li>
<li><p>En résumé : le test t de Student est un cas particulier du modèle linéaire où la variable indépendante est catégorielle binaire.</p></li>
</ul>
<div style="page-break-after: always;"></div>
</section>
</section>
<section id="modèle-linéaire-mixte" class="level2">
<h2 class="anchored" data-anchor-id="modèle-linéaire-mixte">Modèle linéaire mixte</h2>
<section id="définition-1" class="level3">
<h3 class="anchored" data-anchor-id="définition-1">Définition</h3>
<ul>
<li><p>Modèle statistique qui étend le modèle linéaire en incluant à la fois des effets fixes et des effets aléatoires</p></li>
<li><p>Utilisé pour des données hiérarchiques ou groupées (mesures répétées, données longitudinales, etc.)</p></li>
</ul>
</section>
<section id="effets-fixes-et-effets-aléatoires" class="level3">
<h3 class="anchored" data-anchor-id="effets-fixes-et-effets-aléatoires">Effets fixes et effets aléatoires</h3>
<ul>
<li><p>Effets fixes = variables explicatives classiques (variables indépendantes)</p></li>
<li><p>Effets aléatoires = variables de regroupement, modélisant la structure de corrélation des données (variables catégorielles représentant des groupes, sujets, sites, etc.)</p></li>
</ul>
<section id="effets-fixes" class="level4">
<h4 class="anchored" data-anchor-id="effets-fixes">Effets fixes</h4>
<ul>
<li><p>Covariables explicatives classiques, dont ont veut estimer l’effet sur la moyenne de la variable dépendante</p></li>
<li><p>Peuvent être quantitatives (âge, poids, etc.) ou catégorielles (groupe de traitement, sexe, etc.)</p></li>
<li><p>L’effet est FIXE, car le même pour tous les patients</p></li>
</ul>
</section>
<section id="effets-aléatoires" class="level4">
<h4 class="anchored" data-anchor-id="effets-aléatoires">Effets aléatoires</h4>
<ul>
<li><p>Variables de regroupement, représentant des sources de variation non expliquées par les effets fixes</p></li>
<li><p>= variables LATENTES qui modélisent la structure de corrélation des données (mesures répétées sur les mêmes sujets, données groupées par site, etc.)</p></li>
<li><p>On ne s’intéresse pas à l’effet spécifique de chaque niveau de la variable aléatoire, mais à :</p>
<ul>
<li><p>la variance entre les niveaux (variabilité inter-groupe) et au sein des niveaux (variabilité intra-groupe)</p></li>
<li><p>la structure de corrélation induite par la variable aléatoire</p></li>
</ul></li>
</ul>
</section>
</section>
<section id="forme-générale-du-modèle-linéaire-mixte" class="level3">
<h3 class="anchored" data-anchor-id="forme-générale-du-modèle-linéaire-mixte">Forme générale du modèle linéaire mixte</h3>
<ul>
<li><p>Effets fixes estimés ainsi que leur incertitude (IC, p-value) : effets sur la moyenne de la variable dépendante</p></li>
<li><p>Composantes de la variance, décomposée en</p>
<ul>
<li><p>Variance de l’effet aléatoire</p></li>
<li><p>Variance résiduelle</p></li>
</ul></li>
<li><p>NB : plusieurs effets aléatoires au sein d’un même modèle sont possibles et induisent une structure de corrélation plus complexe (matrice de variance-covariance)</p>
<ul>
<li>Par exemple, mesures répétées sur des sujets groupés par site</li>
</ul></li>
</ul>
</section>
<section id="estimateurs" class="level3">
<h3 class="anchored" data-anchor-id="estimateurs">Estimateurs</h3>
<ul>
<li><p>Objectif de l’estimation des paramètres du modèle linéaire mixte : obtenir les valeurs des effets fixes et des composantes de variance qui maximisent la vraisemblance des données observées</p></li>
<li><p>Méthodes d’estimation :</p>
<ul>
<li><p>Maximum de vraisemblance (ML) : estime les paramètres en maximisant la vraisemblance des données</p>
<ul>
<li><p>Permet de comparer des modèles avec des effets fixes différents via le ratio de vraisemblance</p></li>
<li><p>Cependant, les estimations des composantes de variance peuvent être biaisées à cause de la présence d’effets fixes dans le modèle</p></li>
</ul></li>
<li><p>Maximum de vraisemblance restreinte (REML) : variante du ML qui ajuste les estimations des composantes de variance pour tenir compte du nombre d’effets fixes dans le modèle</p>
<ul>
<li><p>Fournit des estimations non biaisées des composantes de variance</p></li>
<li><p>Ne permet pas de comparer des modèles avec des effets fixes différents</p></li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="extensions" class="level3">
<h3 class="anchored" data-anchor-id="extensions">Extensions</h3>
<ul>
<li><p>Modèles non linéaires mixtes : pour des relations non linéaires entre variables</p>
<ul>
<li><p>par exemple modèle logistique, exponentiel…</p></li>
<li><p>ne s’interprète donc pas comme une différence de moyennes</p></li>
</ul></li>
<li><p>Modèles linéaires généralisés mixtes (GLMM) : pour des variables dépendantes non continues (binaires, comptages, etc.)</p>
<ul>
<li><p>combinent les principes des GLM et des modèles linéaires mixtes</p></li>
<li><p>permettent de modéliser des données hiérarchiques avec des distributions non normales (binomiale, de Poisson, etc.)</p></li>
</ul></li>
</ul>
<div style="page-break-after: always;"></div>
</section>
</section>
<section id="modèles-linéaires-généralisés-glm" class="level2">
<h2 class="anchored" data-anchor-id="modèles-linéaires-généralisés-glm">Modèles linéaires généralisés (GLM)</h2>
<section id="introduction-aux-glm" class="level3">
<h3 class="anchored" data-anchor-id="introduction-aux-glm">Introduction aux GLM</h3>
<ul>
<li><p>Les modèles linéaires généralisés reposent sur 3 élements :</p>
<ol type="1">
<li><p>Un prédicteur linéaire : combinaison linéaire des variables indépendantes (comme dans le modèle linéaire classique)</p></li>
<li><p>Une fonction de lien : relie le prédicteur linéaire à la moyenne de la variable dépendante</p></li>
<li><p>Une structure des erreurs : spécifie la distribution de la variable dépendante (exponentielle famille de distributions)</p></li>
</ol></li>
<li><p>Principe : dans les GLM, les données sont transformées afin que les prédictions aient des contraintes identiques à celles de la variable dépendante.</p></li>
</ul>
<section id="le-prédicteur-linéaire" class="level4">
<h4 class="anchored" data-anchor-id="le-prédicteur-linéaire">Le prédicteur linéaire</h4>
<ul>
<li><p>Même principe que dans le modèle linéaire classique</p></li>
<li><p>Les réponses prédites par le modèle le sont à partir d’une combinaison linéaire de variables prédictives</p></li>
<li><p>Correspond à une QUANTITÉ que la FONCTION DE LIEN va transformer pour obtenir la valeur attendue de la variable dépendante</p></li>
<li><p>Effet produit sur la variable dépendante dépend de la fonction de lien choisie</p>
<ul>
<li><p>Par exemple, avec une fonction de lien logit (régression logistique), le prédicteur linéaire correspond au logarithme des odds de l’événement</p></li>
<li><p>Avec une fonction de lien log (régression de Poisson), le prédicteur linéaire correspond au logarithme du taux d’événement</p></li>
<li><p>Avec une fonction de lien identité (régression linéaire), le prédicteur linéaire correspond directement à la moyenne de la variable dépendante</p></li>
</ul></li>
</ul>
</section>
<section id="la-fonction-de-lien" class="level4">
<h4 class="anchored" data-anchor-id="la-fonction-de-lien">La fonction de lien</h4>
<ul>
<li><p>Contrairement au modèle linéaire classique, la relation entre le prédicteur linéaire et la moyenne de la variable dépendante n’est pas forcément directe : la fonction de lien transforme le prédicteur linéaire pour obtenir la valeur attendue de la variable dépendante</p></li>
<li><p>Le prédicteur et la fonction de lien sont liés par une équation qui contraint les valeurs prédites par le modèle à respecter certaines propriétés</p>
<ul>
<li><p>Par exemple, dans une régression logistique, la fonction de lien logit contraint les valeurs prédites à être comprises entre 0 et 1 (probabilités)</p></li>
<li><p>Dans une régression de Poisson, la fonction de lien log contraint les valeurs prédites à être positives (comptages)</p></li>
<li><p>Dans une régression linéaire, la fonction de lien identité n’impose aucune contrainte particulière</p></li>
</ul></li>
<li><p>Synthèse des fonctions de liens :</p>
<ul>
<li><p>Pour une réponse quantitative comptinue (régression linéaire) : <strong>fonction de lien identité</strong></p>
<ul>
<li><p>Domaine des valeurs possibles : <span class="math inline">\(-\infty\)</span> à <span class="math inline">\(+\infty\)</span></p></li>
<li><p>Distribution des erreurs : normale = gaussienne</p></li>
<li><p>Moyenne = somme des effets des prédicteurs = effet <strong>additif</strong>.</p></li>
<li><p>Variance constante (homoscedasticité)</p></li>
</ul></li>
<li><p>Pour une réponse binaire (régression logistique) : <strong>fonction de lien logit</strong></p>
<ul>
<li><p>Domaine des valeurs possibles : 0 à 1 (probabilités)</p></li>
<li><p>Distribution des erreurs : binomiale</p></li>
<li><p>Moyenne (probabilité) après application d’une <strong>fonction “en S”</strong> sur les prédicteurs = effet <strong>multiplicatif</strong> (odds ratio).</p></li>
<li><p>Variance dépend de la probabilité et de sa complémentaire. Si <span class="math inline">\(\text{p} = 50\text{\%}\)</span>, la variance est maximale.</p></li>
</ul></li>
<li><p>Pour une réponse de comptage (régression de Poisson) : <strong>fonction de lien log</strong></p>
<ul>
<li><p>Domaine des valeurs possibles : 0 à <span class="math inline">\(+\infty\)</span> (comptages)</p></li>
<li><p>Distribution des erreurs : de Poisson</p></li>
<li><p>Moyenne (taux d’événement) après application d’une <strong>fonction exponentielle</strong> sur les prédicteurs = effet <strong>multiplicatif</strong> (taux relatif).</p></li>
<li><p>Variance égale à la moyenne (propriété de la distribution de Poisson)</p></li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="la-structure-des-erreurs" class="level4">
<h4 class="anchored" data-anchor-id="la-structure-des-erreurs">La structure des erreurs</h4>
<ul>
<li><p>Spécifie la distribution de la variable dépendante</p></li>
<li><p>Et le rapport entre la moyenne prédite par le modèle et la variance des observations</p>
<ul>
<li><p>Régression linéaire classique : variance constante (homoscedasticité)</p></li>
<li><p>Régression logistique : variance dépend de la probabilité et de sa complémentaire</p></li>
<li><p>Régression de Poisson : variance égale à la moyenne</p></li>
</ul></li>
</ul>
</section>
<section id="maximum-de-vraisemblance-et-déviance" class="level4">
<h4 class="anchored" data-anchor-id="maximum-de-vraisemblance-et-déviance">Maximum de vraisemblance et déviance</h4>
<ul>
<li><p>Les GLM sont estimés par la méthode du maximum de vraisemblance (ML) : on cherche les paramètres du modèle qui maximisent la probabilité d’observer les données</p></li>
<li><p>La vraisemblance est une mesure de la probabilité d’observer les données données les paramètres du modèle</p></li>
<li><p>La déviance est une mesure de la qualité de l’ajustement du modèle aux données : elle compare la vraisemblance du modèle ajusté à celle d’un modèle saturé (modèle parfait)</p>
<ul>
<li><p>Déviance faible = bon ajustement</p></li>
<li><p>Déviance élevée = mauvais ajustement</p></li>
</ul></li>
<li><p>Objectif : minimiser la déviance pour obtenir le meilleur ajustement possible aux données</p></li>
</ul>
<div style="page-break-after: always;"></div>
</section>
</section>
<section id="régression-logistique" class="level3">
<h3 class="anchored" data-anchor-id="régression-logistique">Régression logistique</h3>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Pouruoi on peut pas estimer de RR dans une étude cas-témoins ?</strong></p>
<ul>
<li><p>Dans une étude cas-témoins, on sélectionne les sujets en fonction de leur statut de cas (malade) ou de témoin (non malade), donc ont <span class="math inline">\(\text{Y} = 1\)</span> ou <span class="math inline">\(\text{Y} = 0\)</span>.</p></li>
<li><p>On ne peut pas estimer directement les probabilités <span class="math inline">\(\text{P}(\text{Y} = 1 | \text{X} = x)\)</span> car la proportion de cas et de témoins dans l’échantillon ne reflète pas la prévalence réelle de la maladie dans la population.</p></li>
<li><p>En revanche, les odds <span class="math inline">\(\text{P}(\text{Y} = 1 | \text{X} = x) / \text{P}(\text{Y} = 0 | \text{X} = x)\)</span> peuvent être estimés car ils sont indépendants de la prévalence de la maladie.</p></li>
</ul>
</div>
</div>
<section id="principe" class="level4">
<h4 class="anchored" data-anchor-id="principe">Principe</h4>
<ul>
<li><p>Objectif : modéliser une variable dépendante binaire (donc suivant une loi de Bernoulli 0/1) en fonction de variables indépendantes (quantitatives ou catégorielles)</p></li>
<li><p>Équation : <span class="math inline">\(\text{Y} = \text{log}(\frac{\text{p}}{1 - \text{p}}) = \alpha_0 + \beta_1 \text{X}_1 + \beta_2 \text{X}_2 + \dots + \beta_p \text{X}_p + \varepsilon\)</span></p></li>
<li><p>Donc modéliser la probabilité que <span class="math inline">\(\text{Y} = 1\)</span> (événement d’intérêt) en fonction des variables explicatives <span class="math inline">\(\text{X}_i\)</span>.</p></li>
<li><p>La probabilité <span class="math inline">\(\text{p}\)</span> doit être comprise entre 0 et 1.</p></li>
</ul>
</section>
<section id="transformation-par-la-fonction-de-lien-logit" class="level4">
<h4 class="anchored" data-anchor-id="transformation-par-la-fonction-de-lien-logit">Transformation par la fonction de lien logit</h4>
<ul>
<li><p>La fonction de lien logit transforme la probabilité <span class="math inline">\(\text{p}\)</span> en log-odds : <span class="math inline">\(\text{log}(\frac{\text{p}}{1 - \text{p}})\)</span></p></li>
<li><p>Il s’agit d’une transformation logarithmique des odds (cotes) de l’événement qui permet de travailler sur une échelle non bornée (<span class="math inline">\(-\infty\)</span> à <span class="math inline">\(+\infty\)</span>)</p></li>
<li><p>Ainsi, on rend compatible la nature bornée de la probabilité avec un régression linéaire</p></li>
<li><p>Attention, dans ce cas on supprime <span class="math inline">\(\varepsilon\)</span> qui est intégré dans la distribution binomiale des erreurs</p></li>
<li><p>En fait ça estime des <span class="math inline">\(\text{OR}\)</span> car la transformation <em>logit</em> = <span class="math inline">\(\text{log}(\frac{\text{p}}{1 - \text{p}})\)</span> et odds = <span class="math inline">\(\frac{\text{R}}{1 - \text{R}}\)</span></p></li>
<li><p>Dans l’équation : <span class="math inline">\(\text{OR} = exp^{\beta_i}\)</span> pour une augmentation d’une unité de <span class="math inline">\(\text{X}_i\)</span>, toutes choses égales par ailleurs</p></li>
</ul>
</section>
<section id="structure-des-erreurs" class="level4">
<h4 class="anchored" data-anchor-id="structure-des-erreurs">Structure des erreurs</h4>
<ul>
<li><p>Il est très peu probable que <span class="math inline">\(\varepsilon\)</span> suive une loi normale car :</p>
<ul>
<li><p>La variable dépendante <span class="math inline">\(\text{Y}\)</span> est binaire (0/1)</p></li>
<li><p>Les valeurs à droite varient de <span class="math inline">\(-\infty\)</span> à <span class="math inline">\(+\infty\)</span> (log-odds)</p></li>
</ul></li>
<li><p>On supprime donc <span class="math inline">\(\varepsilon\)</span> et on considère que les erreurs suivent une distribution binomiale, c’est à dire que pour chaque combinaison de valeurs des variables indépendantes, le nombre de succès (Y=1) suit une loi binomiale</p></li>
</ul>
</section>
<section id="multiplicativité-des-effets-et-terme-dinteraction" class="level4">
<h4 class="anchored" data-anchor-id="multiplicativité-des-effets-et-terme-dinteraction">Multiplicativité des effets et terme d’interaction</h4>
<ul>
<li><p>Les coefficients (<span class="math inline">\(\beta\)</span>) du modèle logistique sont <strong>additifs sur le log-odds</strong>, donc leurs exponentielles = les OR se <strong>multiplient</strong>.</p></li>
<li><p>Deux facteurs binaires <span class="math inline">\(X_1\)</span> et <span class="math inline">\(X_2\)</span> (0/1), sans interaction :</p>
<ul>
<li><p><span class="math inline">\(\text{OR}_{X_1=1\ vs\ 0} = e^{\beta_1}\)</span></p></li>
<li><p><span class="math inline">\(\text{OR}_{X_2=1\ vs\ 0} = e^{\beta_2}\)</span></p></li>
<li><p><span class="math inline">\(\text{OR}_{X_1=1, X_2=1} = e^{\beta_1 + \beta_2} = e^{\beta_1} \times e^{\beta_2} = \text{OR}_1 \times \text{OR}_2\)</span></p></li>
<li><p>Exemple (pas d’interaction) : OR tabac = 3, OR alcool = 2 =&gt; OR tabac+alcool = <span class="math inline">\(3 \times 2 = 6\)</span>.</p></li>
</ul></li>
<li><p>Attention : dans le cas d’une interaction entre <span class="math inline">\(X_1\)</span> et <span class="math inline">\(X_2\)</span> :</p>
<ul>
<li><p><strong>Interaction</strong> : on ajoute <span class="math inline">\(\beta_3 (X_1 \times X_2)\)</span> pour autoriser un écart au produit pur.</p>
<ul>
<li><p><span class="math inline">\(\text{OR}_{X_1=1, X_2=1} = e^{\beta_1 + \beta_2 + \beta_3} = \text{OR}_1 \times \text{OR}_2 \times e^{\beta_3}\)</span></p></li>
<li><p>Si <span class="math inline">\(e^{\beta_3} \neq 1\)</span>, l’effet combiné n’est plus strictement multiplicatif (synergie si <span class="math inline">\(\beta_3&gt;0\)</span>, atténuation si <span class="math inline">\(\beta_3&lt;0\)</span>).</p></li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="maximum-de-vraisemblance" class="level4">
<h4 class="anchored" data-anchor-id="maximum-de-vraisemblance">Maximum de vraisemblance</h4>
<ul>
<li>Les paramètres du modèle (<span class="math inline">\(\alpha_0\)</span>, <span class="math inline">\(\beta_1\)</span>, …, <span class="math inline">\(\beta_p\)</span>) sont estimés par la méthode du maximum de vraisemblance (c’est à dire qu’on cherche les valeurs des paramètres qui maximisent la probabilité d’observer les données)</li>
</ul>
</section>
<section id="conditions-de-validité" class="level4">
<h4 class="anchored" data-anchor-id="conditions-de-validité">Conditions de validité</h4>
<ul>
<li><p>Variable dépendante binaire</p></li>
<li><p>Au moins 10 événements (Y=1) par variable indépendante incluse dans le modèle</p></li>
<li><p>L’estimateur <span class="math inline">\(\beta_i\)</span> est asymptotiquement normal (pour des grands échantillons), donc on peut construire des IC et faire des tests de significativité (test de Wald)</p></li>
</ul>
</section>
<section id="test-des-coefficients-1-par-1-test-de-wald" class="level4">
<h4 class="anchored" data-anchor-id="test-des-coefficients-1-par-1-test-de-wald">Test des coefficients 1 par 1 : test de Wald</h4>
<ul>
<li><p>Le test de Wald évalue la significativité individuelle de chaque coefficient de régression dans le modèle logistique</p></li>
<li><p>Il teste l’hypothèse nulle selon laquelle le coefficient de régression est égal à zéro (pas d’effet de la variable indépendante sur la variable dépendante)</p></li>
<li><p>Repose sur la standardisation de l’estimateur du coefficient de régression (<span class="math inline">\(\widehat{\beta_i}\)</span>) en le divisant par son erreur standard (SE) : permet d’obtenir une statistique de test qui suit une distribution normale sous l’hypothèse nulle</p></li>
<li><p>Le test de Wald forme le ratio <span class="math inline">\(\widehat{\beta_i} / \text{SE}(\widehat{\beta_i})\)</span>, le compare à une loi normale (ou son carré à un <span class="math inline">\(\chi^2\)</span> à 1 ddl), et conclut significatif si <span class="math inline">\(|\widehat{\beta_i}| &gt; 1.96\,\text{SE}(\widehat{\beta_i})\)</span> (IC 95% de <span class="math inline">\(\beta_i\)</span> excluant 0, donc OR dont l’IC 95% exclut 1).</p></li>
<li><p>L’erreur standard du coefficient suit une distribution du Chi-carré avec 1 degré de liberté sous l’hypothèse nulle.</p></li>
<li><p>Globalement, si l’IC de <span class="math inline">\(\beta_i\)</span> inclut 0, alors son exponentielle <span class="math inline">\(\text{OR} = exp^{\beta_i}\)</span> inclut 1, donc la variable n’a pas d’effet significatif sur la variable dépendante.</p></li>
<li><p>Précautions avec le test de Wald :</p>
<ul>
<li><p>Petits échantillons : approximations normales peuvent être inexactes</p></li>
<li><p>Évènements rares : erreurs standards peuvent être surévaluées</p></li>
<li><p>Effets très grands ou très petits : distribution asymptotique peut être inexacte</p></li>
<li><p>Séparabilité complète : si une variable prédit parfaitement l’issue, le test de Wald peut être instable</p></li>
</ul></li>
</ul>
</section>
<section id="intérêt-de-lajout-dune-variable-et-test-de-rapport-de-vraisemblance" class="level4">
<h4 class="anchored" data-anchor-id="intérêt-de-lajout-dune-variable-et-test-de-rapport-de-vraisemblance">Intérêt de l’ajout d’une variable et test de rapport de vraisemblance</h4>
<ul>
<li><p>Le test du rapport de vraisemblance permet de comparer deux modèles emboîtés (un modèle complet avec toutes les variables et un modèle réduit sans une variable spécifique)</p></li>
<li><p>Il repose sur un test du Chi-carré dans le modèle logistique et évalue si l’ajout de la variable améliore significativement l’ajustement du modèle aux données</p></li>
<li><p>Permet ainsi de tester plusieurs variables simultanément, contrairement au test de Wald qui évalue chaque variable individuellement</p></li>
<li><p>NB : dans une régression linéaire, on utilise un test F (ANOVA) pour comparer les modèles emboîtés en comparant la variance expliquée par chaque modèle</p></li>
</ul>
<div style="page-break-after: always;"></div>
</section>
</section>
<section id="modèle-de-poisson" class="level3">
<h3 class="anchored" data-anchor-id="modèle-de-poisson">Modèle de Poisson</h3>
<section id="principe-1" class="level4">
<h4 class="anchored" data-anchor-id="principe-1">Principe</h4>
<ul>
<li><p>Objectif : modéliser une variable dépendante de comptage (nombre d’événements) en fonction de variables indépendantes (quantitatives ou catégorielles)</p></li>
<li><p>Problème des données de comptes : ne suivent pas une distribution normale, et leur variance n’est pas constante (variance augmente avec la moyenne)</p></li>
<li><p>Loi de Poisson : probabilité d’observer un certain nombre d’événements dans un intervalle de temps ou d’espace donné, en supposant que les événements se produisent à taux constant (moyenne constante) et indépendamment les uns des autres</p></li>
<li><p>Dans la distribution de Poisson, la moyenne et la variance sont égales : <span class="math inline">\(\text{E}(\text{Y}) = \text{Var}(\text{Y}) = \lambda\)</span>.</p>
<ul>
<li><p>Si variance &gt;&gt; moyenne : surdispersion (modèle de Poisson inadapté)</p></li>
<li><p>Plus la moyenne est grande, plus la distribution de Poisson ressemble à une distribution normale</p></li>
</ul></li>
</ul>
<section id="données-de-comptage" class="level5">
<h5 class="anchored" data-anchor-id="données-de-comptage">Données de comptage</h5>
<ul>
<li><p>Beaucoup de zéros possibles (ex : nombre de visites à l’hôpital)</p></li>
<li><p>Valeurs entières non négatives (0, 1, 2, …)</p></li>
<li><p>Distribution asymétrique, souvent avec une longue queue à droite</p></li>
</ul>
</section>
<section id="transformation-par-la-fonction-de-lien-log" class="level5">
<h5 class="anchored" data-anchor-id="transformation-par-la-fonction-de-lien-log">Transformation par la fonction de lien log</h5>
<ul>
<li><p>La fonction de lien log transforme la moyenne <span class="math inline">\(\lambda\)</span> en log-moyenne : <span class="math inline">\(\text{log}(\lambda)\)</span></p></li>
<li><p>Il s’agit d’une transformation logarithmique qui permet de travailler sur une échelle non bornée (<span class="math inline">\(-\infty\)</span> à <span class="math inline">\(+\infty\)</span>)</p></li>
<li><p>Ainsi, on rend compatible la nature positive des données de comptage avec une régression linéaire</p></li>
</ul>
</section>
<section id="structure-des-erreurs-1" class="level5">
<h5 class="anchored" data-anchor-id="structure-des-erreurs-1">Structure des erreurs</h5>
<ul>
<li>Distribution de Poisson donc variance égale à la moyenne : <span class="math inline">\(\text{Var}(\text{Y}) = \lambda\)</span></li>
</ul>
</section>
<section id="multiplicativité-des-effets-et-terme-dinteraction-1" class="level5">
<h5 class="anchored" data-anchor-id="multiplicativité-des-effets-et-terme-dinteraction-1">Multiplicativité des effets et terme d’interaction</h5>
<ul>
<li>Les coefficients (<span class="math inline">\(\beta\)</span>) du modèle de Poisson sont <strong>additifs sur le log-moyenne</strong>, donc leurs exponentielles = les taux relatifs se <strong>multiplient</strong>.</li>
</ul>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><p>Régression linéaire : moyenne est égale au prédicteur linéaire (donc effet additif sur la moyenne)</p></li>
<li><p>Régression logistique : moyenne est une fonction expit (en S) du prédicteur linéaire (donc effet multiplicatif sur les odds)</p></li>
<li><p>Régression de Poisson : moyenne est une fonction exponentielle du prédicteur linéaire (donc effet multiplicatif sur la moyenne)</p></li>
</ul>
</div>
</div>
</section>
</section>
<section id="interprétation-des-coefficients" class="level4">
<h4 class="anchored" data-anchor-id="interprétation-des-coefficients">Interprétation des coefficients</h4>
<ul>
<li><p>Le coefficient s’interprète comme le <strong>logarithme du risque relatif d’événements</strong> pour une augmentation d’une unité de la variable indépendante, toutes choses égales par ailleurs</p></li>
<li><p>Donc l’exponentielle du coefficient (<span class="math inline">\(exp^{\beta_i}\)</span>) représente le <strong>taux relatif d’événements</strong> associé à une augmentation d’une unité de la variable indépendante <span class="math inline">\(\text{X}_i\)</span>, toutes choses égales par ailleurs</p></li>
<li><p>NB : en réalité il s’agit plutôt d’un <strong>RAPPORT DE MOYENNE</strong> car on modélise la moyenne des comptes et donc pas vraiment un risque relatif</p></li>
<li><p>Les effets sont MULTIPLICATIFS après exponentiation des coefficients (additifs sur le <span class="math inline">\(\log(\lambda)\)</span>)</p>
<ul>
<li><p>Par exemple, si <span class="math inline">\(exp^{\beta_1} = 1.5\)</span>, cela signifie qu’une augmentation de 1 unité de <span class="math inline">\(\text{X}_1\)</span> est associée à une augmentation de 50% du taux moyen d’événements (comptages), toutes choses égales par ailleurs.</p></li>
<li><p>Si <span class="math inline">\(exp^{\beta_2} = 0.8\)</span>, cela signifie qu’une augmentation de 1 unité de <span class="math inline">\(\text{X}_2\)</span> est associée à une diminution de 20% du taux moyen d’événements, toutes choses égales par ailleurs.</p></li>
</ul></li>
</ul>
</section>
<section id="conditions-de-validité-1" class="level4">
<h4 class="anchored" data-anchor-id="conditions-de-validité-1">Conditions de validité</h4>
<ul>
<li><p>Variable dépendante de comptage (0, 1, 2, …)</p></li>
<li><p>Les événements doivent être indépendants</p></li>
<li><p>La moyenne et la variance de la variable dépendante doivent être égales (sinon surdispersion)</p></li>
</ul>
</section>
<section id="tests-statistiques-1" class="level4">
<h4 class="anchored" data-anchor-id="tests-statistiques-1">Tests statistiques</h4>
<ul>
<li><p>Test de Wald pour évaluer la significativité individuelle de chaque coefficient de régression</p>
<ul>
<li>NB : en cas de surdispersion, la p-value du test de Wald peut être biaisée, il est donc préférable d’utiliser des estimateurs robustes ou des modèles alternatifs</li>
</ul></li>
<li><p>Test du rapport de vraisemblance pour comparer des modèles emboîtés et évaluer l’intérêt d’ajouter une variable au modèle</p></li>
</ul>
</section>
<section id="problèmes-fréquents-avec-le-modèle-de-poisson" class="level4">
<h4 class="anchored" data-anchor-id="problèmes-fréquents-avec-le-modèle-de-poisson">Problèmes fréquents avec le modèle de Poisson</h4>
<section id="surdispersion" class="level5">
<h5 class="anchored" data-anchor-id="surdispersion">Surdispersion</h5>
<ul>
<li><p>La surdispersion se produit lorsque la variance des données de comptage est supérieure à la moyenne, ce qui viole l’hypothèse fondamentale du modèle de Poisson</p></li>
<li><p>Mesurer la surdispersion : calcul du ratio <span class="math inline">\(\frac{\text{variance observée}}{\text{variance théorique}}\)</span> = <span class="math inline">\(\frac{\text{variance observée}}{\text{moyenne}}\)</span></p>
<ul>
<li><p>Si ratio &gt; 1 : surdispersion</p></li>
<li><p>Si ratio ~{} 1 : pas de surdispersion</p></li>
</ul></li>
<li><p>Conséquences de la surdispersion :</p>
<ul>
<li><p>Sous-estimation des erreurs standards des coefficients de régression</p></li>
<li><p>Tests de significativité trop optimistes (risque accru de faux positifs)</p></li>
</ul></li>
<li><p>Solutions pour gérer la surdispersion :</p>
<ul>
<li><p>Utiliser un modèle alternatif :</p>
<ul>
<li><p>Modèle quasi-Poisson : ajuste les erreurs standards en fonction de la surdispersion observée</p></li>
<li><p>Modèle binomial négatif : introduit un paramètre de dispersion supplémentaire pour modéliser la variance excédentaire</p></li>
</ul></li>
<li><p>Ajuster les erreurs standards avec des estimateurs robustes (sandwich estimators)</p></li>
</ul></li>
</ul>
<section id="estimateur-robuste-de-la-variance-sandwich-estimator" class="level6">
<h6 class="anchored" data-anchor-id="estimateur-robuste-de-la-variance-sandwich-estimator">Estimateur robuste de la variance (Sandwich estimator)</h6>
<ul>
<li><p>Principe : ajuster les erreurs standards des coefficients de régression pour tenir compte de la surdispersion ou de la corrélation entre les observations</p></li>
<li><p>Calcul : utilise la matrice de variance-covariance des résidus pour ajuster les erreurs standards.</p>
<ul>
<li><p>La matrice variance-covariance est multipliée par une matrice de correction basée sur les résidus du modèle.</p></li>
<li><p>Cela permet d’obtenir des erreurs standards plus robustes, qui reflètent mieux la variabilité réelle des données.</p></li>
</ul></li>
<li><p>Avantages :</p>
<ul>
<li><p>Permet d’obtenir des intervalles de confiance et des tests de significativité plus fiables en présence de surdispersion ou de corrélation</p></li>
<li><p>Facile à implémenter dans la plupart des logiciels statistiques</p></li>
</ul></li>
</ul>
</section>
<section id="bootstrap" class="level6">
<h6 class="anchored" data-anchor-id="bootstrap">Bootstrap</h6>
<ul>
<li><p>Principe : méthode de rééchantillonnage qui permet d’estimer la distribution des estimateurs (comme les coefficients de régression) en générant de nombreux échantillons bootstrap à partir des données originales</p></li>
<li><p>Calcul :</p>
<ul>
<li><p>Générer un grand nombre d’échantillons bootstrap en tirant au hasard avec remise des observations des données originales</p></li>
<li><p>Pour chaque échantillon bootstrap, ajuster le modèle de Poisson et calculer les coefficients de régression</p></li>
<li><p>Utiliser la distribution des coefficients obtenus à partir des échantillons bootstrap pour estimer les erreurs standards, les intervalles de confiance et les p-values</p></li>
</ul></li>
<li><p>Avantages :</p>
<ul>
<li><p>Permet d’obtenir des estimations robustes des erreurs standards et des intervalles de confiance, même en présence de surdispersion ou de structures complexes dans les données</p></li>
<li><p>Ne nécessite pas d’hypothèses strictes sur la distribution des données</p></li>
</ul></li>
<li><p>Inconvénients : peut être computationnellement intensif, surtout pour de grands ensembles de données ou des modèles complexes</p></li>
</ul>
</section>
<section id="modèle-quasi-poisson" class="level6">
<h6 class="anchored" data-anchor-id="modèle-quasi-poisson">Modèle quasi-Poisson</h6>
<ul>
<li><p>Principe : extension du modèle de Poisson qui permet de modéliser la surdispersion en introduisant un paramètre de dispersion supplémentaire</p></li>
<li><p>Calcul :</p>
<ul>
<li><p>La moyenne de la variable dépendante est toujours modélisée comme dans le modèle de Poisson</p></li>
<li><p>La variance est modélisée comme une fonction de la moyenne, mais avec un paramètre de dispersion (<span class="math inline">\(\phi\)</span>) qui permet à la variance d’être plus grande que la moyenne : <span class="math inline">\(\text{Var}(\text{Y}) = \phi \lambda\)</span></p></li>
<li><p>Le paramètre de dispersion est estimé à partir des données, et les erreurs standards des coefficients de régression sont ajustées en conséquence</p></li>
</ul></li>
</ul>
</section>
</section>
<section id="éxcès-de-0" class="level5">
<h5 class="anchored" data-anchor-id="éxcès-de-0">Éxcès de 0</h5>
<ul>
<li><p>L’excès de zéros se produit lorsque le nombre de zéros observés dans les données de comptage est supérieur à ce qui serait attendu selon la distribution de Poisson</p></li>
<li><p>Conséquences : mauvais ajustement du modèle, sous-estimation des erreurs standards, tests de significativité biaisés</p></li>
<li><p>Solutions pour gérer l’excès de zéros :</p>
<ul>
<li><p>Modèles à zéros-inflation (zero-inflated models) :</p>
<ul>
<li><p>Pour les zéros : modèle logistique</p></li>
<li><p>Pour les comptes &gt; 0 : modèle de Poisson ou binomial négatif</p></li>
</ul></li>
<li><p>Modèles hurdle : modélisent séparément le processus de génération des zéros et le processus de génération des comptages positifs</p></li>
</ul></li>
</ul>
<div style="page-break-after: always;"></div>
</section>
</section>
</section>
<section id="modèle-de-survie" class="level3">
<h3 class="anchored" data-anchor-id="modèle-de-survie">Modèle de survie</h3>
<ul>
<li><p>Modèles de survie paramétrique : Weibull, exponentiel, log-logistique = Pas au programme*</p></li>
<li><p>Modèles de survie semi-paramétriques : Modèle de Cox</p></li>
</ul>
<section id="données-de-survie-censure" class="level4">
<h4 class="anchored" data-anchor-id="données-de-survie-censure">Données de survie / censure</h4>
<ul>
<li><p>Données de survie : temps jusqu’à la survenue d’un événement d’intérêt (ex : décès, rechute)</p></li>
<li><p>Soit les patients ont présenté l’événement (décès, rechute) pendant le suivi : on connaît le temps exact de suivi avant l’événement</p></li>
<li><p>Sinon : censure : situation où l’on ne connaît pas le temps exact de l’événement pour certains individus</p>
<ul>
<li><p>Censure à droite : événement non survenu avant la fin du suivi ou perte de suivi</p>
<ul>
<li><p>Censure administrative : fin de l’étude (par ex survie à 5 ans après traitement du cancer ; les patients vivants à 5 ans sont censurés donc considérés comme ayant survécu au moins 5 ans)</p></li>
<li><p>Perdus de vue : patients qui quittent l’étude avant la fin du suivi (et évènement non survenu)</p></li>
</ul></li>
<li><p>Censure à gauche : événement survenu avant le début du suivi (rare) : par exemple si on étudie le temps jusqu’à la guérison d’une maladie, et qu’un patient est déjà guéri au début de l’étude</p></li>
<li><p>Censure intervalle : événement survenu entre deux points de temps connus</p></li>
</ul></li>
</ul>
</section>
<section id="données-nécessaires" class="level4">
<h4 class="anchored" data-anchor-id="données-nécessaires">Données nécessaires</h4>
<ul>
<li><p>Temps de suivi (temps jusqu’à l’événement ou censure)</p></li>
<li><p>Indicateur d’événement (1 si l’événement est survenu, 0 si censuré)</p></li>
</ul>
</section>
<section id="loi-de-probabilité-de-t-délai-jusquà-lévénement" class="level4">
<h4 class="anchored" data-anchor-id="loi-de-probabilité-de-t-délai-jusquà-lévénement">Loi de probabilité de T = délai jusqu’à l’événement</h4>
<ul>
<li><p>Densité de probabilité <span class="math inline">\(f(t)\)</span> : probabilité que l’événement survienne exactement au temps t</p></li>
<li><p>Fonction de survie <span class="math inline">\(S(t)\)</span> : probabilité de survivre au-delà du temps t = <span class="math inline">\(P(T &gt; t)\)</span></p></li>
<li><p>Fonction de risque instantané (hazard function) <span class="math inline">\(h(t)\)</span> : taux instantané de survenue de l’événement au temps t, conditionnellement à la survie jusqu’à ce temps = <span class="math inline">\(h(t) = \frac{f(t)}{S(t)}\)</span></p>
<ul>
<li><p>L’individu jusqu’au temps t.</p></li>
<li><p>Et on regarde la probabilité que l’événement survienne dans un intervalle de temps infinitésimal après t (sachant qu’il a survécu jusqu’à t).</p></li>
</ul></li>
<li><p>Fonction de risque cumulé : correspond au risque total accumulé jusqu’au temps t</p></li>
<li><p>Fonction de répartition : probabilité que l’événement survienne avant ou au temps t.</p></li>
</ul>
</section>
<section id="principe-2" class="level4">
<h4 class="anchored" data-anchor-id="principe-2">Principe</h4>
<ul>
<li><p>Modèle de Cox = modèle de risques proportionnels de Cox</p></li>
<li><p>Objectif : modéliser le temps jusqu’à la survenue d’un événement (ex : décès, rechute) en fonction de variables explicatives (quantitatives ou catégorielles)</p></li>
<li><p>Caractéristiques principales :</p>
<ul>
<li><p>Semi-paramétrique : ne fait pas d’hypothèses sur la forme de la fonction de risque de base (non paramétrique), mais modélise l’effet des covariables de manière paramétrique</p></li>
<li><p>Fonction de risque instantané (hazard function) : taux instantané de survenue de l’événement à un temps donné, conditionnellement à la survie jusqu’à ce temps</p></li>
<li><p>2 hypothèses :</p>
<ul>
<li><p>Proportionnalité des risques : rapport des risques reste constant dans le temps : à tout moment du suivi, le risque relatif entre deux individus est le même</p></li>
<li><p>Log-linéarité des covariables continues : l’effet des covariables continues sur le log-risque est linéaire : chaque année supplémentaire d’âge a le même effet proportionnel sur le risque</p></li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="estimation-dune-courbe-de-survie-méthode-non-paramétrique-de-kaplan-meier" class="level4">
<h4 class="anchored" data-anchor-id="estimation-dune-courbe-de-survie-méthode-non-paramétrique-de-kaplan-meier">Estimation d’une courbe de survie : méthode non paramétrique de Kaplan-Meier</h4>
<ul>
<li><p>Objectif : estimer la fonction de survie <span class="math inline">\(S(t)\)</span> à partir de données censurées</p></li>
<li><p>Principe : calcule la probabilité de survie à chaque temps où un événement survient, en tenant compte des individus censurés = probabilités conditionnelles</p>
<ul>
<li>Par exemple Probabilité de survivre à 2 ans = probabilité de survivre à 1 an x probabilité de survivre entre 1 et 2 ans</li>
</ul></li>
</ul>
<section id="comparaison-de-courbes-de-survie-test-du-log-rank" class="level5">
<h5 class="anchored" data-anchor-id="comparaison-de-courbes-de-survie-test-du-log-rank">Comparaison de courbes de survie : test du log-rank</h5>
<ul>
<li><p>Objectif : comparer les courbes de survie entre deux ou plusieurs groupes (ex : traitement A vs traitement B)</p></li>
<li><p>Principe : teste l’hypothèse nulle selon laquelle il n’y a pas de différence de survie entre les groupes</p>
<ul>
<li><p>Compare le nombre d’événements observés dans chaque groupe au nombre d’événements attendus sous l’hypothèse nulle à chaque temps où un événement survient</p></li>
<li><p>Agrège ces différences sur tous les temps pour obtenir une <strong>statistique de test globale qui suit une distribution du Chi-carré</strong> sous l’hypothèse nulle</p></li>
</ul></li>
</ul>
</section>
</section>
<section id="modèle-de-cox-méthode-semi-paramétrique" class="level4">
<h4 class="anchored" data-anchor-id="modèle-de-cox-méthode-semi-paramétrique">Modèle de Cox : méthode semi-paramétrique</h4>
<section id="principe-3" class="level5">
<h5 class="anchored" data-anchor-id="principe-3">Principe</h5>
<ul>
<li><p>Modélisation de l’effet de variables explicatives sur le risque instantané de survenue de l’événement, sans faire d’hypothèses sur la forme de la fonction de risque de base</p></li>
<li><p>Décris et test la dépendance entre</p>
<ul>
<li><p>La fonction de risque instantané <span class="math inline">\(h(t)\)</span></p></li>
<li><p>Un ensemble de covariables explicatives <span class="math inline">\(\text{X}_1, \text{X}_2, ..., \text{X}_p\)</span></p></li>
</ul></li>
<li><p>2 hypothèses :</p>
<ul>
<li><p>Proportionnalité des risques : le rapport des risques entre deux individus reste constant dans le temps</p></li>
<li><p>Log-linéarité des covariables continues : l’effet des covariables continues sur le log-risque est linéaire</p></li>
</ul></li>
</ul>
</section>
<section id="interprétation-des-coefficients-1" class="level5">
<h5 class="anchored" data-anchor-id="interprétation-des-coefficients-1">Interprétation des coefficients</h5>
<ul>
<li><p>Chaque coefficient (<span class="math inline">\(\beta_i\)</span>) représente l’effet d’une unité de changement dans la variable indépendante <span class="math inline">\(\text{X}_i\)</span> sur le risque instantané de survenue de l’événement, en maintenant toutes les autres variables indépendantes constantes.</p></li>
<li><p>Obtient des <strong>hazard ratios (HR)</strong> en exponentiant les coefficients : <span class="math inline">\(\text{HR} = exp^{\beta_i}\)</span></p>
<ul>
<li><p>Si <span class="math inline">\(\text{HR} &gt; 1\)</span> : augmentation du risque avec l’augmentation de <span class="math inline">\(\text{X}_i\)</span></p></li>
<li><p>Si <span class="math inline">\(\text{HR} &lt; 1\)</span> : diminution du risque avec l’augmentation de <span class="math inline">\(\text{X}_i\)</span></p></li>
<li><p>Si <span class="math inline">\(\text{HR} = 1\)</span> : pas d’effet de <span class="math inline">\(\text{X}_i\)</span> sur le risque</p></li>
</ul></li>
<li><p>Selon le type de variable explicative :</p>
<ul>
<li><p>Variable binaire (0/1) : <span class="math inline">\(\text{HR}\)</span> compare le risque entre les deux groupes (ex : traitement vs contrôle)</p></li>
<li><p>Variable continue : <span class="math inline">\(\text{HR}\)</span> représente le changement proportionnel du risque pour une augmentation d’une unité de la variable</p></li>
<li><p>Variable catégorielle avec plus de 2 niveaux : chaque niveau est comparé à une catégorie de référence, et <span class="math inline">\(\text{HR}\)</span> indique le risque relatif par rapport à cette catégorie</p></li>
</ul></li>
</ul>
</section>
</section>
</section>
<section id="modèle-linéaire-généralisé-mixte-glmm" class="level3">
<h3 class="anchored" data-anchor-id="modèle-linéaire-généralisé-mixte-glmm">Modèle linéaire généralisé mixte (GLMM)</h3>
<ul>
<li><p>Extension des modèles linéaires généralisés (GLM) qui intègre des effets aléatoires pour modéliser la dépendance entre les observations</p></li>
<li><p>Utilisé lorsque les données présentent une structure hiérarchique ou de regroupement (ex : mesures répétées sur les mêmes individus, données groupées par centres cliniques)</p></li>
</ul>
<div style="page-break-after: always;"></div>
</section>
</section>
</section>
<section id="bootstrap-1" class="level1">
<h1>Bootstrap</h1>
<section id="principe-4" class="level2">
<h2 class="anchored" data-anchor-id="principe-4">Principe</h2>
<ul>
<li><p>Dans un échantillon de taille <span class="math inline">\(\text{n}\)</span>, tirer au hasard avec remise des échantillons de taille <span class="math inline">\(\text{n}\)</span>, parmi les <span class="math inline">\(\text{n}\)</span> observations initiales.</p></li>
<li><p>Estimer la statistique d’intérêt (moyenne, médiane, écart-type, coefficient de corrélation, etc.) pour chaque échantillon bootstrap.</p></li>
<li><p>Répéter cette opération un grand nombre de fois (<span class="math inline">\(\text{k}\)</span> = 1000 ou 10 000 itérations) pour obtenir une distribution empirique de la statistique d’intérêt.</p></li>
<li><p>Utiliser cette distribution pour estimer l’incertitude associée à la statistique d’intérêt, par exemple en calculant des intervalles de confiance ou des erreurs standard.</p>
<ul>
<li><p>On classe les <span class="math inline">\(\text{k}\)</span> estimations obtenues du plus petit au plus grand</p></li>
<li><p>On retire les 2,5% des valeurs les plus basses et les 2,5% des valeurs les plus hautes pour obtenir un intervalle de confiance à 95%</p></li>
</ul></li>
<li><p>Revient à dire “<em>si je refaisais l’étude plusieurs fois, dans 95% des cas, le résultat serait compris dans cet intervalle</em>”</p></li>
</ul>
<div class="cell">
<div class="cell-output-display">
<div id="fig-bootstrap-schema" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-bootstrap-schema-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="QUARTO-BIG-NOTES_files/figure-html/fig-bootstrap-schema-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-bootstrap-schema-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Illustration du principe du Bootstrap (Méthode des percentiles)
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="conditions-dapplication" class="level2">
<h2 class="anchored" data-anchor-id="conditions-dapplication">Conditions d’application</h2>
<ul>
<li><p>Données indépendantes (mais c’est possible sur des données en cluster en adaptant la méthode)</p></li>
<li><p>Nombre suffisant d’observations dans l’échantillon initial (idéalement &gt; 30)</p></li>
<li><p>Fluctuations CONTINUES et non discrète de la statistique d’intérêt (éviter les statistiques basées sur des comptages très faibles ou sur une médiane) <span class="math inline">\(\rightarrow\)</span> éviter les distributions “en peigne”.</p></li>
</ul>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="QUARTO-BIG-NOTES_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption>Bootstrap sur médiane (données discrètes) vs Bootstrap sur moyenne (continues)</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="avantages" class="level2">
<h2 class="anchored" data-anchor-id="avantages">Avantages</h2>
<ul>
<li><p>Ne nécessite pas d’hypothèses strictes sur la distribution des données (non paramétrique)</p></li>
<li><p>Peut être appliqué à une large gamme de statistiques d’intérêt</p></li>
<li><p>Stabilisation asymptotique des estimateurs avec un grand nombre de rééchantillonnages, c’est à dire que les résultats deviennent plus précis à mesure que le nombre d’itérations augmente</p></li>
</ul>
</section>
<section id="inconvénients" class="level2">
<h2 class="anchored" data-anchor-id="inconvénients">Inconvénients</h2>
<ul>
<li><p>Peut être computationnellement intensif, surtout pour de grands ensembles de données ou des modèles complexes</p></li>
<li><p>Résultats peuvent être sensibles aux observations extrêmes ou influentes dans l’échantillon initial</p></li>
</ul>
</section>
<section id="applications-courantes" class="level2">
<h2 class="anchored" data-anchor-id="applications-courantes">Applications courantes</h2>
<ul>
<li><p>Estimation des erreurs standards et des intervalles de confiance pour des statistiques complexes (médiane, quantiles, coefficients de régression non linéaires)</p></li>
<li><p>Validation de modèles statistiques (évaluation de la stabilité des coefficients de régression)</p></li>
<li><p>Comparaison de groupes ou de traitements lorsque les hypothèses des tests paramétriques ne sont pas satisfaites</p></li>
</ul>
<div style="page-break-after: always;"></div>
</section>
</section>
<section id="effet-centre" class="level1">
<h1>Effet centre</h1>
<ul>
<li><p>Données regroupées par centres (hôpitaux, cliniques, régions, etc.)</p></li>
<li><p>Donc par définition non-indépendantes (patients d’un même centre plus similaires entre eux qu’avec ceux d’autres centres)</p></li>
<li><p>Ignorer la corrélation : risque accru de faux positifs (erreurs standards sous-estimées, p-values trop optimistes)</p></li>
<li><p>Solutions :</p>
<ul>
<li><p>Modèles de régressions avec erreurs robustes : bootstrap en grappe, estimateurs sandwich</p></li>
<li><p>Modèles linéaires mixtes (LMM) ou modèles linéaires généralisés mixtes (GLMM) : inclure un effet aléatoire pour le centre</p></li>
<li><p>Modèles marginaux (GEE) : modéliser la corrélation entre les observations au sein des centres</p></li>
</ul></li>
</ul>
<section id="modèles-avec-erreurs-robustes" class="level2">
<h2 class="anchored" data-anchor-id="modèles-avec-erreurs-robustes">Modèles avec erreurs robustes</h2>
<ul>
<li><p>Sans prise en compte de la structure en grappes (centres) dans le modèle :</p>
<ul>
<li><p>Biais de confusion par effet de groupe</p>
<ul>
<li><p>Exemple : si un centre a de meilleurs résultats en raison de meilleures pratiques cliniques, et que ce centre a aussi une proportion plus élevée de patients recevant un certain traitement, on pourrait à tort attribuer les meilleurs résultats au traitement plutôt qu’aux pratiques du centre.</p></li>
<li><p>Donc mélange de l’effet du traitement et de l’effet centre.</p></li>
</ul></li>
<li><p>Non-indépendance des observations et des résidus</p>
<ul>
<li>Donc sous-estimation des erreurs standards des coefficients de régression</li>
</ul></li>
</ul></li>
<li><p>Solutions : bootstrap en grappe, estimateurs sandwich</p></li>
</ul>
<section id="bootstrap-en-grappe-cluster-bootstrap" class="level3">
<h3 class="anchored" data-anchor-id="bootstrap-en-grappe-cluster-bootstrap">Bootstrap en grappe = cluster bootstrap</h3>
<ul>
<li><p>Tirer des échantillons bootstrap au niveau des grappes (centres) plutôt qu’au niveau des individus</p></li>
<li><p>Pour chaque échantillon bootstrap, ajuster le modèle de régression et calculer les coefficients</p></li>
<li><p>Utiliser la distribution des coefficients obtenus à partir des échantillons bootstrap pour estimer les erreurs standards, les intervalles de confiance et les p-values</p></li>
<li><p>L’intervalle sera presque toujours plus large qu’avec un bootstrap classique (car on prend en compte la variabilité entre les centres)</p></li>
</ul>
</section>
<section id="estimateur-robuste-de-la-variance-sandwich-estimator-1" class="level3">
<h3 class="anchored" data-anchor-id="estimateur-robuste-de-la-variance-sandwich-estimator-1">Estimateur robuste de la variance (Sandwich estimator)</h3>
<ul>
<li><p>L’estimateur robuste utilise les résidus “réels” du modèle en plus des résidus “théoriques” pour ajuster les erreurs standards</p></li>
<li><p>Si tous les résidus vont dans le même sens, la corrélation est détectée et est prise en compte dans le calcul des erreurs standards.</p></li>
<li><p>La matrice de variance-covariance est ajustée pour refléter la corrélation entre les observations au sein des grappes (centres)</p></li>
<li><p>Mécanisme : <span class="math inline">\(V_{robuste} = V_{classique} \times Correction \times V_{classique}\)</span>, où <span class="math inline">\(Correction\)</span> est une matrice de correction basée sur les résidus du modèle</p></li>
<li><p>Donc les estimations des coefficients restent les mêmes, mais les erreurs standards sont ajustées pour tenir compte de la corrélation intra-groupe !!</p></li>
</ul>
</section>
</section>
<section id="modèles-linéaires-mixtes-lmm-et-modèles-linéaires-généralisés-mixtes-glmm" class="level2">
<h2 class="anchored" data-anchor-id="modèles-linéaires-mixtes-lmm-et-modèles-linéaires-généralisés-mixtes-glmm">Modèles linéaires mixtes (LMM) et modèles linéaires généralisés mixtes (GLMM)</h2>
<ul>
<li><p>Inclure un effet aléatoire pour le centre dans le modèle de régression</p></li>
<li><p>Permet de modéliser la variabilité entre les centres et de capturer la corrélation entre les observations au sein d’un même centre</p></li>
<li><p>Structure du modèle :</p>
<ul>
<li><p>Effets fixes : coefficients de régression pour les variables explicatives</p></li>
<li><p>Effets aléatoires : variabilité spécifique à chaque centre</p></li>
</ul></li>
<li><p>Estimation des paramètres par maximum de vraisemblance ou maximum de vraisemblance restreint (REML)</p>
<ul>
<li><p>ML : convient pour comparer des modèles avec des effets fixes différents, surtout pour avoir des estimations cohérentes des effets fixes</p></li>
<li><p>REML : convient pour comparer des modèles avec des structures d’effets aléatoires différentes, surtout pour avoir des estimations non biaisées de la variance des effets aléatoires</p></li>
</ul></li>
<li><p>GLMM : extension des LMM pour les variables dépendantes non normales (binaire, comptage, etc.)</p></li>
</ul>
</section>
<section id="modèle-marginal-gee-generalized-estimating-equations" class="level2">
<h2 class="anchored" data-anchor-id="modèle-marginal-gee-generalized-estimating-equations">Modèle marginal = GEE (Generalized Estimating Equations)</h2>
<ul>
<li><p>Principe : modéliser la moyenne marginale de la variable dépendante en tenant compte de la corrélation entre les observations au sein des centres</p>
<ul>
<li><p>D’abord estimation d’à quel point les observations au sein des centres sont corrélées (matrice de corrélation)</p></li>
<li><p>Ensuite, modélisation de la moyenne marginale via un modèle de régression en utilisant cette matrice de corrélation</p></li>
</ul></li>
<li><p>Si peu de structure dans les données (faible corrélation intra-centre), GEE se rapproche d’un modèle classique sans prise en compte de la corrélation.</p></li>
</ul>
<div style="page-break-after: always;"></div>
</section>
</section>
<section id="données-manquantes" class="level1">
<h1>Données manquantes</h1>
<section id="types-de-données-manquantes" class="level2">
<h2 class="anchored" data-anchor-id="types-de-données-manquantes">Types de données manquantes</h2>
<ul>
<li><p>MCAR : Missing Completely At Random (Manquant complètement au hasard)</p>
<ul>
<li><p>La probabilité qu’une donnée soit manquante est indépendante des valeurs observées et non observées</p></li>
<li><p>Exemple : un questionnaire perdu par la poste = <strong>completement aléatoire</strong></p></li>
</ul></li>
<li><p>MAR : Missing At Random (Manquant au hasard)</p>
<ul>
<li><p>La probabilité qu’une donnée soit manquante dépend des valeurs observées, mais pas des valeurs non observées</p></li>
<li><p>Une fois qu’on contrôle pour les variables observées, les données manquantes sont aléatoires</p></li>
<li><p>Exemple :</p>
<ul>
<li><p>les patients plus âgés sont moins susceptibles de répondre à une question sur leur activité physique, mais parmi les patients du même âge, la probabilité de réponse ne dépend pas de leur niveau d’activité physique = <strong>conditionnellement aléatoire</strong></p></li>
<li><p>Donc une fois qu’on contrôle pour l’âge, les données manquantes sont aléatoires !</p></li>
</ul></li>
</ul></li>
<li><p>MNAR : Missing Not At Random (Manquant non au hasard)</p>
<ul>
<li><p>La probabilité qu’une donnée soit manquante dépend des valeurs non observées elles-mêmes</p></li>
<li><p>Même après avoir contrôlé pour les variables observées, les données manquantes ne sont pas aléatoires</p></li>
<li><p>Exemple :</p>
<ul>
<li><p>les patients avec une dépression sévère sont moins susceptibles de répondre à un questionnaire sur leur humeur = <strong>non aléatoire</strong></p></li>
<li><p>Donc même après avoir contrôlé pour d’autres variables, la probabilité de réponse dépend du niveau de dépression non observé</p></li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="faire-la-différence-entre-mcar-mar-et-mnar" class="level2">
<h2 class="anchored" data-anchor-id="faire-la-différence-entre-mcar-mar-et-mnar">Faire la différence entre MCAR, MAR et MNAR</h2>
<ul>
<li><p>Pas de tests statistiques formels pour distinguer MCAR, MAR et MNAR</p></li>
<li><p>Donc se baser sur les connaissances du domaine et la nature des données</p></li>
</ul>
</section>
<section id="imputation-des-données-manquantes" class="level2">
<h2 class="anchored" data-anchor-id="imputation-des-données-manquantes">Imputation des données manquantes</h2>
<section id="imputation-simple" class="level3">
<h3 class="anchored" data-anchor-id="imputation-simple">Imputation simple</h3>
<ul>
<li><p>Remplir les valeurs manquantes avec une seule valeur estimée</p></li>
<li><p>Par exemple : moyenne, médiane, mode, ou valeur prédite par un modèle de régression</p></li>
</ul>
</section>
<section id="imputation-multiple" class="level3">
<h3 class="anchored" data-anchor-id="imputation-multiple">Imputation multiple</h3>
<section id="principe-5" class="level4">
<h4 class="anchored" data-anchor-id="principe-5">Principe</h4>
<ol type="1">
<li><p>Imputation des <span class="math inline">\(\text{n}\)</span> valeurs manquantes en prenant une autre valeur de la même colonne.</p></li>
<li><p>Obtention d’un jeu de données <strong>intermédiaire</strong> permettant de réaliser une régression complète</p></li>
<li><p><strong>régressions</strong> sur chaque jeu de données intermédiaire permettant d’obtenir des valeurs estimées pour chacune des <span class="math inline">\(\text{n}\)</span> valeurs manquantes (il faut donc faire <span class="math inline">\(\text{n}\)</span> régressions). Obtention d’un premier jeu de données <strong>imputé</strong> mais pas encore <strong>convergent</strong></p></li>
<li><p>Répéter les étapes 1 à 3 jusqu’à obtenir une <strong>convergence</strong> des valeurs imputées (plus on impute, plus les jeu de données se ressemblent) et obtention <strong>d’un premier jeu de données imputé convergent</strong></p></li>
<li><p>Répéter les étapes 1 à 4 <span class="math inline">\(\text{m}\)</span> fois pour obtenir <span class="math inline">\(\text{m}\)</span> jeux de données imputés convergents. En général, <span class="math inline">\(\text{m}\)</span> = 5 ou 10.</p></li>
</ol>
</section>
<section id="analyse-des-données-imputées" class="level4">
<h4 class="anchored" data-anchor-id="analyse-des-données-imputées">Analyse des données imputées</h4>
<ul>
<li><p>Analyser chaque jeu de données imputé séparément (par exemple, ajuster un modèle de régression sur chaque jeu de données)</p></li>
<li><p>On obtient ainsi <span class="math inline">\(\text{m}\)</span> ensembles de résultats (coefficients, erreurs standards, etc.)</p></li>
<li><p>Combiner les résultats des <span class="math inline">\(\text{m}\)</span> analyses en utilisant les règles de Rubin pour obtenir des estimations globales et des intervalles de confiance qui tiennent compte de l’incertitude liée à l’imputation</p></li>
</ul>
</section>
<section id="règles-de-rubin" class="level4">
<h4 class="anchored" data-anchor-id="règles-de-rubin">Règles de Rubin</h4>
<ul>
<li><p>Moyenne des estimations : calculer la moyenne des coefficients estimés à partir des <span class="math inline">\(\text{m}\)</span> analyses</p></li>
<li><p>Variance totale : combiner la variance intra-imputation (moyenne des variances des <span class="math inline">\(\text{m}\)</span> analyses) et la variance inter-imputation (variance des coefficients estimés entre les <span class="math inline">\(\text{m}\)</span> analyses) pour obtenir une estimation globale de la variance</p></li>
<li><p>Intervalles de confiance et tests de significativité : utiliser la moyenne des estimations et la variance totale pour construire des intervalles de confiance et effectuer des tests de significativité.</p></li>
</ul>
<div style="page-break-after: always;"></div>
</section>
</section>
</section>
</section>
<section id="mesures-répétées-séries-chronologiques" class="level1">
<h1>Mesures répétées / séries chronologiques</h1>
<section id="problème-posé" class="level2">
<h2 class="anchored" data-anchor-id="problème-posé">Problème posé</h2>
<ul>
<li><p>Données collectées à plusieurs moments dans le temps pour les mêmes individus ou unités d’analyse</p></li>
<li><p>Problème : observations non indépendantes (corrélées dans le temps)</p></li>
<li><p>Donc si modèle classique : risque de faux positifs (erreurs standards sous-estimées, p-values trop optimistes) car non-indépendance des résidus.</p></li>
<li><p>Objectif : modéliser une variable à expliquer qui est</p>
<ul>
<li><p>un processus stationnaire</p></li>
<li><p>évoluant dans le temps</p></li>
<li><p>donc pour lequel la corrélation de la mesure entre un temps <span class="math inline">\(\text{t}\)</span> et un temps <span class="math inline">\(\text{t+k}\)</span> dépend de la distance <span class="math inline">\(\text{k}\)</span> entre les deux temps et pas du temps absolu <span class="math inline">\(\text{t}\)</span>.</p></li>
</ul></li>
</ul>
</section>
<section id="effet-sujet" class="level2">
<h2 class="anchored" data-anchor-id="effet-sujet">Effet sujet</h2>
<ul>
<li><p>Observations répétées donc non-indépendantes au sein d’un même individu</p></li>
<li><p>“<em>Effet sujet</em>” = variabilité entre les individus, différent de l’effet centre !</p>
<ul>
<li><p>Pour un effet centre, les sujets sont interchangeables au sein d’un centre</p></li>
<li><p>Pour un effet sujet, on ne peut pas changer les variables entre un temps et un autre (ex : poids d’un individu à différents moments)</p></li>
</ul></li>
<li><p>La corrélation entre les observations dépend de l’écat temporel</p></li>
<li><p>Plusieurs approches sont possibles pour modéliser cette corrélation</p>
<ul>
<li><p>Modèles linéaires mixtes (LMM) ou modèles linéaires généralisés mixtes (GLMM) : inclure un effet aléatoire pour chaque individu</p></li>
<li><p>Modèles marginaux (GEE) : modéliser la corrélation entre les observations au sein des individus</p></li>
<li><p><strong>Modèles de séries chronologiques : ARIMA, modèles à espace d’état, etc.</strong></p></li>
</ul></li>
</ul>
</section>
<section id="modèles-non-spécifiques-au-séries-chronologiques" class="level2">
<h2 class="anchored" data-anchor-id="modèles-non-spécifiques-au-séries-chronologiques">Modèles non spécifiques au séries chronologiques</h2>
<section id="modèles-linéaires-mixtes-lmm-et-modèles-linéaires-généralisés-mixtes-glmm-1" class="level3">
<h3 class="anchored" data-anchor-id="modèles-linéaires-mixtes-lmm-et-modèles-linéaires-généralisés-mixtes-glmm-1">Modèles linéaires mixtes (LMM) et modèles linéaires généralisés mixtes (GLMM)</h3>
<ul>
<li><p>Inclure un effet aléatoire pour chaque individu dans le modèle de régression</p></li>
<li><p>Permet de modéliser la variabilité entre les individus et de capturer la corrélation entre les observations répétées pour un même individu</p></li>
<li><p>Structure du modèle :</p>
<ul>
<li><p>Effets fixes : coefficients de régression pour les variables explicatives</p></li>
<li><p>Effets aléatoires : variabilité spécifique à chaque individu</p></li>
</ul></li>
</ul>
</section>
<section id="modèles-marginaux-gee" class="level3">
<h3 class="anchored" data-anchor-id="modèles-marginaux-gee">Modèles marginaux (GEE)</h3>
<ul>
<li><p>Principe : modéliser la moyenne marginale de la variable dépendante en tenant compte de la corrélation entre les observations répétées pour chaque individu</p>
<ul>
<li><p>D’abord estimation de la corrélation entre les observations répétées (matrice de corrélation)</p></li>
<li><p>Ensuite, modélisation de la moyenne marginale via un modèle de régression en utilisant cette matrice de corrélation</p></li>
</ul></li>
</ul>
</section>
</section>
<section id="modèles-de-séries-chronologiques-arima-autoregressive-integrated-moving-average" class="level2">
<h2 class="anchored" data-anchor-id="modèles-de-séries-chronologiques-arima-autoregressive-integrated-moving-average">Modèles de séries chronologiques = ARIMA (AutoRegressive Integrated Moving Average)</h2>
<ul>
<li><p>Utilisés lorsque les données sont collectées à intervalles réguliers dans le temps</p></li>
<li><p>Capturent les dépendances temporelles entre les observations</p></li>
<li><p>Types de modèles :</p>
<ul>
<li><p>Modèle AR : variable expliquée par ses propres valeurs passées</p></li>
<li><p>Modèle MA : variable expliquée par une moyenne mobile des erreurs passées</p></li>
</ul></li>
</ul>
<section id="modèle-auto-régressif-ar" class="level3">
<h3 class="anchored" data-anchor-id="modèle-auto-régressif-ar">Modèle auto-régressif (AR)</h3>
<section id="définition-et-concept" class="level4">
<h4 class="anchored" data-anchor-id="définition-et-concept">Définition et concept</h4>
<ul>
<li><p>Valeur actuelle <span class="math inline">\(Y_i\)</span> est prédite linéairement par la valeur précédente <span class="math inline">\(Y_{i-1}\)</span> plus un terme de bruit aléatoire</p></li>
<li><p>Le modèle possède une “mémoire” : les erreurs passées influencent les valeurs futures</p>
<ul>
<li><p>Comme la valeur <span class="math inline">\(Y_i\)</span> dépend de la valeur <span class="math inline">\(Y_{i-1}\)</span> + du bruit <span class="math inline">\(\epsilon_i\)</span></p></li>
<li><p>Et que la valeur <span class="math inline">\(Y_{i-1}\)</span> dépend de la valeur <span class="math inline">\(Y_{i-2}\)</span> + du bruit <span class="math inline">\(\epsilon_{i-1}\)</span></p></li>
<li><p>Donc une erreur <span class="math inline">\(\epsilon_{i-1}\)</span> influence <span class="math inline">\(Y_{i-1}\)</span>, qui influence <span class="math inline">\(Y_i\)</span>, et ainsi de suite</p></li>
</ul></li>
<li><p>La variance totale du processus est un équilibre entre la variabilité du bruit injecté à chaque instant et la capacité du système à “se souvenir” de ses erreurs passées</p></li>
<li><p>Un “choc” ou une erreur <span class="math inline">\(\epsilon_i\)</span> survenant à un instant donné se propage dans tout le futur de la série</p></li>
<li><p>La valeur totale du modèle dépend donc de la variabilité du bruit et de la mémoire du système (coefficient <span class="math inline">\(b\)</span>)</p></li>
<li><p>La valeur de départ importe peu, la série est centrée avant modélisation.</p></li>
</ul>
</section>
<section id="variance-totale-du-processus" class="level4">
<h4 class="anchored" data-anchor-id="variance-totale-du-processus">Variance totale du processus</h4>
<ul>
<li><p>La variance totale de la série dépend globalement de deux facteurs :</p>
<ul>
<li><p>La variance du bruit aléatoire <span class="math inline">\(\sigma^2\)</span> : plus le bruit est important, plus la variance totale augmente</p></li>
<li><p>Le coefficient de mémoire <span class="math inline">\(b\)</span> : plus <span class="math inline">\(|b|\)</span> est proche de 1, plus les erreurs passées influencent les valeurs futures, augmentant ainsi la variance totale</p></li>
</ul></li>
</ul>
</section>
<section id="processus-stationnaire" class="level4">
<h4 class="anchored" data-anchor-id="processus-stationnaire">Processus stationnaire</h4>
<ul>
<li><p>Pour que le modèle soit stable, il doit être stationnaire, c’est à dire que sa variabilité doit rester stable dans le temps</p></li>
<li><p>Le coefficient de mémoire <span class="math inline">\(b\)</span> doit être tel que <span class="math inline">\(|b| &lt; 1\)</span>, la variance est donc stationnaire.</p></li>
<li><p>Si <span class="math inline">\(|b| \text{≥} 1\)</span>, ça signifie que les erreurs se cumulent sans limite (marche aléatoire).</p></li>
</ul>
</section>
<section id="structure-de-la-corrélation" class="level4">
<h4 class="anchored" data-anchor-id="structure-de-la-corrélation">Structure de la corrélation</h4>
<ul>
<li><p>Dans un modèle AR :</p>
<ul>
<li><p>La corrélation entre deux mesures décroît de façon exponentielle avec l’écart de temps (le lag)</p></li>
<li><p>Mathématiquement, la corrélation entre <span class="math inline">\(Y_i\)</span> et <span class="math inline">\(Y_{i-k}\)</span> est égale à <span class="math inline">\(b^k\)</span></p></li>
</ul></li>
<li><p>Plus les mesures sont éloignées dans le temps, plus le lien linéaire s’affaiblit, ce qui correspond à la réalité clinique des mesures répétées sur un sujet (plus deux mesures sont éloignées dans le temps, moins elles sont corrélées)</p></li>
</ul>
</section>
</section>
<section id="modèle-de-moyenne-mobile-ma" class="level3">
<h3 class="anchored" data-anchor-id="modèle-de-moyenne-mobile-ma">Modèle de moyenne mobile (MA)</h3>
<section id="définition-et-concept-1" class="level4">
<h4 class="anchored" data-anchor-id="définition-et-concept-1">Définition et concept</h4>
<ul>
<li><p>Valeur actuelle <span class="math inline">\(Y_i\)</span> est exprimée comme une combinaison linéaire des erreurs passées</p></li>
<li><p>Dans ce cas, erreur = bruit = part imprévisible de la mesure, celle qui n’est pas expliquée par la structure même de la série</p></li>
<li><p>Donc valeur actuelle = somme du bruit actuel <span class="math inline">\(\epsilon_i\)</span> + du bruit immédiatement précédent <span class="math inline">\(\epsilon_{i-1}\)</span> (pour un modèle MA(1))</p></li>
</ul>
</section>
<section id="mémoire-courte" class="level4">
<h4 class="anchored" data-anchor-id="mémoire-courte">Mémoire “courte”</h4>
<ul>
<li><p>La corrélation entre deux mesures successives (<span class="math inline">\(Y_j\)</span> et <span class="math inline">\(Y_{j-1}\)</span>) existe uniquement parce qu’elles partagent le même terme d’erreur <span class="math inline">\(\epsilon_{i-1}\)</span></p></li>
<li><p>À l’inverse du modèle AR où la corrélation s’estompe lentement, elle devient strictement nulle dès que l’écart (lag) dépasse l’ordre du modèle</p>
<ul>
<li><p>Pour un MA(1), il n’y a plus aucun terme d’erreur commun entre <span class="math inline">\(Y_j\)</span> et <span class="math inline">\(Y_{j-2}\)</span>, rendant leur corrélation égale à zéro</p></li>
<li><p>Donc la mémoire est très courte : un choc aléatoire influence la mesure du jour et potentiellement celle du lendemain, mais sans effet durable à long terme</p></li>
</ul></li>
<li><p>Permet de modéliser des phénomènes où les erreurs sont temporaires et n’ont pas d’impact prolongé</p></li>
<li><p>La corrélation est nulle au delà du lag défini par l’ordre du modèle MA</p></li>
</ul>
</section>
</section>
<section id="modèles-complexes-arma-et-arima" class="level3">
<h3 class="anchored" data-anchor-id="modèles-complexes-arma-et-arima">Modèles complexes : ARMA et ARIMA</h3>
<ul>
<li><p>Combinaison des modèles AR et MA pour capturer à la fois les dépendances à long terme (AR) et les fluctuations à court terme (MA)</p></li>
<li><p>ARIMA (AutoRegressive Integrated Moving Average) : extension des modèles ARMA qui inclut une étape de différenciation pour rendre la série temporelle stationnaire si nécessaire. I = “Integrated” = dérive au cours du temps.</p></li>
<li><p>SARIMA : extension des modèles ARIMA pour capturer les effets saisonniers dans les données temporelles</p></li>
</ul>
</section>
<section id="identification-des-paramètres-du-modèle" class="level3">
<h3 class="anchored" data-anchor-id="identification-des-paramètres-du-modèle">Identification des paramètres du modèle</h3>
<ul>
<li><p>Utilisation d’un <strong>autocorrélogramme</strong> et d’une <strong>autocorrélogramme partiel</strong> pour identifier les ordres AR et MA</p></li>
<li><p>Autocorrélogramme (ACF) : montre la corrélation entre les observations à différents lags</p>
<ul>
<li><p>Permet d’identifier la partie MA du modèle</p></li>
<li><p>MA : si décroissance rapide à un lag spécifique</p></li>
</ul></li>
<li><p>Autocorrélogramme partiel (PACF) : montre la corrélation entre les observations à différents lags, <strong>en contrôlant pour les lags intermédiaires</strong></p>
<ul>
<li><p>Permet d’identifier la partie AR du modèle</p></li>
<li><p>AR : si décroissance progressive sur plusieurs lags</p></li>
</ul></li>
</ul>
<div style="page-break-after: always;"></div>
</section>
</section>
</section>
<section id="comparaisons-multiples" class="level1">
<h1>Comparaisons multiples</h1>
<section id="pourquoi-ajuster" class="level2">
<h2 class="anchored" data-anchor-id="pourquoi-ajuster">Pourquoi ajuster ?</h2>
<ul>
<li><p>Problème : lorsque plusieurs tests statistiques sont effectués simultanément, le risque global d’erreur de type I (faux positifs) augmente</p></li>
<li><p>Fisher : calcul des <em>p-values</em> pour chaque comparaison</p>
<ul>
<li><p>Fait ainsi de <strong>l’inférence inductive</strong> : utilise chacune des p-values pour en déduire de nouvelles hypothèses sur la population</p></li>
<li><p>Observations de départ sont vraies, mais les conclusions sont probables</p></li>
</ul></li>
<li><p>Neyman-Pearson ; calcule une seule <em>p-value</em> pour l’ensemble des comparaisons</p>
<ul>
<li><p>Hypothèses nulle <span class="math inline">\(\text{H}_0\)</span> et alternative <span class="math inline">\(\text{H}_1\)</span> sont fixées avant les tests</p></li>
<li><p>Risque d’erreur de type I (<span class="math inline">\(\alpha\)</span>) et de type II (<span class="math inline">\(\beta\)</span>) sont fixés à l’avance</p></li>
<li><p>Si on augmente le nombre d’hypothèses, on augmente aussi le risque d’erreur de type I !</p></li>
</ul></li>
</ul>
</section>
<section id="quand-ajuster" class="level2">
<h2 class="anchored" data-anchor-id="quand-ajuster">Quand ajuster ?</h2>
<ul>
<li>Dans les situations Neyman-Pearson, càd les essais cliniques.</li>
</ul>
</section>
<section id="méthodes-dajustement" class="level2">
<h2 class="anchored" data-anchor-id="méthodes-dajustement">Méthodes d’ajustement</h2>
<section id="répartition-du-risque-alpha" class="level3">
<h3 class="anchored" data-anchor-id="répartition-du-risque-alpha">Répartition du risque alpha</h3>
<section id="méthode-de-bonferroni-la-plus-classique" class="level4">
<h4 class="anchored" data-anchor-id="méthode-de-bonferroni-la-plus-classique">Méthode de Bonferroni = la plus classique</h4>
<ul>
<li><p>Principe : diviser le risque alpha par le nombre de comparaisons effectuées</p></li>
<li><p>Si 2 tests, alpha = 0.05/2 = 0.025 pour chaque test</p></li>
</ul>
</section>
<section id="méthode-de-holm" class="level4">
<h4 class="anchored" data-anchor-id="méthode-de-holm">Méthode de Holm</h4>
<ul>
<li><p>Principe : ajustement séquentiel</p>
<ul>
<li><p>Trier les p-values par ordre croissant</p></li>
<li><p>Comparer chaque p-value à un seuil ajusté qui diminue avec le rang de la p-value</p>
<ul>
<li><p>Pour la p-value la plus petite : alpha/n</p></li>
<li><p>Pour la deuxième p-value : alpha/(n-1)</p></li>
<li><p>Etc.</p></li>
</ul></li>
</ul></li>
</ul>
</section>
</section>
<section id="méthode-par-hierarchie" class="level3">
<h3 class="anchored" data-anchor-id="méthode-par-hierarchie">Méthode par hierarchie</h3>
<ul>
<li><p>Principe : définir une hiérarchie des tests avant l’analyse</p>
<ul>
<li><p>Tester d’abord les hypothèses principales</p></li>
<li><p>Si elles sont significatives, tester les hypothèses secondaires</p></li>
<li><p>Si une hypothèse principale n’est pas significative, ne pas tester les hypothèses secondaires associées</p></li>
</ul></li>
</ul>
<div style="page-break-after: always;"></div>
</section>
</section>
</section>
<section id="méthodes-non-supervisées" class="level1">
<h1>Méthodes non supervisées</h1>
<ul>
<li><p>Objectif des méthodes non supervisées : mettre en évidence des groupes homogènes de <strong>sujets</strong> ou de <strong>variables</strong> dans un ensemble de données, sans utiliser d’étiquettes ou de classes prédéfinies</p></li>
<li><p>2 options :</p>
<ul>
<li><p>Réduction du nombre de dimensions pour les rendre compatibles avec nos yeux</p></li>
<li><p>Demander à l’ordinateur de se substituer à nous : nuées dynamiques, classification hierarchiques…</p></li>
</ul></li>
</ul>
<section id="groupes-homogènes-de-sujets-clustering" class="level2">
<h2 class="anchored" data-anchor-id="groupes-homogènes-de-sujets-clustering">Groupes homogènes de sujets : clustering</h2>
<section id="analyse-en-composantes-principales-acp" class="level3">
<h3 class="anchored" data-anchor-id="analyse-en-composantes-principales-acp">Analyse en composantes principales (ACP)</h3>
<section id="principe-6" class="level4">
<h4 class="anchored" data-anchor-id="principe-6">Principe</h4>
<ul>
<li><p>But : réduire le nombre de dimensions tout en conservant le maximum d’information</p></li>
<li><p>1ère composante principale :</p>
<ul>
<li><p>droite qui <strong>explique le maximum de variance</strong> dans les données = <strong>qui explique au mieux la variabilité des données</strong>.</p></li>
<li><p>= combinaison linéaire des variables initiales qui maximise la variance projetée</p></li>
</ul></li>
<li><p>2nde composante principale :</p>
<ul>
<li><p>droite orthogonale à la 1ère qui explique le maximum de variance restante</p></li>
<li><p>Méthode :</p>
<ul>
<li><p>d’abord projeter les points sur le plan de la 1ère composante principale</p></li>
<li><p>Puis répéter l’opération pour trouver la 2nde composante principale</p></li>
</ul></li>
</ul></li>
<li><p>Composantes suivantes :</p>
<ul>
<li><p>Droites orthogonales aux précédentes qui expliquent le maximum de variance restante</p></li>
<li><p>Répéter jusqu’à obtenir autant de composantes que de variables initiales</p></li>
</ul></li>
</ul>
</section>
<section id="interprétation" class="level4">
<h4 class="anchored" data-anchor-id="interprétation">Interprétation</h4>
<ul>
<li><p>Des composantes principales :</p>
<ul>
<li><p>Chaque composante principale est une combinaison linéaire des variables initiales</p></li>
<li><p>Les coefficients de chaque variable dans la combinaison linéaire indiquent l’<strong>importance de cette variable dans la composante principale</strong></p></li>
<li><p>On dit qu’une composante principale explique un pourcentage de la variance totale des données</p></li>
<li><p>Donc si une variable a un coefficient élevé dans une composante principale qui explique une grande partie de la variance, cette variable est importante pour comprendre la structure des données</p></li>
</ul></li>
<li><p>Du “plan principal”</p>
<ul>
<li><p>Plan principal = projection des données sur les 2 premières composantes principales</p></li>
<li><p>Permet de visualiser la structure des données en 2D</p></li>
</ul></li>
<li><p><strong>Pythagore et la géométrie de l’ACP</strong> :</p>
<ul>
<li><p><strong>La méthode des moindres carrés</strong> : L’ACP cherche à minimiser les distances entre les points originaux et leurs projections sur chaque composante principale. Cette minimisation garantit que la composante principale capture le maximum de variance possible.</p></li>
<li><p><strong>Le théorème de Pythagore en action</strong> : Considérons un point de données quelconque. On peut former un triangle rectangle avec trois points clés :</p>
<ol type="1">
<li>Le <strong>centre de gravité</strong> des données (la moyenne générale)</li>
<li>Le <strong>point original</strong> dans l’espace à plusieurs dimensions</li>
<li>La <strong>projection du point</strong> sur la composante principale</li>
</ol>
<p>Ces trois points forment un triangle rectangle où :</p>
<ul>
<li>L’<strong>hypoténuse</strong> = distance du centre au point original (variance totale du point)</li>
<li>Le <strong>premier côté</strong> = distance du centre à la projection sur PC1 (expliquée par PC1)</li>
<li>Le <strong>deuxième côté</strong> = distance perpendiculaire entre le point et PC1 (non expliquée par PC1)</li>
</ul>
<p><strong>Le théorème de Pythagore</strong> : variance totale² = variance PC1² + variance résiduelle²</p></li>
<li><p><strong>Interprétation des composantes principales</strong> :</p>
<ul>
<li><p>La <strong>première composante principale (PC1)</strong> maximise la distance entre le centre et la projection du point. C’est la direction où les données varient le plus.</p></li>
<li><p>La <strong>deuxième composante principale (PC2)</strong> maximise la variance dans la direction <em>perpendiculaire</em> à PC1. Elle capture la variation restante.</p></li>
<li><p>Les composantes principales suivantes font de même, toujours perpendiculaires aux précédentes, expliquant progressivement moins de variance.</p></li>
</ul></li>
<li><p><strong>Visualisation graphique</strong> :</p></li>
</ul></li>
</ul>
<div style="display: flex; justify-content: center; margin: 20px 0;">
<svg width="800" height="700" viewbox="0 0 800 700" style="border: 1px solid #ccc; background-color: #fafafa;">
  <!-- Titre -->
  <text x="400" y="30" font-size="20" font-weight="bold" text-anchor="middle" fill="#333">
    Théorème de Pythagore en ACP
  </text>
  <text x="400" y="55" font-size="14" text-anchor="middle" fill="#666">
    Variance totale² = Variance PC1² + Variance résiduelle²
  </text>
  
  <!-- Grille légère -->
  <defs>
    <pattern id="grid" width="40" height="40" patternunits="userSpaceOnUse">
      <path d="M 40 0 L 0 0 0 40" fill="none" stroke="#e0e0e0" stroke-width="0.5"></path>
    </pattern>
  </defs>
  <rect width="800" height="700" fill="url(#grid)"></rect>
  
  <!-- Axes de coordonnées -->
  <line x1="150" y1="550" x2="750" y2="550" stroke="#333" stroke-width="2"></line>
  <line x1="150" y1="100" x2="150" y2="550" stroke="#333" stroke-width="2"></line>
  
  <!-- Étiquettes axes -->
  <text x="760" y="570" font-size="12" fill="#333">Variable 1</text>
  <text x="120" y="90" font-size="12" fill="#333">Variable 2</text>
  
  <!-- PC1 (axe rouge en tirets) -->
  <line x1="150" y1="550" x2="700" y2="200" stroke="#E74C3C" stroke-width="2" stroke-dasharray="5,5"></line>
  <text x="720" y="180" font-size="12" fill="#E74C3C" font-weight="bold">PC1</text>
  
  <!-- Centre (barycentre) -->
  <circle cx="150" cy="550" r="6" fill="black"></circle>
  <text x="140" y="580" font-size="11" fill="black" font-weight="bold">Centre</text>
  <text x="140" y="595" font-size="10" fill="#666">(Barycentre)</text>
  
  <!-- ==================== POINT A ==================== -->
  <!-- Projection du point A sur PC1 -->
  <circle cx="350" cy="380" r="3" fill="white" stroke="#FF6B6B" stroke-width="2"></circle>
  
  <!-- Point original A -->
  <circle cx="420" cy="330" r="5" fill="#FF6B6B" stroke="#FF6B6B" stroke-width="1"></circle>
  <text x="435" y="335" font-size="12" fill="#FF6B6B" font-weight="bold">Point A</text>
  
  <!-- Triangle Point A -->
  <!-- Hypoténuse (centre à point) -->
  <line x1="150" y1="550" x2="420" y2="330" stroke="#FF6B6B" stroke-width="3"></line>
  
  <!-- Base (centre à projection) -->
  <line x1="150" y1="550" x2="350" y2="380" stroke="#FF6B6B" stroke-width="2" stroke-dasharray="8,4"></line>
  
  <!-- Hauteur (projection à point) -->
  <line x1="350" y1="380" x2="420" y2="330" stroke="#FF6B6B" stroke-width="2" stroke-dasharray="2,4"></line>
  
  <!-- Angle droit Point A -->
  <rect x="345" y="385" width="8" height="8" fill="none" stroke="#FF6B6B" stroke-width="1"></rect>
  
  <!-- Légende Point A -->
  <text x="270" y="410" font-size="10" fill="#FF6B6B" font-weight="bold">Hyp²</text>
  <text x="240" y="520" font-size="10" fill="#FF6B6B" font-weight="bold">Base²</text>
  <text x="390" y="355" font-size="9" fill="#FF6B6B">Haut²</text>
  
  <!-- ==================== POINT B ==================== -->
  <!-- Projection du point B sur PC1 -->
  <circle cx="480" cy="290" r="3" fill="white" stroke="#4ECDC4" stroke-width="2"></circle>
  
  <!-- Point original B -->
  <circle cx="550" cy="220" r="5" fill="#4ECDC4" stroke="#4ECDC4" stroke-width="1"></circle>
  <text x="565" y="225" font-size="12" fill="#4ECDC4" font-weight="bold">Point B</text>
  
  <!-- Triangle Point B -->
  <!-- Hypoténuse -->
  <line x1="150" y1="550" x2="550" y2="220" stroke="#4ECDC4" stroke-width="3"></line>
  
  <!-- Base -->
  <line x1="150" y1="550" x2="480" y2="290" stroke="#4ECDC4" stroke-width="2" stroke-dasharray="8,4"></line>
  
  <!-- Hauteur -->
  <line x1="480" y1="290" x2="550" y2="220" stroke="#4ECDC4" stroke-width="2" stroke-dasharray="2,4"></line>
  
  <!-- Angle droit Point B -->
  <rect x="475" y="295" width="8" height="8" fill="none" stroke="#4ECDC4" stroke-width="1"></rect>
  
  <!-- ==================== POINT C ==================== -->
  <!-- Projection du point C sur PC1 -->
  <circle cx="600" cy="180" r="3" fill="white" stroke="#95E1D3" stroke-width="2"></circle>
  
  <!-- Point original C -->
  <circle cx="680" cy="100" r="5" fill="#95E1D3" stroke="#95E1D3" stroke-width="1"></circle>
  <text x="695" y="105" font-size="12" fill="#95E1D3" font-weight="bold">Point C</text>
  
  <!-- Triangle Point C -->
  <!-- Hypoténuse -->
  <line x1="150" y1="550" x2="680" y2="100" stroke="#95E1D3" stroke-width="3"></line>
  
  <!-- Base -->
  <line x1="150" y1="550" x2="600" y2="180" stroke="#95E1D3" stroke-width="2" stroke-dasharray="8,4"></line>
  
  <!-- Hauteur -->
  <line x1="600" y1="180" x2="680" y2="100" stroke="#95E1D3" stroke-width="2" stroke-dasharray="2,4"></line>
  
  <!-- Angle droit Point C -->
  <rect x="595" y="185" width="8" height="8" fill="none" stroke="#95E1D3" stroke-width="1"></rect>
  
  <!-- ==================== LÉGENDE ==================== -->
  <g transform="translate(150, 630)">
    <!-- Boîte légère -->
    <rect x="0" y="0" width="600" height="60" fill="#f5f5f5" stroke="#ccc" stroke-width="1" rx="3"></rect>
    
    <!-- Lignes -->
    <line x1="10" y1="15" x2="50" y2="15" stroke="#666" stroke-width="3"></line>
    <text x="60" y="20" font-size="11" fill="#333"><tspan font-weight="bold">Hypoténuse</tspan> = Distance centre → point (variance totale)</text>
    
    <line x1="10" y1="35" x2="50" y2="35" stroke="#666" stroke-width="2" stroke-dasharray="8,4"></line>
    <text x="60" y="40" font-size="11" fill="#333"><tspan font-weight="bold">Base</tspan> = Distance centre → projection (expliquée par PC1)</text>
    
    <line x1="320" y1="15" x2="360" y2="15" stroke="#666" stroke-width="2" stroke-dasharray="2,4"></line>
    <text x="370" y="20" font-size="11" fill="#333"><tspan font-weight="bold">Hauteur</tspan> = Distance perpendiculaire (non expliquée)</text>
    
    <text x="520" y="40" font-size="11" fill="#333">□ = Angle droit</text>
  </g>
</svg>
</div>
<p><strong>Interprétation du schéma :</strong></p>
<p>Pour chaque point (A, B, C), on observe un triangle rectangle : - L’<strong>hypoténuse</strong> (trait épais plein) relie le centre au point original → c’est la variance <strong>totale</strong> du point - La <strong>base</strong> (trait en tirets) relie le centre à la projection sur PC1 → c’est la variance <strong>expliquée</strong> par PC1 - La <strong>hauteur</strong> (petit trait en pointillé) relie la projection au point → c’est la variance <strong>non expliquée</strong> par PC1 - L’angle droit (petit carré) garantit que le théorème s’applique</p>
<p><strong>L’équation de Pythagore s’applique :</strong> <span class="math display">\[\text{(Hypoténuse)}^2 = \text{(Base)}^2 + \text{(Hauteur)}^2\]</span></p>
<p>Ce qui se traduit par : <span class="math display">\[\text{Variance totale}^2 = \text{Variance PC1}^2 + \text{Variance résiduelle}^2\]</span></p>
</section>
<section id="relation-composantes-principales-valeurs-propres" class="level4">
<h4 class="anchored" data-anchor-id="relation-composantes-principales-valeurs-propres">Relation composantes principales / valeurs propres</h4>
<ul>
<li><p>Chacune des composantes principales = un vecteur propre de la matrice de covariance des données.</p></li>
<li><p>La longueur de la composante principale est proportionnelle à la variance expliquée par cette composante et correspond à <strong>la valeur propre associée à ce vecteur propre</strong>.</p></li>
<li><p>En résumé :</p>
<ul>
<li><p>Vecteur propre = direction de la composante principale</p></li>
<li><p>Valeur propre = longueur de la composante principale = variance expliquée par la composante principale</p></li>
</ul></li>
<li><p>Donc plus la valeur propre est grande, plus la composante principale explique une grande partie de la variance des données.</p></li>
</ul>
</section>
</section>
</section>
</section>

</main>
<!-- /main column -->
<div id="markmap-link-container" style="position: fixed; top: 10px; right: 10px; z-index: 1000; background: white; padding: 10px; border: 2px solid #4a90e2; border-radius: 5px; box-shadow: 0 2px 5px rgba(0,0,0,0.2);">
  <a href="QUARTO-BIG-NOTES-markmap.html" target="_blank" style="text-decoration: none; color: #4a90e2; font-weight: bold; font-size: 14px;">
    🗺️ Voir la Markmap
  </a>
</div>
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>