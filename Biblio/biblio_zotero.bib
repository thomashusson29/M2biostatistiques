@article{austinComparison12Algorithms2014,
  title = {A Comparison of 12 Algorithms for Matching on the Propensity Score},
  author = {Austin, Peter C},
  year = 2014,
  month = mar,
  journal = {Statistics in Medicine},
  volume = {33},
  number = {6},
  pages = {1057--1069},
  issn = {0277-6715},
  doi = {10.1002/sim.6004},
  urldate = {2025-01-06},
  abstract = {Propensity-score matching is increasingly being used to reduce the confounding that can occur in observational studies examining the effects of treatments or interventions on outcomes. We used Monte Carlo simulations to examine the following algorithms for forming matched pairs of treated and untreated subjects: optimal matching, greedy nearest neighbor matching without replacement, and greedy nearest neighbor matching without replacement within specified caliper widths. For each of the latter two algorithms, we examined four different sub-algorithms defined by the order in which treated subjects were selected for matching to an untreated subject: lowest to highest propensity score, highest to lowest propensity score, best match first, and random order. We also examined matching with replacement. We found that (i) nearest neighbor matching induced the same balance in baseline covariates as did optimal matching; (ii) when at least some of the covariates were continuous, caliper matching tended to induce balance on baseline covariates that was at least as good as the other algorithms; (iii) caliper matching tended to result in estimates of treatment effect with less bias compared with optimal and nearest neighbor matching; (iv) optimal and nearest neighbor matching resulted in estimates of treatment effect with negligibly less variability than did caliper matching; (v) caliper matching had amongst the best performance when assessed using mean squared error; (vi) the order in which treated subjects were selected for matching had at most a modest effect on estimation; and (vii) matching with replacement did not have superior performance compared with caliper matching without replacement. \copyright{} 2013 The Authors. Statistics in Medicine published by John Wiley \& Sons, Ltd.},
  pmcid = {PMC4285163},
  pmid = {24123228},
  file = {/Users/crsa938/Zotero/storage/G3H5ZDX7/Austin - 2014 - A comparison of 12 algorithms for matching on the .pdf}
}

@article{austinIntroductionPropensityScore2011,
  title = {An {{Introduction}} to {{Propensity Score Methods}} for {{Reducing}} the {{Effects}} of {{Confounding}} in {{Observational Studies}}},
  author = {Austin, Peter C.},
  year = 2011,
  month = may,
  journal = {Multivariate Behavioral Research},
  volume = {46},
  number = {3},
  pages = {399--424},
  issn = {0027-3171},
  doi = {10.1080/00273171.2011.568786},
  urldate = {2025-01-05},
  abstract = {The propensity score is the probability of treatment assignment conditional on observed baseline characteristics. The propensity score allows one to design and analyze an observational (nonrandomized) study so that it mimics some of the particular characteristics of a randomized controlled trial. In particular, the propensity score is a balancing score: conditional on the propensity score, the distribution of observed baseline covariates will be similar between treated and untreated subjects. I describe 4 different propensity score methods: matching on the propensity score, stratification on the propensity score, inverse probability of treatment weighting using the propensity score, and covariate adjustment using the propensity score. I describe balance diagnostics for examining whether the propensity score model has been adequately specified. Furthermore, I discuss differences between regression-based methods and propensity score-based methods for the analysis of observational data. I describe different causal average treatment effects and their relationship with propensity score analyses.},
  pmcid = {PMC3144483},
  pmid = {21818162}
}

@article{riley2020,
  title = {Calculating the Sample Size Required for Developing a Clinical Prediction Model},
  author = {Riley, Richard D. and Ensor, Joie and Snell, Kym I. E. and Harrell, Frank E. and Martin, Glen P. and Reitsma, Johannes B. and Moons, Karel G. M. and Collins, Gary and van Smeden, Maarten},
  year = 2020,
  month = mar,
  journal = {BMJ},
  volume = {368},
  pages = {m441},
  publisher = {British Medical Journal Publishing Group},
  issn = {1756-1833},
  doi = {10.1136/bmj.m441},
  urldate = {2026-02-25},
  abstract = {{$<$}p{$>$}Clinical prediction models aim to predict outcomes in individuals, to inform diagnosis or prognosis in healthcare. Hundreds of prediction models are published in the medical literature each year, yet many are developed using a dataset that is too small for the total number of participants or outcome events. This leads to inaccurate predictions and consequently incorrect healthcare decisions for some individuals. In this article, the authors provide guidance on how to calculate the sample size required to develop a clinical prediction model.{$<$}/p{$>$}},
  chapter = {Research Methods \&amp; Reporting},
  copyright = {Published by the BMJ Publishing Group Limited. For permission to use (where not already granted under a licence) please go to http://group.bmj.com/group/rights-licensing/permissions},
  langid = {english},
  pmid = {32188600},
  file = {/Users/crsa938/Zotero/storage/76UQ9DQV/Riley et al. - 2020 - Calculating the sample size required for developing a clinical prediction model.pdf}
}
